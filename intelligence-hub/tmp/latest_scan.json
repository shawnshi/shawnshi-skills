{
  "metadata": {
    "timestamp": "2026-02-23T12:44:22.833626",
    "sources": {
      "nature_digital": "OK",
      "jeffgeerling.com": "OK",
      "v2ex": "OK",
      "ericmigi.com": "OK",
      "science": "OK",
      "lancet_digital": "OK",
      "nejm": "OK",
      "simonwillison.net": "OK",
      "daringfireball.net": "OK",
      "idiallo.com": "OK",
      "producthunt": "OK",
      "devblogs.microsoft.com/oldnewthing": "OK",
      "healthit": "OK",
      "seangoedecke.com": "OK",
      "mitchellh.com": "OK",
      "github": "OK",
      "maurycyz.com": "OK",
      "dynomight.net": "OK",
      "lcamtuf.substack.com": "OK",
      "shkspr.mobi": "OK",
      "xeiaso.net": "OK",
      "lucumr.pocoo.org": "OK",
      "pluralistic.net": "OK",
      "overreacted.io": "OK",
      "garymarcus.substack.com": "OK",
      "righto.com": "OK",
      "skyfall.dev": "OK",
      "timsh.org": "OK",
      "utcc.utoronto.ca/~cks": "OK",
      "matklad.github.io": "OK",
      "johndcook.com": "OK",
      "terriblesoftware.org": "OK",
      "derekthompson.org": "OK",
      "rakhim.exotext.com": "OK",
      "evanhahn.com": "OK",
      "xania.org": "OK",
      "antirez.com": "OK",
      "nesbitt.io": "OK",
      "micahflee.com": "OK",
      "entropicthoughts.com": "OK",
      "construction-physics.com": "OK",
      "tedium.co": "OK",
      "buttondown.com/hillelwayne": "OK",
      "susam.net": "OK",
      "jayd.ml": "OK",
      "borretti.me": "OK",
      "gilesthomas.com": "OK",
      "geohot.github.io": "OK",
      "joanwestenberg.com": "OK",
      "paulgraham.com": "OK",
      "minimaxir.com": "OK",
      "wheresyoured.at": "OK",
      "blog.jim-nielsen.com": "OK",
      "himss": "403 Client Error: Forbidden for url: https://www.himss.org/news",
      "dfarq.homeip.net": "OK",
      "brutecat.com": "OK",
      "geoffreylitt.com": "OK",
      "eli.thegreenplace.net": "OK",
      "ajmc": "403 Client Error: Forbidden for url: https://www.ajmc.com/newsroom",
      "jyn.dev": "OK",
      "fabiensanglard.net": "OK",
      "hugotunius.se": "OK",
      "chadnauseam.com": "OK",
      "gwern.net": "OK",
      "downtowndougbrown.com": "OK",
      "filfre.net": "OK",
      "abortretry.fail": "OK",
      "it-notes.dragas.net": "OK",
      "bogdanthegeek.github.io": "OK",
      "hey.paris": "OK",
      "danielwirtz.com": "OK",
      "oldvcr.blogspot.com": "OK",
      "philiplaine.com": "OK",
      "berthub.eu": "OK",
      "arxiv_med_ai": "400 Client Error: Bad Request for url: https://export.arxiv.org/api/query?search_query=all:medicine+AND+cat:cs.AI&sortBy=lastUpdatedDate&sortOrder=desc&max_results=5",
      "danieldelaney.net": "OK",
      "refactoringenglish.com": "OK",
      "simone.org": "OK",
      "matduggan.com": "OK",
      "dwarkesh.com": "OK",
      "bernsteinbear.com": "OK",
      "beej.us": "OK",
      "troyhunt.com": "OK",
      "tomrenner.com": "OK",
      "herman.bearblog.dev": "OK",
      "steveblank.com": "OK",
      "martinalderson.com": "OK",
      "blog.pixelmelt.dev": "OK",
      "danielchasehooper.com": "OK",
      "chiark.greenend.org.uk/~sgtatham": "OK",
      "aresluna.org": "OK",
      "healthaffairs.org": "OK",
      "experimental-history.com": "OK",
      "grantslatton.com": "OK",
      "miguelgrinberg.com": "OK",
      "beckershospitalreview.com": "OK",
      "anildash.com": "OK",
      "mjg59.dreamwidth.org": "OK",
      "keygen.sh": "OK",
      "healthcareitnews.com": "unbound prefix: line 6, column 2",
      "computer.rip": "OK",
      "hackernews": "OK",
      "mobihealthnews.com": "unbound prefix: line 6, column 2",
      "michael.stapelberg.ch": "OK",
      "worksonmymachine.substack.com": "OK",
      "ehrintelligence.com": "403 Client Error: Forbidden for url: https://ehrintelligence.com/feed",
      "rachelbythebay.com": "HTTPSConnectionPool(host='rachelbythebay.com', port=4433): Max retries exceeded with url: /w/atom.xml (Caused by ProxyError('Unable to connect to proxy', RemoteDisconnected('Remote end closed connection without response')))",
      "krebsonsecurity.com": "502 Server Error: Bad Gateway for url: https://krebsonsecurity.com/feed/",
      "tedunangst.com": "HTTPSConnectionPool(host='www.tedunangst.com', port=443): Read timed out. (read timeout=20)"
    },
    "count": 324
  },
  "items": [
    {
      "title": "Nature Digital Medicine: A large-scale benchmark for evaluating large language models on medical question answering in Romanian",
      "url": "https://www.nature.com/articles/s41746-026-02465-0",
      "source": "Nature Digital Medicine",
      "time": "2026-02-23T12:43:10.004894",
      "raw_desc": ""
    },
    {
      "title": "Nature Digital Medicine: Artificial intelligence–enhanced microsurgical training: a systematic review",
      "url": "https://www.nature.com/articles/s41746-026-02452-5",
      "source": "Nature Digital Medicine",
      "time": "2026-02-23T12:43:10.004894",
      "raw_desc": ""
    },
    {
      "title": "Nature Digital Medicine: Defining operational safety in clinical artificial intelligence systems",
      "url": "https://www.nature.com/articles/s41746-026-02450-7",
      "source": "Nature Digital Medicine",
      "time": "2026-02-23T12:43:10.004894",
      "raw_desc": ""
    },
    {
      "title": "Nature Digital Medicine: CancerLLM: a large language model in cancer domain",
      "url": "https://www.nature.com/articles/s41746-026-02441-8",
      "source": "Nature Digital Medicine",
      "time": "2026-02-23T12:43:10.004894",
      "raw_desc": ""
    },
    {
      "title": "Nature Digital Medicine: Robust and interpretable unit level causal inference in neural networks for pediatric myopia",
      "url": "https://www.nature.com/articles/s41746-026-02442-7",
      "source": "Nature Digital Medicine",
      "time": "2026-02-23T12:43:10.004894",
      "raw_desc": ""
    },
    {
      "title": "jeffgeerling.com: Frigate with Hailo for object detection on a Raspberry Pi",
      "url": "https://www.jeffgeerling.com/blog/2026/frigate-with-hailo-for-object-detection-on-a-raspberry-pi/",
      "source": "jeffgeerling.com",
      "time": "2026-02-23T12:43:10.565660",
      "raw_desc": ""
    },
    {
      "title": "jeffgeerling.com: AI is destroying Open Source, and it's not even good yet",
      "url": "https://www.jeffgeerling.com/blog/2026/ai-is-destroying-open-source/",
      "source": "jeffgeerling.com",
      "time": "2026-02-23T12:43:10.565660",
      "raw_desc": ""
    },
    {
      "title": "jeffgeerling.com: Testing Reachy Mini - Hugging Face's Pi powered robot",
      "url": "https://www.jeffgeerling.com/blog/2026/testing-reachy-mini-hugging-face-robot/",
      "source": "jeffgeerling.com",
      "time": "2026-02-23T12:43:10.565660",
      "raw_desc": ""
    },
    {
      "title": "《极客湾曝光手机厂商媒体送测机乱象》的视频目前在 B 站已被下架",
      "url": "https://www.v2ex.com/t/1193478",
      "source": "V2EX",
      "time": "2026-02-23T12:43:10.568676",
      "raw_desc": "到底在怕什么呢？艹！！！\r\n\r\nhttps://www.bilibili.com/video/BV12mZtBTEJB\r\n\r\n补补档也同步： https://www.youtube.com/watch?v=hDambRVqOp8"
    },
    {
      "title": "请教一下稳定的 VPS 推荐。",
      "url": "https://www.v2ex.com/t/1193471",
      "source": "V2EX",
      "time": "2026-02-23T12:43:10.568676",
      "raw_desc": "最近一直用的机场跑路了，干脆想着自己搭一个，想请各位推荐一下，一定要是稳定的，感谢感谢。\r\n\r\n- **用途** ：梯子\r\n- **预算** ：250 美元/年左右\r\n- **网络环境** ：广州电信、广州移动\r\n- **基本要求** : 看 youtube 不卡，高峰时期也能保证基本的速度\r\n- **优先级** ：稳定>速度"
    },
    {
      "title": "正向思维， AI 会利好哪些岗位？",
      "url": "https://www.v2ex.com/t/1193498",
      "source": "V2EX",
      "time": "2026-02-23T12:43:10.568676",
      "raw_desc": "Ai 加持下传统软件工程里 coding 和 test 岗位（数量）确实面临压力。\r\n\r\n那么其他的岗位呢？比如架构，需求分析，运维，技术支持，售前支持等岗位，他们被 ai 冲击的部分会在哪里。\r\n\r\n架构和需求分析有可能会进一步演化成 prompt oriented 。目标是搞清楚客户要什么，转化为 ai 能执行的 prompt 。\r\n\r\n运维感觉也会受到不小的冲击。\r\n\r\n（高级）技术支持怕是主要作用是给 ai 擦屁股？分析 ai vibe 出来的代码怎么就在这个地方不管用。而售前支持则是对齐需求和既有产品颗粒度，感觉也容易被 ai 替代。"
    },
    {
      "title": "美国政府出品的机场",
      "url": "https://www.v2ex.com/t/1193519",
      "source": "V2EX",
      "time": "2026-02-23T12:43:10.568676",
      "raw_desc": "https://freedom.gov\r\n说是支持 ios ，安卓等平台，绝对匿名开源保护隐私"
    },
    {
      "title": "在 x 上看到一篇文章，贴给大家看看： Claude Code 创始人：程序员， 2026 年开始消失",
      "url": "https://www.v2ex.com/t/1193512",
      "source": "V2EX",
      "time": "2026-02-23T12:43:10.568676",
      "raw_desc": "最近，Claude Code 创始人 Boris Cherny 上了 Y Combinator 的 Lightcone 播客，聊了将近一个小时。\r\n\r\n这期访谈非常精彩。信息密度极高，爆点一个接一个。\r\n\r\n如果你是程序员，建议你认真看完。如果你不是程序员，更建议你看完——因为这件事跟每个人都有关。\r\n\r\nBoris 在访谈里说了一句话：“I think we’re going to start to see the title ‘software engineer’ go away.”“我认为我们将开始看到’软件工程师’这个头衔慢慢消失。”\r\n\r\n三年前，我用 ChatGPT 写出第一个贪吃蛇的时候，发了条朋友圈：留给人族程序员的时间不多了。\r\n\r\n当时程序员们不服气。“你懂什么叫架构吗？”“AI 写的代码一跑就崩。”“它只会写个贪吃蛇，让它写个王者荣耀试试。”\r\n\r\n三年后，Claude Code 的创始人亲口验证了这个判断。而且他说得比我激进得多。\r\n\r\n下面，我把这期访谈里最有价值的内容拆给你们看。\r\n\r\nBoris 是谁？\r\n\r\n在说他说了什么之前，先说说他是谁。\r\n\r\nBo"
    },
    {
      "title": "也许又是一个删库跑路的爽文",
      "url": "https://www.v2ex.com/t/1193513",
      "source": "V2EX",
      "time": "2026-02-23T12:43:10.568676",
      "raw_desc": "没听各位大佬的忠告啊，想到是大学同学让帮忙就没有埋雷，结果被坑了。\r\n大致流程就是技术入股->免费劳动帮程序从 php go ，迁移到 java ，期间给过几次 3 千生活费，然后去年威逼/利诱离职跟着干我看他们对技术没那么尊重，而且行业我也不看好（房地产购房小程序），就拿了几万退股，后面知道那套程序卖了 90 多，我说那有没有我的份，从合同上来看，确实是没我的份，后悔没埋雷啊。\r\n打开电脑找资料的时候，发现里面还有数据库的连接还能连上......应该是他们交接了没改密码，或者是我当初建的查询账户，总之我资料全交了，有没有合法的方法要回我的收入，还有合同里面应该备注程序之类的智慧知识产权不能专卖，坑啊，大家引以为戒。"
    },
    {
      "title": "特斯拉内推",
      "url": "https://www.v2ex.com/t/1193477",
      "source": "V2EX",
      "time": "2026-02-23T12:43:10.568676",
      "raw_desc": "特斯拉内推\r\n\r\n前后端开发，数据，算法工程师都有。\r\n\r\n企业福利\r\n\r\n15 天年假\r\n\r\nESPP 员工优惠购股\r\n\r\n足额五险一金外有额外商业保险\r\n\r\n入职有股票/现金奖励\r\n\r\n免费午餐\r\n\r\n工作地点：大部分职位在上海临港超级工厂办公，班车接送\r\n\r\n工作时间：8:30 到下午 5 点\r\n\r\nvx：LoL88880space"
    },
    {
      "title": "求推荐大手人体工学鼠标",
      "url": "https://www.v2ex.com/t/1193480",
      "source": "V2EX",
      "time": "2026-02-23T12:43:10.568676",
      "raw_desc": "第三指手长：20cm\r\n\r\n买了个京造 m3 elite ，感觉太小了，用起来手掌骨抵着还没普通鼠标用得舒服"
    },
    {
      "title": "双家庭宽带 PPPoE 拨号成功的的情况下，大家在 OpenWrt 路由器固件内是怎么分配这 2 路宽带线路的用途的？",
      "url": "https://www.v2ex.com/t/1193475",
      "source": "V2EX",
      "time": "2026-02-23T12:43:10.568676",
      "raw_desc": ""
    },
    {
      "title": "[送码]视频加密播放器,回帖即送",
      "url": "https://www.v2ex.com/t/1193532",
      "source": "V2EX",
      "time": "2026-02-23T12:43:10.568676",
      "raw_desc": "开发了一款视频加密播放器.名字叫 LockBox\r\n\r\n防录屏,防虚拟机,防注入,防采集卡.\r\n支持安卓,windows,ios,macos(不防录屏).\r\n支持多重加密追踪水印.\r\n支持多种授权方式.\r\n如果只是自己加密,自己使用或小范围使用,完全免费.\r\n\r\n欢迎有需要的朋友尝试.\r\n\r\n下载地址:https://lockbox.movingshop.cn\r\n\r\n注册后,回复注册的用户 ID 即送 10 年会员."
    },
    {
      "title": "ericmigi.com: CloudPebble Returns! Plus New Pure JavaScript and Round 2 SDK",
      "url": "https://repebble.com/blog/cloudpebble-returns-plus-pure-javascript-and-round-2-sdk",
      "source": "ericmigi.com",
      "time": "2026-02-23T12:43:10.605382",
      "raw_desc": ""
    },
    {
      "title": "ericmigi.com: February Pebble Production and Software Updates",
      "url": "https://repebble.com/blog/february-pebble-production-and-software-updates",
      "source": "ericmigi.com",
      "time": "2026-02-23T12:43:10.605382",
      "raw_desc": ""
    },
    {
      "title": "ericmigi.com: On Being A Canadian In America In 2026",
      "url": "https://ericmigi.com/blog/on-being-a-canadian-in-america-in-2026",
      "source": "ericmigi.com",
      "time": "2026-02-23T12:43:10.605382",
      "raw_desc": ""
    },
    {
      "title": "Science: NIH research grant funding rates plummeted in 2025",
      "url": "https://www.science.org/content/article/nih-research-grant-success-rates-plummeted-2025",
      "source": "Science",
      "time": "2026-02-23T12:43:10.608245",
      "raw_desc": ""
    },
    {
      "title": "Science: Trump’s NSF pick is a stranger to its research community",
      "url": "https://www.science.org/content/article/trump-s-nsf-pick-stranger-its-research-community",
      "source": "Science",
      "time": "2026-02-23T12:43:10.608245",
      "raw_desc": ""
    },
    {
      "title": "Science: New energy department science advisory committee reflects Trump’s AI push",
      "url": "https://www.science.org/content/article/new-energy-department-science-advisory-committee-reflects-trump-s-ai-push",
      "source": "Science",
      "time": "2026-02-23T12:43:10.608245",
      "raw_desc": ""
    },
    {
      "title": "Science: ChatGPT spits out surprising insight in particle physics",
      "url": "https://www.science.org/content/article/chatgpt-spits-out-surprising-insight-particle-physics",
      "source": "Science",
      "time": "2026-02-23T12:43:10.608245",
      "raw_desc": ""
    },
    {
      "title": "Science: A shocking explanation for tape’s distinctive screech",
      "url": "https://www.science.org/content/article/shocking-explanation-tape-s-distinctive-screech",
      "source": "Science",
      "time": "2026-02-23T12:43:10.608245",
      "raw_desc": ""
    },
    {
      "title": "The Lancet Digital Health: [Editorial] Large language models and misinformation",
      "url": "https://www.thelancet.com/journals/landig/article/PIIS2589-7500(25)00157-8/fulltext?rss=yes",
      "source": "The Lancet Digital Health",
      "time": "2026-02-23T12:43:10.634750",
      "raw_desc": ""
    },
    {
      "title": "The Lancet Digital Health: [Comment] Large language models need immunisation to protect against misinformation",
      "url": "https://www.thelancet.com/journals/landig/article/PIIS2589-7500(25)00160-8/fulltext?rss=yes",
      "source": "The Lancet Digital Health",
      "time": "2026-02-23T12:43:10.634750",
      "raw_desc": ""
    },
    {
      "title": "The Lancet Digital Health: [Comment] Are we heading towards a cybersecurity crisis in health care and are actions needed?",
      "url": "https://www.thelancet.com/journals/landig/article/PIIS2589-7500(25)00128-1/fulltext?rss=yes",
      "source": "The Lancet Digital Health",
      "time": "2026-02-23T12:43:10.634750",
      "raw_desc": ""
    },
    {
      "title": "The Lancet Digital Health: [Correspondence] Can generative artificial intelligence empower target trial emulations?",
      "url": "https://www.thelancet.com/journals/landig/article/PIIS2589-7500(25)00132-3/fulltext?rss=yes",
      "source": "The Lancet Digital Health",
      "time": "2026-02-23T12:43:10.634750",
      "raw_desc": ""
    },
    {
      "title": "The Lancet Digital Health: [Articles] Associations between contralesional neuroplasticity and motor impairment through deep learning-derived MRI regional brain age in chronic stroke (ENIGMA): a multicohort, retrospective, observational study",
      "url": "https://www.thelancet.com/journals/landig/article/PIIS2589-7500(25)00124-4/fulltext?rss=yes",
      "source": "The Lancet Digital Health",
      "time": "2026-02-23T12:43:10.634750",
      "raw_desc": ""
    },
    {
      "title": "NEJM: An Antibody–Oligonucleotide Conjugate for Myotonic Dystrophy Type 1",
      "url": "https://www.nejm.org/doi/full/10.1056/NEJMoa2407326?af=R&rss=currentIssue",
      "source": "NEJM",
      "time": "2026-02-23T12:43:10.790203",
      "raw_desc": ""
    },
    {
      "title": "NEJM: Hematopoietic Stem-Cell Gene Therapy for Cystinosis",
      "url": "https://www.nejm.org/doi/full/10.1056/NEJMoa2506431?af=R&rss=currentIssue",
      "source": "NEJM",
      "time": "2026-02-23T12:43:10.790203",
      "raw_desc": ""
    },
    {
      "title": "NEJM: Transcatheter or Surgical Aortic-Valve Replacement in Low-Risk Patients at 7 Years",
      "url": "https://www.nejm.org/doi/full/10.1056/NEJMoa2509766?af=R&rss=currentIssue",
      "source": "NEJM",
      "time": "2026-02-23T12:43:10.790203",
      "raw_desc": ""
    },
    {
      "title": "NEJM: Teclistamab plus Daratumumab in Relapsed or Refractory Multiple Myeloma",
      "url": "https://www.nejm.org/doi/full/10.1056/NEJMoa2514663?af=R&rss=currentIssue",
      "source": "NEJM",
      "time": "2026-02-23T12:43:10.790203",
      "raw_desc": ""
    },
    {
      "title": "NEJM: Acromegaly",
      "url": "https://www.nejm.org/doi/full/10.1056/NEJMc2518017?af=R&rss=currentIssue",
      "source": "NEJM",
      "time": "2026-02-23T12:43:10.790203",
      "raw_desc": ""
    },
    {
      "title": "simonwillison.net: The Claude C Compiler: What It Reveals About the Future of Software",
      "url": "https://simonwillison.net/2026/Feb/22/ccc/#atom-everything",
      "source": "simonwillison.net",
      "time": "2026-02-23T12:43:10.812337",
      "raw_desc": ""
    },
    {
      "title": "simonwillison.net: London Stock Exchange: Raspberry Pi Holdings plc",
      "url": "https://simonwillison.net/2026/Feb/22/raspberry-pi-openclaw/#atom-everything",
      "source": "simonwillison.net",
      "time": "2026-02-23T12:43:10.812337",
      "raw_desc": ""
    },
    {
      "title": "simonwillison.net: How I think about Codex",
      "url": "https://simonwillison.net/2026/Feb/22/how-i-think-about-codex/#atom-everything",
      "source": "simonwillison.net",
      "time": "2026-02-23T12:43:10.812337",
      "raw_desc": ""
    },
    {
      "title": "daringfireball.net: Sentry",
      "url": "https://sentry.io/resources/ios-workshop-jan-2026/?utm_source=daringfireball&utm_medium=paid-display&utm_campaign=general-fy27q1-evergreen&utm_content=static-ad-mobilerss-trysentry",
      "source": "daringfireball.net",
      "time": "2026-02-23T12:43:10.919535",
      "raw_desc": "My thanks to Sentry for sponsoring last week at DF. Sentry is running a hands-on workshop: “Crash Reporting, Tracing, and Logs for iOS in Sentry”. You can watch it on demand. You’ll learn how to connect the dots between slowdowns, crashes, and the user experience in your iOS app. It’ll show you how to:\n\nSet up Sentry to surface high-priority mobile issues without alert fatigue.\nUse Logs and Breadcrumbs to reconstruct what happened with a crash.\nFind what’s behind a performance bottleneck using Tracing.\nMonitor and reduce the size of your iOS app using Size Analysis.\n\n\n ★"
    },
    {
      "title": "daringfireball.net: IMAX and Apple Collaborate to Screen F1 Races Live in Theaters",
      "url": "https://www.motorsport.com/f1/news/f1-to-screen-live-in-imax-theatres-in-2026-as-apple-tv-unveils-new-us-viewing-experience/10798974/",
      "source": "daringfireball.net",
      "time": "2026-02-23T12:43:10.919535",
      "raw_desc": "Lydia Mee, reporting for Motorsport:\n\nIMAX has announced that a select number of races will be shown\nlive in IMAX locations across the United States in 2026. The new\nfan viewing experience is part of a collaboration with Apple TV,\nwhich has taken over the broadcasting rights for the championship\nin the US on a multi-year deal from 2026.\n“F1 is a rapidly growing force in sports and culture in the US,\nand by bringing F1 on Apple TV live to IMAX theatres nationwide,\nwe’re delivering the energy and excitement to even more screens in\na truly immersive way,” said Oliver Schusser, Apple’s vice\npresident of music, sports, and Beats.\n\nYou know what would add even more screens in an immersive way? If Vision Pro users had access to the same live screenings on virtual IMAX screens.\n\n ★"
    },
    {
      "title": "daringfireball.net: One More Spitball Idea for Apple’s March 4 Media Event ‘Experience’: Immersive F1 on Vision Pro?",
      "url": "https://www.formula1.com/en/latest/article/official-grand-prix-start-times-for-2026-f1-season-confirmed.2UgPfArqH76tzlOYh21jSG",
      "source": "daringfireball.net",
      "time": "2026-02-23T12:43:10.919535",
      "raw_desc": "A reader pointed out that the 2026 Formula 1 season starts in Australia on March 8. You will recall from October that Apple TV is now the exclusive broadcast partner for F1 in the U.S. Apple is already dabbling with live immersive sports broadcasting for VisionOS with a limited slate of Lakers games this season. If they have something planned for streaming F1 races live on Vision Pro, with some level of immersion, March 4 would be a pretty good date to demo that experience to the media.\nIt doesn’t even have to be live race coverage. Technically that’s probably impossible for this season. It would just be a sign of confidence and interest in the platform long-term merely to see some sort of immersive component to F1 on Apple TV, even if it’s not live. Like “ride the track” to experience the turns and elevation changes.\nCould just be a total coincidence that the Formula 1 season is starting the weekend after this event. But it seems worth noting.\n\n ★"
    },
    {
      "title": "idiallo.com: Nvidia was only invited to invest ",
      "url": "https://idiallo.com/byte-size/nvidia-was-only-invited-to-invest?src=feed",
      "source": "idiallo.com",
      "time": "2026-02-23T12:43:10.998355",
      "raw_desc": ""
    },
    {
      "title": "idiallo.com: Teleoperation is Always the Butt of the Joke ",
      "url": "https://idiallo.com/blog/teleoperation-is-the-butt-of-the-joke?src=feed",
      "source": "idiallo.com",
      "time": "2026-02-23T12:43:10.998355",
      "raw_desc": ""
    },
    {
      "title": "idiallo.com: Thinking Improves Thinking ",
      "url": "https://idiallo.com/blog/taking-our-mind-for-granted?src=feed",
      "source": "idiallo.com",
      "time": "2026-02-23T12:43:10.998355",
      "raw_desc": ""
    },
    {
      "title": "Product Hunt: Claude in PowerPoint",
      "url": "https://www.producthunt.com/products/claude",
      "source": "Product Hunt",
      "time": "2026-02-23T12:43:11.007544",
      "raw_desc": "Use Claude to build, edit & refine PowerPoint presentations.\n          \n\nDiscussion\n            |\n            Link"
    },
    {
      "title": "Product Hunt: Straion",
      "url": "https://www.producthunt.com/products/straion",
      "source": "Product Hunt",
      "time": "2026-02-23T12:43:11.007544",
      "raw_desc": "Manage Rules for AI Coding Agents \n          \n\nDiscussion\n            |\n            Link"
    },
    {
      "title": "Product Hunt: Wordy",
      "url": "https://www.producthunt.com/products/wordy-81fc3d1c-40c1-42d1-9a07-6c2a80ffb302",
      "source": "Product Hunt",
      "time": "2026-02-23T12:43:11.007544",
      "raw_desc": "Learn languages from real movie and TV clips with quizzes\n          \n\nDiscussion\n            |\n            Link"
    },
    {
      "title": "Product Hunt: Tidy",
      "url": "https://www.producthunt.com/products/tidy-3",
      "source": "Product Hunt",
      "time": "2026-02-23T12:43:11.007544",
      "raw_desc": "A personal assistant that can learn to use any app you use\n          \n\nDiscussion\n            |\n            Link"
    },
    {
      "title": "Product Hunt: Woise",
      "url": "https://www.producthunt.com/products/woise-2",
      "source": "Product Hunt",
      "time": "2026-02-23T12:43:11.008103",
      "raw_desc": "AI Voice & Screen Recording Tool for Websites\n          \n\nDiscussion\n            |\n            Link"
    },
    {
      "title": "Product Hunt: git-lrc",
      "url": "https://www.producthunt.com/products/git-lrc",
      "source": "Product Hunt",
      "time": "2026-02-23T12:43:11.008103",
      "raw_desc": "Free, unlimited AI code reviews that run on commit\n          \n\nDiscussion\n            |\n            Link"
    },
    {
      "title": "Product Hunt: WANotifier ",
      "url": "https://www.producthunt.com/products/wanotifier",
      "source": "Product Hunt",
      "time": "2026-02-23T12:43:11.008103",
      "raw_desc": "All-in-one WhatsApp marketing & automation tool\n          \n\nDiscussion\n            |\n            Link"
    },
    {
      "title": "Product Hunt: Rork Max",
      "url": "https://www.producthunt.com/products/rork-app-for-ios",
      "source": "Product Hunt",
      "time": "2026-02-23T12:43:11.009159",
      "raw_desc": "Best AI for iOS apps. Website that replaces Xcode\n          \n\nDiscussion\n            |\n            Link"
    },
    {
      "title": "Product Hunt: Prism Videos",
      "url": "https://www.producthunt.com/products/prism-videos",
      "source": "Product Hunt",
      "time": "2026-02-23T12:43:11.009159",
      "raw_desc": "A unified workspace to generate and edit AI videos \n          \n\nDiscussion\n            |\n            Link"
    },
    {
      "title": "Product Hunt: Lyria 3 by Google Deepmind",
      "url": "https://www.producthunt.com/products/lyria-3-by-google-deepmind",
      "source": "Product Hunt",
      "time": "2026-02-23T12:43:11.009159",
      "raw_desc": "Turn any photo or thought into a custom song inside Gemini\n          \n\nDiscussion\n            |\n            Link"
    },
    {
      "title": "devblogs.microsoft.com/oldnewthing: The 2026/2027 Seattle Symphony subscription season at a glance",
      "url": "https://devblogs.microsoft.com/oldnewthing/20260220-01/?p=112076",
      "source": "devblogs.microsoft.com/oldnewthing",
      "time": "2026-02-23T12:43:11.053870",
      "raw_desc": ""
    },
    {
      "title": "devblogs.microsoft.com/oldnewthing: Customizing the ways the dialog manager dismisses itself: Detecting the ESC key, first (failed) attempt",
      "url": "https://devblogs.microsoft.com/oldnewthing/20260220-00/?p=112074",
      "source": "devblogs.microsoft.com/oldnewthing",
      "time": "2026-02-23T12:43:11.053870",
      "raw_desc": ""
    },
    {
      "title": "devblogs.microsoft.com/oldnewthing: Exploring the signals the dialog manager uses for dismissing a dialog",
      "url": "https://devblogs.microsoft.com/oldnewthing/20260219-00/?p=112072",
      "source": "devblogs.microsoft.com/oldnewthing",
      "time": "2026-02-23T12:43:11.053870",
      "raw_desc": ""
    },
    {
      "title": "seangoedecke.com: LLM-generated skills work, if you generate them afterwards",
      "url": "https://seangoedecke.com/generate-skills-afterwards/",
      "source": "seangoedecke.com",
      "time": "2026-02-23T12:43:11.641754",
      "raw_desc": ""
    },
    {
      "title": "seangoedecke.com: Two different tricks for fast LLM inference",
      "url": "https://seangoedecke.com/fast-llm-inference/",
      "source": "seangoedecke.com",
      "time": "2026-02-23T12:43:11.641754",
      "raw_desc": ""
    },
    {
      "title": "seangoedecke.com: On screwing up",
      "url": "https://seangoedecke.com/screwing-up/",
      "source": "seangoedecke.com",
      "time": "2026-02-23T12:43:11.641754",
      "raw_desc": ""
    },
    {
      "title": "mitchellh.com: My AI Adoption Journey",
      "url": "https://mitchellh.com/writing/my-ai-adoption-journey",
      "source": "mitchellh.com",
      "time": "2026-02-23T12:43:11.732682",
      "raw_desc": ""
    },
    {
      "title": "mitchellh.com: Don't Trip[wire] Yourself: Testing Error Recovery in Zig",
      "url": "https://mitchellh.com/writing/tripwire",
      "source": "mitchellh.com",
      "time": "2026-02-23T12:43:11.732682",
      "raw_desc": ""
    },
    {
      "title": "mitchellh.com: Finding and Fixing Ghostty's Largest Memory Leak",
      "url": "https://mitchellh.com/writing/ghostty-memory-leak-fix",
      "source": "mitchellh.com",
      "time": "2026-02-23T12:43:11.732682",
      "raw_desc": ""
    },
    {
      "title": "huggingface /skills",
      "url": "https://github.com/huggingface/skills",
      "source": "GitHub",
      "time": "2026-02-23T12:43:11.845535",
      "raw_desc": ""
    },
    {
      "title": "vxcontrol /pentagi",
      "url": "https://github.com/vxcontrol/pentagi",
      "source": "GitHub",
      "time": "2026-02-23T12:43:11.845535",
      "raw_desc": "✨ Fully autonomous AI Agents system capable of performing complex penetration testing tasks"
    },
    {
      "title": "anthropics /claude-code",
      "url": "https://github.com/anthropics/claude-code",
      "source": "GitHub",
      "time": "2026-02-23T12:43:11.845535",
      "raw_desc": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands."
    },
    {
      "title": "x1xhlol /system-prompts-and-models-of-ai-tools",
      "url": "https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools",
      "source": "GitHub",
      "time": "2026-02-23T12:43:11.845535",
      "raw_desc": "FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, Dia & v0. (And other Open Sourced) System Prompts, Internal Tools & AI Models"
    },
    {
      "title": "Stremio /stremio-web",
      "url": "https://github.com/Stremio/stremio-web",
      "source": "GitHub",
      "time": "2026-02-23T12:43:11.846042",
      "raw_desc": "Stremio - Freedom to Stream"
    },
    {
      "title": "OpenBB-finance /OpenBB",
      "url": "https://github.com/OpenBB-finance/OpenBB",
      "source": "GitHub",
      "time": "2026-02-23T12:43:11.846042",
      "raw_desc": "Financial data platform for analysts, quants and AI agents."
    },
    {
      "title": "cloudflare /agents",
      "url": "https://github.com/cloudflare/agents",
      "source": "GitHub",
      "time": "2026-02-23T12:43:11.846042",
      "raw_desc": "Build and deploy AI Agents on Cloudflare"
    },
    {
      "title": "abhigyanpatwari /GitNexus",
      "url": "https://github.com/abhigyanpatwari/GitNexus",
      "source": "GitHub",
      "time": "2026-02-23T12:43:11.846042",
      "raw_desc": "GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration"
    },
    {
      "title": "stan-smith /FossFLOW",
      "url": "https://github.com/stan-smith/FossFLOW",
      "source": "GitHub",
      "time": "2026-02-23T12:43:11.846042",
      "raw_desc": "Make beautiful isometric infrastructure diagrams"
    },
    {
      "title": "maurycyz.com: Inside an alpha-beta scintillator:",
      "url": "https://maurycyz.com/misc/ah_teardown/",
      "source": "maurycyz.com",
      "time": "2026-02-23T12:43:11.919963",
      "raw_desc": ""
    },
    {
      "title": "maurycyz.com: Notes on blog future-proofing",
      "url": "https://maurycyz.com/misc/futureproofing/",
      "source": "maurycyz.com",
      "time": "2026-02-23T12:43:11.919963",
      "raw_desc": ""
    },
    {
      "title": "maurycyz.com: Writing my own static site generator",
      "url": "https://maurycyz.com/misc/new_ssg/",
      "source": "maurycyz.com",
      "time": "2026-02-23T12:43:11.919963",
      "raw_desc": ""
    },
    {
      "title": "dynomight.net: Heritability of human life span is about 50% when heritability is redefined to be something different",
      "url": "https://dynomight.net/lifespan/",
      "source": "dynomight.net",
      "time": "2026-02-23T12:43:12.298422",
      "raw_desc": "How heritable is hair color? Well, if you’re a redhead and you have an identical twin, they will definitely also be a redhead. But the age at which twins go gray seems to vary a bit based on lifestyle. And there’s some randomness in where melanocytes end up on your skull when you’re an embryo. And your twin might dye their hair! So the correct answer is, some large number, but less than 100%.\nOK, but check this out: Say I redefine “hair color” to mean “hair color except ignoring epigenetic and embryonic stuff and pretending that no one ever goes gray or dyes their hair et cetera”. Now, hair color is 100% heritable. Amazing, right?\nOr—how heritable is IQ? The wise man answers, “Some number between 0% or 100%, it’s not that important, please don’t yell at me.” But whatever the number is, it depends on society. In our branch of the multiverse, some kids get private tutors and organic food and $20,000 summer camps, while other kids get dysfunctional schools and lead paint and summers spent drinking Pepsi and staring at glowing rectangles. These things surely have at least some impact on IQ.\nBut again, watch this: Say I redefine “IQ” to be “IQ in some hypothetical world where every kid got exactly the same school, nutrition, and parenting, so none of those non-genetic factors matter anymore.” Suddenly, the heritability of IQ is higher. Thrilling, right? So much science.\nIf you want to redefine stuff like this… that’s not wrong. I mean, heritability is a pretty arbitrary concept to start with. So if you prefer to talk about heritability in some other world instead of our actual world, who am I to judge?\nIncidentally, here’s a recent paper:\n\nI STRESS THAT THIS IS A PERFECTLY FINE PAPER. I’m picking on it mostly because it was published in Science, meaning—like all Science papers—it makes grand claims but is woefully vague about what those claims mean or what was actually done. Also, publishing in Science is morally wrong and/or makes me envious. So I thought I’d try to explain what’s happening.\nIt’s actually pretty simple. At least, now that I’ve spent several hours reading the paper and its appendix over and over again, I’ve now convinced myself that it’s pretty simple. So, as a little pedagogical experiment, I’m going to try to explain the paper three times, with varying levels of detail.\nExplanation 1: The very extremely high level picture\nThe normal way to estimate the heritability of lifespan is using twin data. Depending on what dataset you use, this will give 23-35%. This paper built a mathematical model that tries to simulate how long people would live in a hypothetical world in which no one dies from any non-aging related cause, meaning no car accidents, no drug overdoses, no suicides, no murders, and no (non-age-related) infectious disease. On that simulated data, for simulated people in a hypothetical world, heritability was 46-57%.\nCommentary\nEveryone seems to be interpreting this paper as follows:\n\nAha! We thought the heritability of lifespan was 23-35%. But it turns out that it’s around 50%. Now we know!\n\nI understand this. Clearly, when the editors at Science chose the title for this paper, their goal was to lead you to that conclusion. But this is not what the paper says. What it says is this:\n\nWe built a mathematical model of alternate universe in which nobody died from accidents, murder, drug overdoses, or infectious disease. In that model, heritability was about 50%.\n\nExplanation 2: The very high-level picture\nLet’s start over. Here’s figure 2 from the paper.\n\nNormally, heritability is estimated from twin studies. The idea is that identical twins share 100% of their DNA, while fraternal twins share only 50%. So if some trait is more correlated among identical twins than among fraternal twins, that suggests DNA influences that trait. There are statistics that formalize this intuition. Given a dataset that records how long various identical and fraternal twins lived, these produce a heritability number.\nTwo such traditional estimates appear as black circles in the above figures. For the Danish twin cohort, lifespan is estimated to be 23% heritable. For the Swedish cohort, it’s 35%.\nThis paper makes a “twin simulator”. Given historical data, they fit a mathematical model to simulate the lifespans of “new” twins. Then they compute heritability on this simulated data.\nWhy calculate heritability on simulated data instead of real data? Well, their mathematical model contains an “extrinsic mortality” parameter, which is supposed to reflect the chance of death due to all non-aging-related factors like accidents, murder, or infectious disease. They assume that the chance someone dies from any of this stuff is constant over people, constant over time, and that it accounts for almost all deaths for people aged between 15 and 40.\nThe point of building the simulator is that it’s possible to change extrinsic mortality. That’s what’s happening in the purple curves in the above figure. For a range of different extrinsic mortality parameters, they simulate datasets of twins. For each simulated dataset, they estimate heritability just like with a real dataset.\nNote that the purple curves above nearly hit the black circles. This means that if they run their simulator with extrinsic mortality set to match reality, they get heritability numbers that line up with what we get from real data. That suggests their mathematical model isn’t totally insane.\nIf you decrease extrinsic mortality, then you decrease the non-genetic randomness in how long people live. So heritability goes up. Hence, the purple curves go up as you go to the left.\nIntermission: On Science\nMy explanation of this paper relies on some amount of guesswork. For whatever reason, Science has decided that papers should contain almost no math, even when the paper in question is about math. So I’m mostly working from an English description. But even that description isn’t systematic. There’s no place that clearly lays out all the things they did, in order. Instead, you get little hints, sort of randomly distributed throughout the paper. There’s an appendix, which the paper confidently cites over and over. But if you actually read the appendix, it’s just more disconnected explanations of random things except now with equations set in glorious Microsoft Word format.\nNow, in most journals, authors write everything. But Science has professional editors. Given that every single statistics-focused paper in Science seems to be like this, we probably shouldn’t blame the authors of this one. (Other than for their decision to publish in Science in the first place.)\nI do wonder what those editors are doing, though. I mean, let me show you something. Here’s the first paragraph where they start to actually explain what they actually did, from the first page:\n\nSee that h(t,θ) at the end? What the hell is that, you ask? That’s a good question, because it was never introduced before this and is never mentioned again. I guess it’s just supposed to be f(t,θ), which is fine. (I yield to none in my production of typos.) But if paying journals ungodly amounts of money brought us to this, of what use are those journals?\nMoving on…\nExplanation 3: Also pretty high level, but as low as we’re doing to go\nProbably most people don’t need this much detail and should skip this section. For everyone else, let’s start over one last time.\nThe “normal” way to estimate heritability is by looking at correlations between different kinds of twins. Intuitively, if the lifespans of identical twins are more correlated than the lifespans of fraternal twins, that suggests lifespan is heritable. And it turns out that one estimator for heritability is “twice the difference between the correlation among identical twins and the correlation among fraternal twins, all raised together.” There are other similar estimators for other kinds of twins. These normally say lifespan is perhaps 20% and 35% heritable.\nThis paper created an equation to model the probability a given person will die at a given age. The parameters of the equation vary from person to person, reflecting that some of us have DNA that predisposes us to live longer than others. But the idea is that the chances of dying are fairly constant between the ages of 15 and 40, after which they start increasing.\nThis equation contains an “extrinsic mortality” parameter. This is meant to reflect the chance of death due to all non-aging related factors like accidents or murder, etc. They assume this is constant. (Constant with respect to people and constant over time.) Note that they don’t actually look at any data on causes of death. They just add a constant risk of death that’s shared by all people at all ages to the equation, and then they call this “extrinsic mortality”.\nNow remember, different people are supposed to have different parameters in their probability-of-death equations. To reflect this, they fit a Gaussian distribution (bell curve) to the parameters with the goal of making it fit with historical data. The idea is that if the distribution over parameters were too broad, you might get lots of people dying at 15 or living until 120, which would be wrong. If the distribution were too concentrated, then you might get everyone dying at 43, which would also be wrong. So they find a good distribution, one that makes the ages people die in simulation look like the ages people actually died in historical data.\nRight! So now they have:\n\nAn equation that’s supposed to reflect the probability a given person dies at a given age.\nA distribution over the parameters of that equation that’s supposed to produce population-wide death ages that look like those in real historical data.\n\nBefore moving on, I remind you of two things:\n\nThey assume their death equation entirely determines the probability someone will die in a given year.\nThey assume that the shape of someone’s death equation is entirely determined by genetics.\n\nThe event of a person dying at a given age is random. But the probability that this happens is assumed to be fixed and determined by genes and genes alone.\nNow they simulate different kinds of twins. To simulate identical twins, they just draw parameters from their parameter distribution, assign those parameters to two different people, and then let them randomly die according to their death equation. (Is this getting morbid?) To simulate fraternal twins, they do the same thing, except instead of giving the two twins identical parameters, they give them correlated parameters, to reflect that they share 50% of their DNA.\nHow exactly do they create those correlated parameters? They don’t explain this in the paper, and they’re quite vague in the supplement. As far as I can tell they sample two sets of parameters from their parameter distribution such that the parameters are correlated at a level of 0.5.\nNow they have simulated twins. They can simulate them with different extrinsic mortality values. If they lower extrinsic mortality, heritability of lifespan goes up. If they lower it to zero, heritability goes up to around 50%.\nMore commentary\nAlmost all human traits are partly genetic and partly due to the environment and/or random. If you could change the world and reduce the amount of randomness, then of course heritability would go up. That’s true for life expectancy just life for anything else. So what’s the point of this paper?\nThere is a point!\n\n\nSure, obviously heritability would be higher in a world without accidents or murder. We don’t need a paper to know that. But how much higher? It’s impossible to say without modeling and simulating that other world.\n\n\nOur twin datasets are really old. It’s likely that non-aging-related deaths are lower now in the past, because we have better healthcare and so on. This means that the heritability of lifespan for people alive today may be larger than it was for the people in our twin datasets, some of whom were born in 1870. We won’t know for sure until we’re all dead, but this paper gives us a way to guess.\n\n\nHave I mentioned that heritability depends on society? And that heritability changes when society changes? And that heritability is just a ratio and you should stop trying to make it be a non-ratio because only-ratio things cannot be non-ratios? This is a nice reminder.\n\n\nHonestly, I think the model the paper built is quite clever. Nothing is perfect, but I think this is a pretty good run at the question of, “How high would the heritability of lifespan be if extrinsic mortality were lower?”\nI only have two objections. The first is to the Science writing style. This is a paper describing a statistical model. So shouldn’t there be somewhere in the paper where they explain exactly what they did, in order, from start to finish? Ostensibly, I think this is done in the left-hand column on the second page, just with little detail because Science is written for a general audience. But personally I think that description is the worst of all worlds. Instead of giving the high-level story in a coherent way, it throws random technical details at you without enough information to actually make sense of them. Couldn’t the full story with the full details at least be in the appendix? I feel like this wasted hours of my time, and that if someone wanted to reproduce this work, they would have almost no chance of doing so from the description given. How have we as a society decided that we should take our “best” papers and do this to them?\nBut my main objection is this:\n\nAt first, I thought this was absurd. The fact that people die in car accidents is not a “confounding factor”. And pretending that no one dies in a car accidents does not “address” some kind of bias. That’s just computing heritability in some other world. Remember, heritability is not some kind of Platonic form. It is an observational statistic. There is no such thing as “true” heritability, independent of the contingent facts of our world.\nBut upon reflection, I think they’re trying to say something like this:\n\nHeritability of human lifespan is about 50% when extrinsic mortality is adjusted to be closer to modern levels.\n\nThe problem is: I think this is… not true? Here are the actual heritability estimates in the paper, varying by dataset (different plots) the cutoff year (colors) and extrinsic mortality (x-axis).\n\nWhen extrinsic mortality goes down, heritability goes up. So the obvious question is: What is extrinsic mortality in modern people?\nThis is a tricky question, because “extrinsic mortality” isn’t some simple observational statistic. It is a parameter in their model. (Remember, they never looked at causes of death.) So it’s hard to say, but they seem to suggest that extrinsic mortality in modern people is 0.001 / year, or perhaps a bit less.\nThe above figures have the base-10 logarithm of extrinsic mortality on the x-axis. And the base-10 logarithm of 0.001 is -3. But if you look at the curves when the x-axis is -3, the heritability estimates are not 50%. They’re more like 35-45%, depending on the particular model and age cutoff.\nSo here’s my suggested title:\n\nHeritability of human lifespan is about 40% when extrinsic mortality is adjusted to modern levels, according to our simulation.\n\nThere might be a reason I don’t work at Science."
    },
    {
      "title": "dynomight.net: Why read novels?",
      "url": "https://dynomight.net/novels/",
      "source": "dynomight.net",
      "time": "2026-02-23T12:43:12.300242",
      "raw_desc": "Why should you read novels? We tell children they’re magic carpets for the mind / exercise for the soul instead of the body / lighthouses in the great sea of time. But aren’t they ultimately a form of entertainment?\nMany years ago, I read Crime and Punishment. Here, with no research and no notes, is what I can remember about that book:\n\nIt was pretty good.\nThere was some guy, I think named Ras-something.\nHe was really angsty/edgy and lived in a small apartment or attic.\nOne day, for no particular reason, he killed an old woman.\nHaving done this random murder, he became even more angsty/edgy.\nThen there was this police inspector guy.\nThe inspector kept coming after Ras-whoever and making extremely long philosophical rants.\nThose rants may or may not have represented the personal views of Fyodor Dostoevsky.\nI can’t remember how the book ended. Surely Ras-whoever didn’t live happily ever after? But was he caught or did he confess? No idea.\n\nThis is probably below average. I know people who seem to remember every detail of everything they read. But even if you’re one of them, so what? Is remembering those books better than remembering whatever else you would have done with your time if you hadn’t been reading?\nAnd yet: If I’m on vacation and I spend an afternoon reading a novel where in the mountains or on a beach, I feel like I’m living my best life. Whereas if I spent an afternoon staring at short videos on my phone, I’m sure I’d feel like a gigantic loser. So what’s going on here?\nTheory 1: Ye olde status\nThe obvious explanation is that there’s nothing intrinsically great about reading novels. The reason we think it’s great is that reading novels—at least the right ones—is high status. It’s a way of playing the Glass Bead Game, a way of collecting cultural capital for you to lord over other people who don’t have as much time or education as you do. It may feel like you “actually enjoy reading”, but that’s because you’re a desperate striver that subconsciously shape-shifts into whatever you think will make you look fancy. Apologize for reading. Apologize!\nI think there is something in this. However, I’m also pretty sure it’s not the full explanation, and I’m bored to death with everyone trying to explain everything this way. So let’s move on.\nTheory 2: Diminishing returns\nSay you can’t read novels. Maybe because you’re illiterate, maybe because you have no attention span, maybe because you can’t tear yourself away from Candy Clicker. Now, say you cultivate the ability to read novels. Whatever issues you address in that process, it seems like it will clearly be good for you, right?\nUnder this theory, what’s important is having the ability to read novels. But said ability is acquired by reading novels, so read some novels.\nAlternatively, say you could read novels, but you simply never have. It’s plausible that the first time you have the “novel” experience of taking photons into your eyes and mentally converting them into a story, this truly does feed your mind.\nBoth versions of this theory suggest that reading novels has diminishing returns. That fits nicely with the fact that many people push their children to read novels while not reading any themselves. But do we really believe that after you’ve read some number of novels, it’s pointless to read more?\nTheory 3: Common language\nI think Catcher in the Rye is a good but not great book. But I love talking about Catcher in the Rye because (1) all North Americans seem to have read it, and (2) whenever I ask someone to tell me how they feel about Holden Caulfield, I always seem to learn something about them.\n(I find him sympathetic.)\nIf there’s a group of people talking about Catcher in the Rye—or The Three-Body Problem, or Infinite Jest, or Don Quixote—then you benefit from being able to participate. The cynic might argue that this is zero-sum status competition. But I don’t think that’s most of it. Because, at least in my social circles, people feel boorish talking about books if not everyone has read them. So these conversations only happen if everyone has read the book in question.\nUltimately, we’re all alone in the world, and trying to connect with each other by pushing air through our throat meat. With more shared cultural context, those meat sounds are more meaningful, so we can all feel less alone.\nTrue. But shared context can come from other things, too, like traveling to the same places, or watching the same sports, or practicing the same skills or hobbies. So what makes books special? The two answers I see are:\n\nNothing. If you think they’re better than other types of cultural context, that’s because you’re a book person.\nBooks leave more room for interpretation. Maybe Don Quixote is a fanatic, maybe he’s an idealist, maybe he’s a “wise fool”. It’s debatable. But there’s no doubt who won the last World Cup.\n\nI lean weakly towards the first answer. Novels are a useful form of social context. But that’s a side benefit. It’s not why we read most books.\nTheory 4: Legible mind-space\nMaybe novels are just another form of entertainment. OK. But say you tried to tell the same story as a novel or as movie / podcast / opera / interpretive dance performance. Different formats will be better in different ways. One advantage I see for novels is that they make it natural to explore the interior worlds of the characters.\nSome movies have voice-overs where characters explain what they’re thinking. But this is generally considered cringe and a poor use of the medium. Meanwhile, many books are mostly about exploring what the characters are thinking.\nThoughts are worth exploring. If you want to explore thoughts, maybe novels are the best way to do that.\nAside: I’ve mentioned before that I think My Brilliant Friend is the best TV show ever made. Can I confess that I like it much more than the books it is based on? Because, like the books, the TV show involves a lot of what the main character is thinking, and even makes heavy use of voice-overs. So maybe other mediums have unrealized potential?\nTheory 5: Purity of vision\nMovies are expensive to make. To be financially viable, they need to target a large slice of the population. Movies also reflect the combined efforts of many people. Both of these mean that movies are a compromise between different visions.\nNovels are usually written by one person. And they’re often written more for personal expression than to make money. After all, writing is fun. I mean—writing is hard, but would you rather spend an afternoon holding up a shotgun microphone, cleaning a movie star’s trailer, or writing a novel?\nTo quantify this, some searching suggests that around 10,000 feature films are released each year, as compared to around 1,000,000 novels. (Does one in 7,000 people really write a novel each year?) That’s two orders of magnitude. So if you want to hear a truly unique story, a pure vision of one person, maybe novels are where you’ll find it.\nTheory 6: All these theories are stupid\nOr: Maybe the point of reading War and Peace is that War and Peace is incredible and obviously one of the greatest pieces of art ever made in any medium. No one who reads War and Peace can question the value of what they’ve done. What are we talking about?\nFair. I definitely feel like I’m living my best life when I read War and Peace. But I also feel like I’m living an OK-ish life when I read a novel about Spenser, private investigator. And most novels most people read are closer to the Spenser than to War and Peace. And I still feel better spending an afternoon reading about Spenser than I would watching 99% of TV shows.\nTheory 7: Dopamine\nOr perhaps the difference is that reading is a thing you do rather than something you consume.\nThis theory holds than when spend an hour slurping up short-form video, you’re training yourself to sort of pull a lever in the hope that some reward is delivered to you. But if you read (or do watercolors, or meditate) you’re training yourself to calmly pursue long-term goals and to sustain attention in the face of complexity.\nSometimes I wonder if phones/apps are the most addictive thing ever created. I suspect that more people today are addicted to their phones today than were ever addicted to any drug other than caffeine or perhaps nicotine. And while a phone addiction is less physically harmful than tobacco, that phone addiction will eat a larger part of your soul.\nI think this is a big part of the explanation.\nTheory 8: Non-fungible time\nIn the end, I don’t think novels are the best way to spend your time. In my view no novel—not even War and Peace—is as good as a truly great conversation.\nBut great conversations are hard to create. Sometimes you’re sitting on a train, or laying in bed, or it’s just been a long day and you don’t have the energy to find a giant block of marble and pursue your dream of experimental sculpture. In these situations, maybe reading a novel is the best thing you could do in the category of things you could realistically do.\nExercise for the reader: Apply these theories to blog posts."
    },
    {
      "title": "dynomight.net: Good if make prior after data instead of before",
      "url": "https://dynomight.net/prior/",
      "source": "dynomight.net",
      "time": "2026-02-23T12:43:12.309445",
      "raw_desc": "They say you’re supposed to choose your prior in advance. That’s why it’s called a “prior”. First, you’re supposed to say say how plausible different things are, and then you update your beliefs based on what you see in the world.\nFor example, currently you are—I assume—trying to decide if you should stop reading this post and do something else with your life. If you’ve read this blog before, then lurking somewhere in your mind is some prior for how often my posts are good. For the sake of argument, let’s say you think 25% of my posts are funny and insightful and 75% are boring and worthless.\n\nOK. But now here you are reading these words. If they seem bad/good, then that raises the odds that this particular post is worthless/non-worthless. For the sake of argument again, say you find these words mildly promising, meaning that a good post is 1.5× more likely than a worthless post to contain words with this level of quality.\n\nIf you combine those two assumptions, that implies that the probability that this particular post is good is 33.3%. That’s true because the red rectangle below has half the area of the blue one, and thus the probability that this post is good should be half the probability that it’s bad (33.3% vs. 66.6%)\n\n\n\n(Why half the area? Because the red rectangle is ⅓ as wide and ³⁄₂ as tall as the blue one and ⅓ × ³⁄₂ = ½. If you only trust equations, click here for equations.)\n\nIt’s easiest to calculate the ratio of the odds that the post is good versus bad, namely\nP[good | words] / P[bad | words]\n = P[good, words] / P[bad, words]\n = (P[good] × P[words | good])\n / (P[bad] × P[words | bad])\n = (0.25 × 1.5) / (0.75 × 1)\n = 0.5.\n \nIt follows that\nP[good | words] = 0.5 × P[bad | words],\n \nand thus that\nP[good | words] = 1/3.\n \nAlternatively, if you insist on using Bayes’ equation:\nP[good | words]\n = P[good] × P[words | good] / P[words]\n = P[good] × P[words | good]\n / (P[good] × P[words | good] + P[bad] × P[words | bad])\n = 0.25 × 1.5 / (0.25 × 1.5 + 0.75)\n = (1/3)\n \n\nTheoretically, when you chose your prior that 25% of dynomight posts are good, that was supposed to reflect all the information you encountered in life before reading this post. Changing that number based on information contained in this post wouldn’t make any sense, because that information is supposed to be reflected in the second step when you choose your likelihood p[good | words]. Changing your prior based on this post would amount to “double-counting”.\nIn theory, that’s right. It’s also right in practice for the above example, and for the similar cute little examples you find in textbooks.\nBut for real problems, I’ve come to believe that refusing to change your prior after you see the data often leads to tragedy. The reason is that in real problems, things are rarely just “good” or “bad”, “true” or “false”. Instead, truth comes in an infinite number of varieties. And you often can’t predict which of these varieties matter until after you’ve seen the data.\nAliens\nLet me show you what I mean. Say you’re wondering if there are aliens on Earth. As far as we know, there’s no reason aliens shouldn’t have emerged out of the random swirling of molecules on some other planet, developed a technological civilization, built spaceships, and shown up here. So it seems reasonable to choose a prior it’s equally plausible that there are aliens or that there are not, i.e. that\nP[aliens] ≈ P[no aliens] ≈ 50%.\n\n\nMeanwhile, here on our actual world, we have lots of weird alien-esque evidence, like the Gimbal video, the Go Fast video, the FLIR1 video, the Wow! signal, government reports on unidentified aerial phenomena, and lots of pilots that report seeing “tic-tacs” fly around in physically impossible ways. Call all that stuff data. If aliens weren’t here, then it seems hard to explain all that stuff. So it seems like P[data | no aliens] should be some low number.\nOn the other hand, if aliens were here, then why don’t we ever get a good image? Why are there endless confusing reports and rumors and grainy videos, but never a single clear close-up high-resolution video, and never any alien debris found by some random person on the ground? That also seems hard to explain if aliens were here. So I think P[data | aliens] should also be some low number. For the sake of simplicity, let’s call it a wash and assume that\nP[data | no aliens] ≈ P[data | aliens].\n\n\nSince neither the prior nor the data see any difference between aliens and no-aliens, the posterior probability is\nP[no aliens | data] ≈ P[aliens | data] ≈ 50%.\n\n\nSee the problem?\n\n\n(Click here for math.)\n\nObserve that\nP[aliens | data] / P[no aliens | data]\n = P[aliens, data] / P[no aliens, data]\n = (P[aliens] × P[data | aliens])\n / (P[no aliens] × P[data | no aliens])\n ≈ 1,\n \nwhere the last line follows from the fact that P[aliens] ≈ P[no aliens] and P[data | aliens] ≈ P[data | no aliens]. Thus we have that\nP[aliens | data] ≈ P[no aliens | data] ≈ 50%.\n \n\nWe’re friends. We respect each other. So let’s not argue about if my starting assumptions are good. They’re my assumptions. I like them. And yet the final conclusion seems insane to me. What went wrong?\nAssuming I didn’t screw up the math (I didn’t), the obvious explanation is that I’m experiencing cognitive dissonance as a result of a poor decision on my part to adopt a set of mutually contradictory beliefs. Say you claim that Alice is taller than Bob and Bob is taller than Carlos, but you deny that Alice is taller than Carlos. If so, that would mean that you’re confused, not that you’ve discovered some interesting paradox.\nPerhaps if I believe that P[aliens] ≈ P[no aliens] and that P[data | aliens] ≈ P[data | no aliens], then I must accept that P[aliens | data] ≈ P[no aliens | data]. Maybe rejecting that conclusion just means I have some personal issues I need to work on.\nI deny that explanation. I deny it! Or, at least, I deny that’s it’s most helpful way to think about this situation. To see why, let’s build a second model.\nMore aliens\nHere’s a trivial observation that turns out to be important: “There are aliens” isn’t a single thing. There could be furry aliens, slimy aliens, aliens that like synthwave music, etc. When I stated my prior, I could have given different probabilities to each of those cases. But if I had, it wouldn’t have changed anything, because there’s no reason to think that furry vs. slimy aliens would have any difference in their eagerness to travel to ape-planets and fly around in physically impossible tic-tacs.\nBut suppose I had divided up the state of the world into these four possibilities:\n\n\n\npossibility\ndescription\n\n\n\n\nNo aliens + normal people\nThere are no aliens. Meanwhile, people are normal and not prone to hallucinating evidence for things that don’t exist.\n\n\nNo aliens + weird people\nThere are no aliens. Meanwhile, people are weird and do tend to hallucinate evidence for things that don’t exist.\n\n\nNormal aliens\nThere are aliens. They may or may not have cool spaceships or enjoy shooting people with lasers. But one way or another, they leave obvious, indisputable evidence that they’re around.\n\n\nWeird aliens\nThere are aliens. But they stay hidden until humans get interested in space travel. And after that, they let humans take confusing grainy videos, but never a single good video, never ever, not one.\n\n\n\nIf I had broken things down that way, I might have chosen this prior:\nP[no aliens + normal people] ≈ 41%\nP[no aliens + weird people] ≈ 9%\nP[normal aliens] ≈ 49%\nP[weird aliens] ≈ 1%\n\n\nNow, let’s think about the empirical evidence again. It’s incompatible with no aliens + normal people, since if there were no aliens, then normal people wouldn’t hallucinate flying tic-tacs. The evidence is also incompatible with normal aliens since is those kinds of aliens were around they would make their existence obvious. However, the evidence fits pretty well with weird aliens and also with no aliens + weird people.\nSo, a reasonable model would be\nP[data | normal aliens] ≈ 0\t\nP[data | no aliens + normal people] ≈ 0\nP[data | weird aliens] ≈ P[data | no aliens + weird people].\n\n\nIf we combine those assumptions, now we only get a 10% posterior probability of aliens.\nP[no aliens + normal people | data] ≈ 0\nP[no aliens + weird people | data] ≈ 90%\nP[normal aliens | data] ≈ 0\nP[weird aliens | data] ≈ 10%\n\n\nNow the results seem non-insane.\n\n\n(math)\n\nTo see why, first note that\nP[normal aliens | data]\n ≈ P[data | no aliens + normal people]\n ≈ 0,\n \nsince both normal aliens and no aliens + normal people have near-zero probability of producing the observed data.\nMeanwhile,\nP[no aliens + weird people | data] / P[weird aliens | data]\n = P[no aliens + weird people, data] / P[weird aliens, data]\n ≈ P[no aliens + weird people] / P[weird aliens]\n ≈ .09 / .01\n = 9,\n \nwhere the second equality follows from the fact that the data is assumed to be equally likely under no aliens + weird people and weird people\nIt follows that\nP[no aliens + normal people | data]\n ≈ 9 × P[weird aliens | data],\n \nand so\nP[no aliens + weird people | data] ≈ 90%\nP[weird aliens | data] ≈ 10%.\n \n\nHuh?\nI hope you are now confused. If not, let me lay out what’s strange: The priors for the two above models both say that there’s a 50% chance of aliens. The first prior wasn’t wrong, it was just less detailed than the second one.\nThat’s weird, because the second prior seemed to lead to completely different predictions. If a prior is non-wrong and the math is non-wrong, shouldn’t your answers be non-wrong? What the hell?\nThe simple explanation is that I’ve been lying to you a little bit. Take any situation where you’re trying to determine the truth of anything. Then there’s some space of things that could be true.\n\nIn some cases, this space is finite. If you’ve got a single tritium atom and you wait a year, either the atom decays or it doesn’t. But in most cases, there’s a large or infinite space of possibilities. Instead of you just being “sick” or “not sick”, you could be “high temperature but in good spirits” or “seems fine except won’t stop eating onions”.\n(Usually the space of things that could be true isn’t easy to map to a small 1-D interval. I’m drawing like that for the sake of visualization, but really you should think of it as some high-dimensional space, or even an infinite dimensional space.)\nIn the case of aliens, the space of things that could be true might include, “There are lots of slimy aliens and a small number of furry aliens and the slimy aliens are really shy and the furry aliens are afraid of squirrels.” So, in principle, what you should do is divide up the space of things that might be true into tons of extremely detailed things and give a probability to each.\n\nOften, the space of things that could be true is infinite. So theoretically, if you really want to do things by the book, what you should really do is specify how plausible each of those (infinite) possibilities is.\nAfter you’ve done that, you can look at the data. For each thing that could be true, you need to think about the probability of the data. Since there’s an infinite number of things that could be true, that’s an infinite number of probabilities you need to specify. You could picture it as some curve like this:\n\n(That’s a generic curve, not one for aliens.)\nTo me, this is the most underrated problem with applying Bayesian reasoning to complex real-world situations: In practice, there are an infinite number of things that can be true. It’s a lot of work to specify prior probabilities for an infinite number of things. And it’s also a lot of work to specify the likelihood of your data given an infinite number of things.\nSo what do we do in practice? We simplify, usually by limiting creating grouping the space of things that could be true into some small number of discrete categories. For the above curve, you might break things down into these four equally-plausible possibilities.\n\nThen you might estimate these data probabilities for each of those possibilities.\n\nThen you could put those together to get this posterior:\n\nThat’s not bad. But it is just an approximation. Your “real” posterior probabilities correspond to these areas:\n\nThat approximation was pretty good. But the reason it was good is that we started out with a good discretization of the space of things that might be true: One where the likelihood of the data didn’t vary too much for the different possibilities inside of A, B, C, and D. Imagine the likelihood of the data—if you were able to think about all the infinite possibilities one by one—looked like this:\n\nThis is dangerous. The problem is that you can’t actually think about all those infinite possibilities. When you think about four four discrete possibilities, you might estimate some likelihood that looks like this:\n\nIf you did that, that would lead to you underestimating the probability of A, B, and C, and overestimating the probability of D.\nThis is where my first model of aliens went wrong. My prior P[aliens] was not wrong. (Not to me.) The mistake was in assigning the same value to P[data | aliens] and P[data | no aliens]. Sure, I think the probability of all our alien-esque data is equally likely given aliens and given no-aliens. But that’s only true for certain kinds of aliens, and certain kinds of no-aliens. And my prior for those kinds of aliens is much lower than for those kinds of non-aliens.\nTechnically, the fix to the first model is simple: Make P[data | aliens] lower. But the reason it’s lower is that I have additional prior information that I forgot to include in my original prior. If I just assert that P[data | aliens] is much lower than P[data | no aliens] then the whole formal Bayesian thing isn’t actually doing very much—I might as well just state that I think P[aliens | data] is low. If I want to formally justify why P[data | aliens] should be lower, that requires a messy recursive procedure where I sort of add that missing prior information and then integrate it out when computing the data likelihood.\n\n\n(math)\n\nMathematically,\nP[data | aliens]\n = ∫ P[wierd aliens | aliens]\n × P[data | wierd aliens] d(weird aliens)\n + ∫ P[normal aliens | aliens]\n × P[data | normal aliens] d(normal aliens).\n \nBut now I have to give a detailed prior anyway. So what was the point of starting with a simple one?\n\nI don’t think that technical fix is very good. While it’s technically correct (har-har) it’s very unintuitive. The better solution is what I did in the second model: To create a finer categorization of the space of things that might be true, such that the probability of the data is constant-ish for each term.\nThe thing is: Such a categorization depends on the data. Without seeing the actual data in our world, I would never have predicted that we would have so many pilots that report seeing tic-tacs. So I would never have predicted that I should have categories that are based on how much people might hallucinate evidence or how much aliens like to mess with us. So the only practical way to get good results is to first look at the data to figure out what categories are important, and then to ask yourself how likely you would have said those categories were, if you hadn’t yet seen any of the evidence."
    },
    {
      "title": "lcamtuf.substack.com: Unreal numbers",
      "url": "https://lcamtuf.substack.com/p/unreal-numbers",
      "source": "lcamtuf.substack.com",
      "time": "2026-02-23T12:43:12.348608",
      "raw_desc": ""
    },
    {
      "title": "lcamtuf.substack.com: It's all a blur",
      "url": "https://lcamtuf.substack.com/p/its-all-a-blur",
      "source": "lcamtuf.substack.com",
      "time": "2026-02-23T12:43:12.348608",
      "raw_desc": ""
    },
    {
      "title": "lcamtuf.substack.com: You gotta think outside the hypercube",
      "url": "https://lcamtuf.substack.com/p/you-gotta-think-outside-the-hypercube",
      "source": "lcamtuf.substack.com",
      "time": "2026-02-23T12:43:12.348608",
      "raw_desc": ""
    },
    {
      "title": "shkspr.mobi: How close are we to a vision for 2010?",
      "url": "https://shkspr.mobi/blog/2026/02/how-close-are-we-to-a-vision-for-2010/",
      "source": "shkspr.mobi",
      "time": "2026-02-23T12:43:12.390547",
      "raw_desc": ""
    },
    {
      "title": "shkspr.mobi: OpenBenches at FOSDEM",
      "url": "https://shkspr.mobi/blog/2026/02/openbenches-at-fosdem/",
      "source": "shkspr.mobi",
      "time": "2026-02-23T12:43:12.390547",
      "raw_desc": ""
    },
    {
      "title": "shkspr.mobi: Book Review: Families And How To Survive Them by John Cleese and Robin Skynner ★★⯪☆☆",
      "url": "https://shkspr.mobi/blog/2026/02/book-review-families-and-how-to-survive-them-by-john-cleese-and-robin-skynner/",
      "source": "shkspr.mobi",
      "time": "2026-02-23T12:43:12.390547",
      "raw_desc": ""
    },
    {
      "title": "xeiaso.net: Life Update: On medical leave",
      "url": "https://xeiaso.net/notes/2026/life-update-medical-leave/",
      "source": "xeiaso.net",
      "time": "2026-02-23T12:43:12.605303",
      "raw_desc": ""
    },
    {
      "title": "xeiaso.net: Anubis v1.25.0: Necron",
      "url": "https://github.com/TecharoHQ/anubis/releases/tag/v1.25.0",
      "source": "xeiaso.net",
      "time": "2026-02-23T12:43:12.605303",
      "raw_desc": ""
    },
    {
      "title": "xeiaso.net: The Discourse has been Automated",
      "url": "https://xeiaso.net/notes/2026/the-discourse-has-been-automated/",
      "source": "xeiaso.net",
      "time": "2026-02-23T12:43:12.605303",
      "raw_desc": ""
    },
    {
      "title": "lucumr.pocoo.org: The Final Bottleneck",
      "url": "https://lucumr.pocoo.org/2026/2/13/the-final-bottleneck/",
      "source": "lucumr.pocoo.org",
      "time": "2026-02-23T12:43:12.633687",
      "raw_desc": "Historically, writing code was slower than reviewing code.\nIt might not have felt that way, because code reviews sat in queues until\nsomeone got around to picking it up.  But if you compare the\nactual acts themselves, creation was usually the more expensive part.  In teams\nwhere people both wrote and reviewed code, it never felt like “we should\nprobably program slower.”\nSo when more and more people tell me they no longer know what code is in their\nown codebase, I feel like something is very wrong here and it’s time to\nreflect.\nYou Are Here\nSoftware engineers often believe that if we make the bathtub\nbigger, overflow disappears.  It doesn’t.\nOpenClaw right now has north of 2,500\npull requests open.  That’s a big bathtub.\nAnyone who has worked with queues knows this: if input grows faster than\nthroughput, you have an accumulating failure.  At that point, backpressure and\nload shedding are the only things that retain a system that can still operate.\nIf you have ever been in a Starbucks overwhelmed by mobile orders, you know the\nfeeling.  The in-store experience breaks down.  You no longer know how many\norders are ahead of you.  There is no clear line, no reliable wait estimate, and\noften no real cancellation path unless you escalate and make noise.\nThat is what many AI-adjacent open source projects feel like right now.  And\nincreasingly, that is what a lot of internal company projects feel like in\n“AI-first” engineering teams, and that’s not sustainable.  You can’t triage, you\ncan’t review, and many of the PRs cannot be merged after a certain point because\nthey are too far out of date. And the creator might have lost the motivation to\nactually get it merged.\nThere is huge excitement about newfound delivery speed, but in private\nconversations, I keep hearing the same second sentence: people are also confused\nabout how to keep up with the pace they themselves created.\nWe Have Been Here Before\nHumanity has been here before.  Many times over.  We already talk about the\nLuddites a lot in the context of AI, but it’s interesting to see what led up to\nit.  Mark Cartwright wrote a great article about the textile\nindustry\nin Britain during the industrial revolution.  At its core was a simple idea:\nwhenever a bottleneck was removed, innovation happened downstream from that.\nWeaving sped up? Yarn became the constraint. Faster spinning? Fibre needed to be\nimproved to support the new speeds until finally the demand for cotton went up\nand that had to be automated too.  We saw the same thing in shipping that led\nto modern automated ports and containerization.\nAs software engineers we have been here too.  Assembly did not scale to larger\nengineering teams, and we had to invent higher level languages.  A lot of what\nprogramming languages and software development frameworks did was allow us\nto write code faster and to scale to larger code bases.  What it did not do up\nto this point was take away the core skill of engineering.\nWhile it’s definitely easier to write C than assembly, many of the core problems\nare the same.  Memory latency still matters, physics are still our ultimate\nbottleneck, algorithmic complexity still makes or breaks software at scale.\nGiving Up?\nWhen one part of the pipeline becomes dramatically faster, you need to throttle\ninput.  Pi is a great example of this.  PRs are auto closed\nunless people are trusted.  It takes OSS\nvacations.  That’s one\noption: you just throttle the inflow.  You push against your newfound powers\nuntil you can handle them.\nOr Giving In\nBut what if the speed continues to increase?  What downstream of writing code do\nwe have to speed up?  Sure, the pull request review clearly turns into the\nbottleneck.  But it cannot really be automated.  If the machine writes the code,\nthe machine better review the code at the same time.  So what ultimately comes\nup for human review would already have passed the most critical possible review\nof the most capable machine.  What else is in the way?  If we continue with the\nfundamental belief that machines cannot be accountable, then humans need to be\nable to understand the output of the machine.  And the machine will ship\nrelentlessly.  Support tickets of customers will go straight to machines to\nimplement improvements and fixes, for other machines to review, for humans to\nrubber stamp in the morning.\nA lot of this sounds both unappealing and reminiscent of the textile industry.\nThe individual weaver no longer carried responsibility for a bad piece of cloth.\nIf it was bad, it became the responsibility of the factory as a whole and it was\njust replaced outright.  As we’re entering the phase of single-use plastic\nsoftware, we might be moving the whole layer of responsibility elsewhere.\nI Am The Bottleneck\nBut to me it still feels different.  Maybe that’s because my lowly brain can’t\ncomprehend the change we are going through, and future generations will just\nlaugh about our challenges.  It feels different to me, because what I see taking\nplace in some Open Source projects, in some companies and teams feels deeply\nwrong and unsustainable.  Even Steve Yegge himself now casts\ndoubts about the\nsustainability of the ever-increasing pace of code creation.\nSo what if we need to give in?  What if we need to pave the way for this new\ntype of engineering to become the standard?  What affordances will we have to\ncreate to make it work?  I for one do not know.  I’m looking at this with\nfascination and bewilderment and trying to make sense of it.\nBecause it is not the final bottleneck.  We will find ways to take\nresponsibility for what we ship, because society will demand it.  Non-sentient\nmachines will never be able to carry responsibility, and it looks like we will\nneed to deal with this problem before machines achieve this status.\nRegardless of how bizarre they appear to\nact already.\nI too am the bottleneck\nnow.  But you know what?\nTwo years ago, I too was the bottleneck.  I was the bottleneck all along.  The\nmachine did not really change that.  And for as long as I carry responsibilities\nand am accountable, this will remain true.  If we manage to push accountability\nupwards, it might change, but so far, how that would happen is not clear."
    },
    {
      "title": "lucumr.pocoo.org: A Language For Agents",
      "url": "https://lucumr.pocoo.org/2026/2/9/a-language-for-agents/",
      "source": "lucumr.pocoo.org",
      "time": "2026-02-23T12:43:12.641088",
      "raw_desc": "Last year I first started thinking about what the future of programming\nlanguages might look like now that agentic engineering is a growing thing.\nInitially I felt that the enormous corpus of pre-existing code would cement\nexisting languages in place but now I’m starting to think the opposite is true.\nHere I want to outline my thinking on why we are going to see more new\nprogramming languages and why there is quite a bit of space for interesting\ninnovation.  And just in case someone wants to start building one, here are some\nof my thoughts on what we should aim for!\nWhy New Languages Work\nDoes an agent perform dramatically better on a language that it has in its\nweights?  Obviously yes.  But there are less obvious factors that affect how\ngood an agent is at programming in a language: how good the tooling around it is\nand how much churn there is.\nZig seems underrepresented in the weights (at least in the models I’ve used)\nand also changing quickly.  That combination is not optimal, but it’s still\npassable: you can program even in the upcoming Zig version if you point the\nagent at the right documentation.  But it’s not great.\nOn the other hand, some languages are well represented in the weights but agents\nstill don’t succeed as much because of tooling choices.  Swift is a good\nexample: in my experience the tooling around building a Mac or iOS application\ncan be so painful that agents struggle to navigate it.  Also not great.\nSo, just because it exists doesn’t mean the agent succeeds and just because it’s\nnew also doesn’t mean that the agent is going to struggle.  I’m convinced that\nyou can build yourself up to a new language if you don’t want to depart\neverywhere all at once.\nThe biggest reason new languages might work is that the cost of coding is going\ndown dramatically.  The result is the breadth of an ecosystem matters less. I’m\nnow routinely reaching for JavaScript in places where I would have used Python.\nNot because I love it or the ecosystem is better, but because the agent does\nmuch better with TypeScript.\nThe way to think about this: if important functionality is missing in my\nlanguage of choice, I just point the agent at a library from a different\nlanguage and have it build a port.  As a concrete example, I recently built an\nEthernet driver in JavaScript to implement the host controller for our sandbox.\nImplementations exist in Rust, C, and Go, but I wanted something pluggable and\ncustomizable in JavaScript.  It was easier to have the agent reimplement it than\nto make the build system and distribution work against a native binding.\nNew languages will work if their value proposition is strong enough and they\nevolve with knowledge of how LLMs train.  People will adopt them despite being\nunderrepresented in the weights.  And if they are designed to work well with\nagents, then they might be designed around familiar syntax that is already known\nto work well.\nWhy A New Language?\nSo why would we want a new language at all?  The reason this is interesting to\nthink about is that many of today’s languages were designed with the assumption\nthat punching keys is laborious, so we traded certain things for brevity.  As an\nexample, many languages — particular modern ones — lean heavily on type\ninference so that you don’t have to write out types.  The downside is that you\nnow need an LSP or the resulting compiler error messages to figure out what the\ntype of an expression is.  Agents struggle with this too, and it’s also\nfrustrating in pull request review where complex operations can make it very\nhard to figure out what the types actually are.  Fully dynamic languages are\neven worse in that regard.\nThe cost of writing code is going down, but because we are also producing more\nof it, understanding what the code does is becoming more important.  We might\nactually want more code to be written if it means there is less ambiguity when\nwe perform a review.\nI also want to point out that we are heading towards a world where some code is\nnever seen by a human and is only consumed by machines.  Even in that case, we\nstill want to give an indication to a user, who is potentially a non-programmer,\nabout what is going on.  We want to be able to explain to a user what the code\nwill do without going into the details of how.\nSo the case for a new language comes down to: given the fundamental changes in\nwho is programming and what the cost of code is, we should at least consider\none.\nWhat Agents Want\nIt’s tricky to say what an agent wants because agents will lie to you and they\nare influenced by all the code they’ve seen.  But one way to estimate how they\nare doing is to look at how many changes they have to perform on files and how\nmany iterations they need for common tasks.\nThere are some things I’ve found that I think will be true for a while.\nContext Without LSP\nThe language server protocol lets an IDE infer information about what’s under\nthe cursor or what should be autocompleted based on semantic knowledge of the\ncodebase.  It’s a great system, but it comes at one specific cost that is tricky\nfor agents: the LSP has to be running.\nThere are situations when an agent just won’t run the LSP — not because of\ntechnical limitations, but because it’s also lazy and will skip that step if it\ndoesn’t have to.  If you give it an example from documentation, there is no easy\nway to run the LSP because it’s a snippet that might not even be complete.  If\nyou point it at a GitHub repository and it pulls down individual files, it will\njust look at the code.  It won’t set up an LSP for type information.\nA language that doesn’t split into two separate experiences (with-LSP and\nwithout-LSP) will be beneficial to agents because it gives them one unified way\nof working across many more situations.\nBraces, Brackets, and Parentheses\nIt pains me as a Python developer to say this, but whitespace-based indentation\nis a problem.  The underlying token efficiency of getting whitespace right is\ntricky, and a language with significant whitespace is harder for an LLM to work\nwith.  This is particularly noticeable if you try to make an LLM do surgical\nchanges without an assisted tool.  Quite often they will intentionally disregard\nwhitespace, add markers to enable or disable code and then rely on a code\nformatter to clean up indentation later.\nOn the other hand, braces that are not separated by whitespace can cause issues\ntoo.  Depending on the tokenizer, runs of closing parentheses can end up split\ninto tokens in surprising ways (a bit like the “strawberry” counting problem),\nand it’s easy for an LLM to get Lisp or Scheme wrong because it loses track of\nhow many closing parentheses it has already emitted or is looking at.  Fixable\nwith future LLMs?  Sure, but also something that was hard for humans to get\nright too without tooling.\nFlow Context But Explicit\nReaders of this blog might know that I’m a huge believer in async locals and\nflow execution context — basically the ability to carry data through every\ninvocation that might only be needed many layers down the call chain.  Working\nat an observability company has really driven home the importance of this for\nme.\nThe challenge is that anything that flows implicitly might not be configured.\nTake for instance the current time.  You might want to implicitly pass a timer\nto all functions.  But what if a timer is not configured and all of a sudden a\nnew dependency appears?  Passing all of it explicitly is tedious for both humans\nand agents and bad shortcuts will be made.\nOne thing I’ve experimented with is having effect markers on functions that are\nadded through a code formatting step.  A function can declare that it needs the\ncurrent time or the database, but if it doesn’t mark this explicitly, it’s\nessentially a linting warning that auto-formatting fixes.  The LLM can start\nusing something like the current time in a function and any existing caller gets\nthe warning; formatting propagates the annotation.\nThis is nice because when the LLM builds a test, it can precisely mock out\nthese side effects — it understands from the error messages what it has to\nsupply.\nFor instance:\nfn issue(sub: UserId, scopes: []Scope) -> Token\n    needs { time, rng }\n{\n    return Token{\n        sub,\n        exp: time.now().add(24h),\n        scopes,\n    }\n}\n\ntest \"issue creates exp in the future\" {\n    using time = time.fixed(\"2026-02-06T23:00:00Z\");\n    using rng  = rng.deterministic(seed: 1);\n\n    let t = issue(user(\"u1\"), [\"read\"]);\n    assert(t.exp > time.now());\n}\n\nResults over Exceptions\nAgents struggle with exceptions, they are afraid of them.  I’m not sure to what\ndegree this is solvable with RL (Reinforcement Learning), but right now agents\nwill try to catch everything they can, log it, and do a pretty poor recovery.\nGiven how little information is actually available about error paths, that makes\nsense.  Checked exceptions are one approach, but they propagate all the way up\nthe call chain and don’t dramatically improve things.  Even if they end up as\nhints where a linter tracks which errors can fly by, there are still many call\nsites that need adjusting.  And like the auto-propagation proposed for context\ndata, it might not be the right solution.\nMaybe the right approach is to go more in on typed results, but that’s still\ntricky for composability without a type and object system that supports it.\nMinimal Diffs and Line Reading\nThe general approach agents use today to read files into memory is line-based,\nwhich means they often pick chunks that span multi-line strings.  One easy way\nto see this fall apart: have an agent work on a 2000-line file that also\ncontains long embedded code strings — basically a code generator.  The agent\nwill sometimes edit within a multi-line string assuming it’s the real code when\nit’s actually just embedded code in a multi-line string.  For multi-line\nstrings, the only language I’m aware of with a good solution is Zig, but its\nprefix-based syntax is pretty foreign to most people.\nReformatting also often causes constructs to move to different lines.  In many\nlanguages, trailing commas in lists are either not supported (JSON) or not\ncustomary.  If you want diff stability, you’d aim for a syntax that requires\nless reformatting and mostly avoids multi-line constructs.\nMake It Greppable\nWhat’s really nice about Go is that you mostly cannot import symbols from\nanother package into scope without every use being prefixed with the package\nname.  Eg: context.Context instead of Context.  There are escape hatches\n(import aliases and dot-imports), but they’re relatively rare and usually\nfrowned upon.\nThat dramatically helps an agent understand what it’s looking at.  In general,\nmaking code findable through the most basic tools is great — it works with\nexternal files that aren’t indexed, and it means fewer false positives for\nlarge-scale automation driven by code generated on the fly (eg: sed, perl\ninvocations).\nLocal Reasoning\nMuch of what I’ve said boils down to: agents really like local reasoning.  They\nwant it to work in parts because they often work with just a few loaded files in\ncontext and don’t have much spatial awareness of the codebase.  They rely on\nexternal tooling like grep to find things, and anything that’s hard to grep or\nthat hides information elsewhere is tricky.\nDependency Aware Builds\nWhat makes agents fail or succeed in many languages is just how good the build\ntools are.  Many languages make it very hard to determine what actually needs to\nrebuild or be retested because there are too many cross-references.  Go is\nreally good here: it forbids circular dependencies between packages (import\ncycles), packages have a clear layout, and test results are cached.\nWhat Agents Hate\nMacros\nAgents often struggle with macros.  It was already pretty clear that humans\nstruggle with macros too, but the argument for them was mostly that code\ngeneration was a good way to have less code to write.  Since that is less of a\nconcern now, we should aim for languages with less dependence on macros.\nThere’s a separate question about generics and\ncomptime.  I think they fare\nsomewhat better because they mostly generate the same structure with different\nplaceholders and it’s much easier for an agent to understand that.\nRe-Exports and Barrel Files\nRelated to greppability: agents often struggle to understand barrel\nfiles and they don’t\nlike them.  Not being able to quickly figure out where a class or function comes\nfrom leads to imports from the wrong place, or missing things entirely and\nwasting context by reading too many files.  A one-to-one mapping from where\nsomething is declared to where it’s imported from is great.\nAnd it does not have to be overly strict either.  Go kind of goes this way, but\nnot too extreme.  Any file within a directory can define a function, which isn’t\noptimal, but it’s quick enough to find and you don’t need to search too far.\nIt works because packages are forced to be small enough to find everything with\ngrep.\nThe worst case is free re-exports all over the place that completely decouple\nthe implementation from any trivially reconstructable location on disk.  Or\nworse: aliasing.\nAliasing\nAgents often hate it when aliases are involved.  In fact, you can get them to\neven complain about it in thinking blocks if you let them refactor something\nthat uses lots of aliases.  Ideally a language encourages good naming and\ndiscourages aliasing at import time as a result.\nFlaky Tests and Dev Env Divergence\nNobody likes flaky tests, but agents even less so.  Ironic given how\nparticularly good agents are at creating flaky tests in the first place.  That’s\nbecause agents currently love to mock and most languages do not support mocking\nwell.  So many tests end up accidentally not being concurrency safe or depend on\ndevelopment environment state that then diverges in CI or production.\nMost programming languages and frameworks make it much easier to write flaky\ntests than non-flaky ones.  That’s because they encourage indeterminism\neverywhere.\nMultiple Failure Conditions\nIn an ideal world the agent has one command, that lints and compiles and it\ntells the agent if all worked out fine.  Maybe another command to run all tests\nthat need running.  In practice most environments don’t work like this.  For\ninstance in TypeScript you can often run the code even though it fails\ntype checks.  That can gaslight the agent.  Likewise\ndifferent bundler setups can cause one thing to succeed just for a slightly\ndifferent setup in CI to fail later.  The more uniform the tooling the better.\nIdeally it either runs or doesn’t and there is mechanical fixing for as many\nlinting failures as possible so that the agent does not have to do it by hand.\nWill We See New Languages?\nI think we will.  We are writing more software now than we ever have — more\nwebsites, more open source projects, more of everything.  Even if the ratio of\nnew languages stays the same, the absolute number will go up.  But I also truly\nbelieve that many more people will be willing to rethink the foundations of\nsoftware engineering and the languages we work with.  That’s because while for\nsome years it has felt you need to build a lot of infrastructure for a language\nto take off, now you can target a rather narrow use case: make sure the agent is\nhappy and extend from there to the human.\nI just hope we see two things.  First, some outsider art: people who haven’t\nbuilt languages before trying their hand at it and showing us new things.\nSecond, a much more deliberate effort to document what works and what doesn’t\nfrom first principles.  We have actually learned a lot about what makes good\nlanguages and how to scale software engineering to large teams.  Yet,  finding\nit written down, as a consumable overview of good and bad language design, is\nvery hard to come by.  Too much of it has been shaped by opinion on rather\npointless things instead of hard facts.\nNow though, we are slowly getting to the point where facts matter more, because\nyou can actually measure what works by seeing how well agents perform with it.\nNo human wants to be subject to surveys, but agents don’t\ncare.  We can see how successful they are and where they\nare struggling."
    },
    {
      "title": "lucumr.pocoo.org: Pi: The Minimal Agent Within OpenClaw",
      "url": "https://lucumr.pocoo.org/2026/1/31/pi/",
      "source": "lucumr.pocoo.org",
      "time": "2026-02-23T12:43:12.646220",
      "raw_desc": "If you haven’t been living under a rock, you will have noticed this week that a\nproject of my friend Peter went viral on the\ninternet.  It went by many names. The\nmost recent one is OpenClaw but in the news you might\nhave encountered it as ClawdBot or MoltBot depending on when you read about it.\nIt is an agent connected to a communication channel of your choice that just\nruns code.\nWhat you might be less familiar with is that what’s under the hood of OpenClaw\nis a little coding agent called Pi. And\nPi happens to be, at this point, the coding agent that I use almost exclusively.\nOver the last few weeks I became more and more of a shill for the little agent.\nAfter I gave a talk on this recently, I realized that I did not actually write\nabout Pi on this blog yet, so I feel like I might want to give some context on\nwhy I’m obsessed with it, and how it relates to OpenClaw.\nPi is written by Mario Zechner and unlike Peter, who\naims for “sci-fi with a touch of madness,” 1 Mario is very grounded.  Despite\nthe differences in approach, both OpenClaw and Pi follow the same idea: LLMs are\nreally good at writing and running code, so embrace this.  In some ways I think\nthat’s not an accident because Peter got me and Mario hooked on this idea, and\nagents last year.\nWhat is Pi?\nSo Pi is a coding agent.  And there are many coding agents.  Really, I think you\ncan pick effectively anyone off the shelf at this point and you will be able to\nexperience what it’s like to do agentic programming.  In reviews on this blog\nI’ve positively talked about AMP and one of the reasons I resonated so much with\nAMP is that it really felt like it was a product built by people who got both\naddicted to agentic programming but also had tried a few different things to see\nwhich ones work and not just to build a fancy UI around it.\nPi is interesting to me because of two main reasons:\n\nFirst of all, it has a tiny core. It has the shortest system prompt of any\nagent that I’m aware of and it only has four tools: Read, Write, Edit, Bash. \nThe second thing is that it makes up for its tiny core by providing an\nextension system that also allows extensions to persist state into sessions,\nwhich is incredibly powerful. \n\nAnd a little bonus: Pi itself is written like excellent software. It doesn’t\nflicker, it doesn’t consume a lot of memory, it doesn’t randomly break, it is\nvery reliable and it is written by someone who takes great care of what goes\ninto the software.\nPi also is a collection of little components that you can build your own agent\non top.  That’s how OpenClaw is built, and that’s also how I built my own little\nTelegram bot and how Mario built his\nmom.  If you want\nto build your own agent, connected to something, Pi when pointed to itself and\nmom, will conjure one up for you.\nWhat’s Not In Pi\nAnd in order to understand what’s in Pi, it’s even more important to understand\nwhat’s not in Pi, why it’s not in Pi and more importantly: why it won’t be in\nPi.  The most obvious omission is support for MCP.  There is no MCP support in\nit. While you could build an extension for it, you can also do what OpenClaw\ndoes to support MCP which is to use\nmcporter. mcporter exposes MCP calls via\na CLI interface or TypeScript bindings and maybe your agent can do something\nwith it.  Or not, I don’t know :)\nAnd this is not a lazy omission.  This is from the philosophy of how Pi works.\nPi’s entire idea is that if you want the agent to do something that it doesn’t\ndo yet, you don’t go and download an extension or a skill or something like\nthis. You ask the agent to extend itself.  It celebrates the idea of code\nwriting and running code.\nThat’s not to say that you cannot download extensions.  It is very much\nsupported. But instead of necessarily encouraging you to download someone else’s\nextension, you can also point your agent to an already existing extension, say\nlike, build it like the thing you see over there, but make these changes to it\nthat you like.\nAgents Built for Agents Building Agents\nWhen you look at what Pi and by extension OpenClaw are doing, there is an\nexample of software that is malleable like clay.  And this sets certain\nrequirements for the underlying architecture of it that are actually in many\nways setting certain constraints on the system that really need to go into the\ncore design.\nSo for instance, Pi’s underlying AI SDK is written so that a session can really\ncontain many different messages from many different model providers. It\nrecognizes that the portability of sessions is somewhat limited between model\nproviders and so it doesn’t lean in too much into any model-provider-specific\nfeature set that cannot be transferred to another.\nThe second is that in addition to the model messages it maintains custom\nmessages in the session files which can be used by extensions to store state or\nby the system itself to maintain information that either not at all is sent to\nthe AI or only parts of it.\nBecause this system exists and extension state can also be persisted to disk, it\nhas built-in hot reloading so that the agent can write code, reload, test it and\ngo in a loop until your extension actually is functional.  It also ships with\ndocumentation and examples that the agent itself can use to extend itself.  Even\nbetter: sessions in Pi are trees.  You can branch and navigate within a session\nwhich opens up all kinds of interesting opportunities such as enabling workflows\nfor making a side-quest to fix a broken agent tool without wasting context in\nthe main session.  After the tool is fixed, I can rewind the session back to\nearlier and Pi summarizes what has happened on the other branch.\nThis all matters because for instance if you consider how MCP works, on most\nmodel providers, tools for MCP, like any tool for the LLM, need to be loaded\ninto the system context or the tool section thereof on session start.  That\nmakes it very hard to impossible to fully reload what tools can do without\ntrashing the complete cache or confusing the AI about how prior invocations work\ndifferently.\nTools Outside The Context\nAn extension in Pi can register a tool to be available to the LLM to call and\nevery once in a while I find this useful. For instance, despite my criticism of\nhow Beads is implemented, I do think that giving an agent access to a to-do list\nis a very useful thing. And I do use an agent-specific issue tracker that works\nlocally that I had my agent build itself. And because I wanted the agent to also\nmanage to-dos, in this particular case I decided to give it a tool rather than a\nCLI.  It felt appropriate for the scope of the problem and it is currently the\nonly additional tool that I’m loading into my context.\nBut for the most part all of what I’m adding to my agent are either skills or\nTUI extensions to make working with the agent more enjoyable for me.  Beyond\nslash commands, Pi extensions can render custom TUI components directly in the\nterminal: spinners, progress bars, interactive file pickers, data tables,\npreview panes.  The TUI is flexible enough that Mario proved you can run Doom\nin it.  Not practical,\nbut if you can run Doom, you can certainly build a useful dashboard or debugging\ninterface.\nI want to highlight some of my extensions to give you an idea of what’s\npossible.  While you can use them unmodified, the whole idea really is that you\npoint your agent to one and remix it to your heart’s content.\n/answer\nI don’t use plan mode.  I encourage the agent\nto ask questions and there’s a productive back and forth.  But I don’t like\nstructured question dialogs that happen if you give the agent a question tool.\nI prefer the agent’s natural prose with explanations and diagrams interspersed.\nThe problem: answering questions inline gets messy.  So /answer reads the\nagent’s last response, extracts all the questions, and reformats them into a\nnice input box.\n\n/todos\nEven though I criticize Beads for its\nimplementation, giving an agent a to-do list is genuinely useful.  The /todos\ncommand brings up all items stored in .pi/todos as markdown files.  Both the\nagent and I can manipulate them, and sessions can claim tasks to mark them as in\nprogress.\n\n/review\nAs more code is written by agents, it makes little sense to throw unfinished\nwork at humans before an agent has reviewed it first.  Because Pi sessions are\ntrees, I can branch into a fresh review context, get findings, then bring fixes\nback to the main session.\n\nThe UI is modeled after Codex which provides easy to review commits, diffs,\nuncommitted changes, or remote PRs.  The prompt pays attention to things I care\nabout so I get the call-outs I want (eg: I ask it to call out newly added\ndependencies.)\n/control\nAn extension I experiment with but don’t actively use.  It lets one Pi agent send\nprompts to another.  It is a simple multi-agent system without complex\norchestration which is useful for experimentation.\n/files\nLists all files changed or referenced in the session.  You can reveal them in\nFinder, diff in VS Code, quick-look them, or reference them in your prompt.\nshift+ctrl+r quick-looks the most recently mentioned file which is handy when\nthe agent produces a PDF.\nOthers have built extensions too: Nico’s subagent\nextension and\ninteractive-shell which\nlets Pi autonomously run interactive CLIs in an observable TUI overlay.\nSoftware Building Software\nThese are all just ideas of what you can do with your agent.  The point of it\nmostly is that none of this was written by me, it was created by the agent to my\nspecifications.  I told Pi to make an extension and it did.  There is no MCP, there are\nno community skills, nothing.  Don’t get me wrong, I use tons of skills.  But\nthey are hand-crafted by my clanker and not downloaded from anywhere.  For\ninstance I fully replaced all my CLIs or MCPs for browser automation with a\nskill that just uses\nCDP.\nNot because the alternatives don’t work, or are bad, but because this is just\neasy and natural.  The agent maintains its own functionality.\nMy agent has quite a few\nskills and crucially\nI throw skills away if I don’t need them.  I for instance gave it a skill to\nread Pi sessions that other engineers shared, which helps with code review.  Or\nI have a skill to help the agent craft the commit messages and commit behavior I\nwant, and how to update changelogs.  These were originally slash commands, but\nI’m currently migrating them to skills to see if this works equally well.  I\nalso have a skill that hopefully helps Pi use uv rather than pip, but I also\nadded a custom extension to intercept calls to pip and python to redirect\nthem to uv instead.\nPart of the fascination that working with a minimal agent like Pi gave me is\nthat it makes you live that idea of using software that builds more software.\nThat taken to the extreme is when you remove the UI and output and connect it\nto your chat.  That’s what OpenClaw does and given its tremendous growth,\nI really feel more and more that this is going to become our future in one\nway or another.\n\n\n\nhttps://x.com/steipete/status/2017313990548865292↩"
    },
    {
      "title": "pluralistic.net: Pluralistic: A perforated corporate veil (20 Feb 2026)",
      "url": "https://pluralistic.net/2026/02/20/karioca-konzernrecht/",
      "source": "pluralistic.net",
      "time": "2026-02-23T12:43:12.662460",
      "raw_desc": ""
    },
    {
      "title": "pluralistic.net: Pluralistic: Six Years of Pluralistic (19 Feb 2026)",
      "url": "https://pluralistic.net/2026/02/19/now-we-are-six/",
      "source": "pluralistic.net",
      "time": "2026-02-23T12:43:12.662460",
      "raw_desc": ""
    },
    {
      "title": "pluralistic.net: Pluralistic: What's a \"gig work minimum wage\" (17 Feb 2026)",
      "url": "https://pluralistic.net/2026/02/17/no-piecework/",
      "source": "pluralistic.net",
      "time": "2026-02-23T12:43:12.662460",
      "raw_desc": ""
    },
    {
      "title": "overreacted.io: A Social Filesystem",
      "url": "https://overreacted.io/a-social-filesystem/",
      "source": "overreacted.io",
      "time": "2026-02-23T12:43:12.872522",
      "raw_desc": ""
    },
    {
      "title": "overreacted.io: Introducing RSC Explorer",
      "url": "https://overreacted.io/introducing-rsc-explorer/",
      "source": "overreacted.io",
      "time": "2026-02-23T12:43:12.872522",
      "raw_desc": ""
    },
    {
      "title": "overreacted.io: Hire Me in Japan",
      "url": "https://overreacted.io/hire-me-in-japan/",
      "source": "overreacted.io",
      "time": "2026-02-23T12:43:12.872522",
      "raw_desc": ""
    },
    {
      "title": "garymarcus.substack.com: Rumors of AGI’s arrival have been greatly exaggerated ",
      "url": "https://garymarcus.substack.com/p/rumors-of-agis-arrival-have-been",
      "source": "garymarcus.substack.com",
      "time": "2026-02-23T12:43:12.988789",
      "raw_desc": ""
    },
    {
      "title": "garymarcus.substack.com: We URGENTLY need a federal law forbidding AI from impersonating humans",
      "url": "https://garymarcus.substack.com/p/we-urgently-need-a-federal-law-forbidding",
      "source": "garymarcus.substack.com",
      "time": "2026-02-23T12:43:12.988789",
      "raw_desc": ""
    },
    {
      "title": "garymarcus.substack.com: Irony, Irony laced with Karma, and Terror",
      "url": "https://garymarcus.substack.com/p/irony-irony-laced-with-karma-and",
      "source": "garymarcus.substack.com",
      "time": "2026-02-23T12:43:12.988789",
      "raw_desc": ""
    },
    {
      "title": "skyfall.dev: Good riddance, 4o",
      "url": "https://mahadk.com/posts/4o/",
      "source": "skyfall.dev",
      "time": "2026-02-23T12:43:13.435915",
      "raw_desc": ""
    },
    {
      "title": "skyfall.dev: The UK paid £4.1 million for a bookmarks site",
      "url": "https://mahadk.com/posts/ai-skills-hub/",
      "source": "skyfall.dev",
      "time": "2026-02-23T12:43:13.435915",
      "raw_desc": ""
    },
    {
      "title": "skyfall.dev: Using the M1 MacBook Air in 2026",
      "url": "https://mahadk.com/posts/m1-mba/",
      "source": "skyfall.dev",
      "time": "2026-02-23T12:43:13.435915",
      "raw_desc": ""
    },
    {
      "title": "timsh.org: Scam Telegram: Uncovering a network of groups spreading crypto drainers",
      "url": "https://timsh.org/scam-telegram-investigation/",
      "source": "timsh.org",
      "time": "2026-02-23T12:43:13.612955",
      "raw_desc": ""
    },
    {
      "title": "timsh.org: Why you should self-host your (vibecoded) app",
      "url": "https://timsh.org/why-you-should-self-host/",
      "source": "timsh.org",
      "time": "2026-02-23T12:43:13.612955",
      "raw_desc": ""
    },
    {
      "title": "timsh.org: Switching to Claude Code + VSCode inside Docker",
      "url": "https://timsh.org/claude-inside-docker/",
      "source": "timsh.org",
      "time": "2026-02-23T12:43:13.612955",
      "raw_desc": ""
    },
    {
      "title": "utcc.utoronto.ca/~cks: Your feed reader User-Agent is a too-old browser",
      "url": "https://utcc.utoronto.ca/~cks/cspace-old-browser.html",
      "source": "utcc.utoronto.ca/~cks",
      "time": "2026-02-23T12:43:13.623646",
      "raw_desc": "Your software is blocked from fetching my syndication feeds\n  because it is using a User-Agent header in its HTTP requests that\n  claims it is a too-old browser.\n  Your software has been redirected to this special single-entry feed\n  so that you can hopefully find out about this and ideally remedy it.\n  Please see\n  my\n  general web page on too-old browser User-Agents."
    },
    {
      "title": "matklad.github.io: Wrapping Code Comments",
      "url": "https://matklad.github.io/2026/02/21/wrapping-code-comments.html",
      "source": "matklad.github.io",
      "time": "2026-02-23T12:43:13.647874",
      "raw_desc": "Wrapping Code Comments\nFeb 21, 2026\n\nI was today years old when I realized that:\n\n\nCode and code comments ideally should be wrapped to a different column.\n\n\nFor comments, the width should be relative to the start of the comment.\n\n\nIt’s a good idea to limit line length to about 100 columns. This is a physical limit, the width at\nwhich you can still comfortably fit two editors side by side (see\nSize Matters). Note an apparent\ncontradiction: the optimal width for readable prose is usually taken to be narrower, 60–70 columns.\nThe contradiction is resolved by noticing that, for code, indentation eats into usable space.\nTypically, code is much less typographically dense than prose.\nStill, I find comment blocks easier to read when they are  wrapped narrower than the surrounding\ncode. I want lines to be wrapped at 100, and content of comments to be wrapped at 70 (unless that\npushes overall line to be longer than 100). That is, I want layout like this (using 20/30 rulers\ninstead of 70/100, for illustrative purposes):\n\n// Top level comments\n// can be this wide.\nconst S = struct {\n    // Nested comments are\n    // also this wide, but\n    // are shifted right.\n    fn f() void {\n        switch (value) {\n            0 => {\n                // But there is\n                // a hard limit.\n            }\n        }\n    }\n}\n\nThis feels obvious in retrospect, but notably isn’t be well-supported by the tools? The\nVS Code extension I use allows\nconfiguring dedicated fill column for comments, but doesn’t make it relative, so indented comment\nblocks are always narrower than top-level ones. Emacs M-q also doesn’t do relative wrapping out of\nthe box!\n\nAside on hard-wrapping: should we bother with wrapping comments at all? Can’t we rely on our editor\nto implement soft-wrapping? The problem with soft-wrapping is that you can’t soft-wrap text\ncorrectly without understanding its meaning. Consider a markdown list:\n\nA list:\n  * item one,\n  * item two.\n\nIf the first item is long enough to necessitate wrapping, the wrapped line should also be indented,\nwhich requires parsing the text as markdown first:\n\nA list:\n  * item one which is long enough\n    necessitate wrapping,\n  * item two."
    },
    {
      "title": "matklad.github.io: Diagnostics Factory",
      "url": "https://matklad.github.io/2026/02/16/diagnostics-factory.html",
      "source": "matklad.github.io",
      "time": "2026-02-23T12:43:13.653857",
      "raw_desc": "Diagnostics Factory\nFeb 16, 2026\n\nIn\nError Codes For Control Flow,\nI explained that Zig’s strongly-typed error codes solve the “handling” half of error management,\nleaving “reporting” to the users. Today, I want to describe my personal default approach to\nthe reporting problem, that is, showing the user a useful error message.\nThe approach is best described in the negative: avoid thinking about error payloads, and what\nthe type of error should be. Instead, provide a set of functions for constructing errors.\nTo give a concrete example, in TigerBeetle’s\ntidy.zig\n(a project-specific linting script, another useful meta-pattern), we define errors as follows:\n\nconst Errors = struct {\n    pub fn add_long_line(\n        errors: *Errors,\n        file: SourceFile,\n        line_index: usize,\n    ) void { ... }\n\n    pub fn add_banned(\n        errors: *Errors,\n        file: SourceFile,\n        offset: usize,\n        banned_item: []const u8,\n        replacement: []const u8,\n    ) void { ... }\n\n    pub fn add_dead_declaration(...) void { ... }\n\n    ...\n};\n\nand the call-site looks like this:\n\nfn tidy_file(file: SourceFile, errors: *Errors) void {\n    // ...\n    var line_index: usize = 0;\n    while (lines.next()) |line| : (line_index += 1) {\n        const line_length = line_length(line);\n        if (line_length > 100 and !contains_url(line)) {\n            errors.add_long_line(file, line_index);\n        }\n    }\n}\n\nIn this case, I collect multiple errors so I don’t return right away. Fail fast would look like\nthis:\n\nerrors.add_long_line(file, line_index);\nreturn error.Tidy;\n\nNote that the error code is intentionally independent of the specific error produced.\n\nSome interesting properties of the solution:\n\n\nThe error representation is a set of constructor functions, the calling code doesn’t care what\nactually happens inside. This is why the error factory is my default solution — I don’t have\nto figure out up-front what I’ll do with the errors, and I can change my mind later.\n\n\nThere’s a natural place to convert information from the form available at the place where we emit\nthe error to a form useful for the user. In add_banned above, the caller passes in a absolute\noffset in a file, and it is resolved to line number and column inside (tip: use line_index for\n0-based internal indexes, and line_number for user-visible 1-based ones). Contrast this with a\ntraditional error as sum-type approach, where there’s a sharp syntactic discontinuity between\nconstructing a variant directly and calling a helper function.\n\n\nThis syntactic uniformity in turn allows easily grepping for all error locations:\nrg 'errors.add_'.\n\n\nSimilarly, there’s one central place that enumerates all possible errors (which is either a\nbenefit or a drawback).\n\n\nA less trivial property is that this structure enables polymorphism. In fact, in the tidy.zig\ncode, there are two different representations of errors. When running the script, errors are\ndirectly emitted to stderr. But when testing it, errors are collected into an in-memory buffer:\n\npub fn add_banned(\n    errors: *Errors,\n    file: SourceFile,\n    offset: usize,\n    banned_item: []const u8,\n    replacement: []const u8,\n) void {\n    errors.emit(\n        \"{s}:{d}: error: {s} is banned, use {s}\\n\",\n        .{\n            file.path, file.line_number(offset),\n            banned_item, replacement,\n        },\n    );\n}\n\nfn emit(\n    errors: *Errors,\n    comptime fmt: []const u8,\n    args: anytype,\n) void {\n    comptime assert(fmt[fmt.len - 1] == '\\n');\n    errors.count += 1;\n    if (errors.captured) |*captured| {\n        captured.writer(errors.gpa).print(fmt, args)\n            catch @panic(\"OOM\");\n    } else {\n        std.debug.print(fmt, args);\n    }\n}\n\nThere isn’t a giant union(enum) of all errors, because it’s not needed for the present use-case.\nThis pattern can be further extended to a full-fledged diagnostics framework with error builders,\nspans, ANSI colors and such, but that is tangential to the main idea here: even when “programming in\nthe small”, it might be a good idea to avoid constructing enums directly, and mandate an\nintermediate function call.\n\nTwo more meta observations here:\nFirst, the entire pattern is of course the expression of duality between a sum of two types and a\nproduct of two functions (the visitor pattern)\n\nfn foo() -> Result<T, E>;\n\nfn bar(ok: impl FnOnce(T), err: impl FnOnce(E));\n\n\nenum Result<T, E> {\n    Ok(T),\n    Err(E),\n}\n\ntrait Result<T, E> {\n    fn ok(self, T);\n    fn err(self, E);\n}\n\nSecond, every abstraction is a thin film separating two large bodies of code. Any interface has\ntwo sides, the familiar one presented to the user, and the other, hidden one, presented to the\nimplementor. Often, default language machinery pushes you towards using the same construct for both\nbut that can be suboptimal. It’s natural for the user and the provider of the abstraction to\ndisagree on the optimal interface, and to evolve independently. Using a single big enum for errors\ncouples error emitting and error reporting code, as they have to meet in the middle. In contrast,\nthe factory solution is optimal for producer (they literally just pass whatever they already have on\nhand, without any extra massaging of data), and is flexible for consumer(s)."
    },
    {
      "title": "matklad.github.io: Justifying text-wrap: pretty",
      "url": "https://matklad.github.io/2026/02/14/justifying-text-wrap-pretty.html",
      "source": "matklad.github.io",
      "time": "2026-02-23T12:43:13.655575",
      "raw_desc": "Justifying text-wrap: pretty\nFeb 14, 2026\n\n\nSomething truly monumental happened in the world of software development in 2025. Safari shipped a\nreasonable implementation of text-wrap: pretty:\nhttps://webkit.org/blog/16547/better-typography-with-text-wrap-pretty/. We are getting\ncloser and closer to the cutting-edge XV-century technology. Beautiful paragraphs!\n\n\n\nWe are not quite there yet, hence the present bug report.\n\nA naive way to break text into lines to form a paragraph of a given width is greediness: add the\nnext word to the current line if it fits, otherwise start a new line. The result is unlikely to be\npretty — sometimes it makes sense to try to squeeze one more word on a line to make the lines more\nbalanced overall. Johannes Gutenberg did this sort of thing manually, to produce a beautiful page\nabove. In 1981, Knuth and Plass figured out a way to teach computers to do this, using dynamic\nprogramming, for line breaking in TeX.\nInexplicably, until 2025, browsers stuck with the naive greedy algorithm, subjecting generations of\nweb users to ugly typography. To be fair, the problem in a browser is harder version than the one\nsolved by Gutenberg, Plass, and Knuth. In print, the size of the page is fixed, so you can compute\noptimal line breaking once, offline. In the web context, the window width is arbitrary and even\nchanges dynamically, so the line-breaking has to be “online”. On the other hand, XXI century\nbrowsers have a bit more compute resources than we had in 1980 or even 1450!\n\nMaking lines approximately equal in terms of number of characters is only half-way through towards a\nbeautiful paragraph. No matter how you try, the length won’t be exactly the same, so, if you want\nboth the left and the right edges of the page to be aligned, you also need to fudge the spaces\nbetween the words a bit. In CSS,\ntext-wrap: pretty\nasks the browser to select line breaks in an intelligent way to make lines roughly equal, and\ntext-align: justify\nadjusts whitespace to make them equal exactly.\nAlthough Safari is the first browser to ship a non-joke implementation of text-wrap, the\ncombination with text-align looks ugly, as you can see in this very blog post. To pin the ugliness\ndown, the whitespace between the words is blown out of proportion. Here’s the same justified\nparagraph with and without text-wrap: pretty:\n\n\n\n\nThe paragraph happens to look ok with greedy line-breaking. But the “smart” algorithm decides to add\nan entire line to it, which requires inflating all the white space proportionally. By itself, either\nof\n\np {\n    text-wrap: pretty;\n    text-align: justify;\n}\n\nlooks alright. It’s just the combination of the two that is broken.\n\nThis behavior is a natural consequence of implementation. My understanding is that the dynamic\nprogramming scoring function aims to get each line close to the target width, and is penalized for\ndeviations. Crucially, the actual max width of a paragraph is fixed: while a line can be arbitrary\nshorter, it can’t be any longer, otherwise it’ll overflow. For this reason, the dynamic programming\nsets the target width to be a touch narrower than the paragraph. That way, it’s possible to both\nunder and overshoot, leading to better balance overall. As per\noriginal article:\n\nThe browser aims to wrap each line sooner than the maximum limit of the text box. It wraps\nwithin the range, definitely after the magenta line, and definitely before the red line.\n\n\n\n\n\nBut if you subsequently justify all the way to the red line, the systematic overshoot will manifest\nitself as too wide inter-word space!\nWebKit devs, you are awesome for shipping this feature ahead of everyone else, please fix this small\nwrinkle such that I can make my blog look the way I had intended all along ;-)"
    },
    {
      "title": "johndcook.com: Bitcoin mining difficulty",
      "url": "https://www.johndcook.com/blog/2026/02/22/bitcoin-mining-difficulty/",
      "source": "johndcook.com",
      "time": "2026-02-23T12:43:13.705757",
      "raw_desc": ""
    },
    {
      "title": "johndcook.com: Exahash, Zettahash, Yottahash",
      "url": "https://www.johndcook.com/blog/2026/02/22/zettahash/",
      "source": "johndcook.com",
      "time": "2026-02-23T12:43:13.705757",
      "raw_desc": ""
    },
    {
      "title": "johndcook.com: 10,000,000th Fibonacci number",
      "url": "https://www.johndcook.com/blog/2026/02/21/f10000000/",
      "source": "johndcook.com",
      "time": "2026-02-23T12:43:13.705757",
      "raw_desc": ""
    },
    {
      "title": "terriblesoftware.org: Why Am I Doing the Thinking for You?",
      "url": "https://terriblesoftware.org/2026/02/02/why-am-i-doing-the-thinking-for-you/",
      "source": "terriblesoftware.org",
      "time": "2026-02-23T12:43:13.860760",
      "raw_desc": ""
    },
    {
      "title": "terriblesoftware.org: Why I Still Write Code as an Engineering Manager",
      "url": "https://terriblesoftware.org/2026/01/22/why-i-still-write-code-as-an-engineering-manager/",
      "source": "terriblesoftware.org",
      "time": "2026-02-23T12:43:13.860760",
      "raw_desc": ""
    },
    {
      "title": "terriblesoftware.org: Life Happens at 1x Speed",
      "url": "https://terriblesoftware.org/2026/01/08/life-happens-at-1x-speed/",
      "source": "terriblesoftware.org",
      "time": "2026-02-23T12:43:13.860760",
      "raw_desc": ""
    },
    {
      "title": "derekthompson.org: The Orality Theory of Everything",
      "url": "https://www.theatlantic.com/ideas/2026/02/social-media-literacy-crisis/686076/?utm_source=feed",
      "source": "derekthompson.org",
      "time": "2026-02-23T12:43:14.087311",
      "raw_desc": "The world is full of theories of everything. The smartphone theory of everything argues that our personal devices are responsible for the rise of political polarization, anxiety, depression, and conspiracy theories—not to mention the decline of attention spans, intelligence, happiness, and general comity. The housing theory of everything pins inequality, climate change, obesity, and declining fertility on the West’s inability to build enough homes. If you treat theories of everything as literal theories of everything, you will be disappointed to find that they all have holes. I prefer to think of them as exercises in thinking through the ways that single phenomena can have large and unpredictable second-order effects.My new favorite theory of everything is the orality theory of everything. This theory emerges from the work of mid-20th-century media theorists, especially Walter Ong and Marshall McLuhan. They argued that the invention of the alphabet and the rise of literacy were among the most important events in human history. These developments shifted communications from an age of orality—in which all information was spoken and all learning was social—to an age of literacy, in which writing could fix words in place, allowing people to write alone, read alone, and develop ever more complicated ideas that would have been impossible to memorize. The age of orality was an age of social storytelling and flexible cultural memory. The age of literacy made possible a set of abstract systems of thought—calculus, physics, advanced biology, quantum mechanics—that form the basis of all modern technology. But that’s not all, Ong and his ilk said. Literacy literally restructured our consciousness, and the demise of literate culture—the decline of reading and the rise of social media—is again transforming what it feels like to be a thinking person.The most enthusiastic modern proponent of the orality theory of everything that I know of is Bloomberg’s Joe Weisenthal, the co-host of the Odd Lots podcast. We discussed orality, literacy, and the implications for politics, storytelling, expertise, social relations, and much more. The following transcript has been edited for clarity, brevity, and the goal of making both speakers sound a bit smarter.Derek Thompson: The return of orality: Why do you think it explains everything?Joe Weisenthal: I don’t think it explains everything. I think it only explains 99 percent of everything.I believe that human communication is becoming more oral. And by that I don’t just mean that people are talking more with their mouths, although I do think that is the case. It’s more that communication in general, whether in the spoken form or in the digital form, has the characteristics of conversation. And it truly harkens back to a time before, really, the written word, or certainly before mass literacy.In 2016, during the presidential election, I started reading the work of Walter Ong. He was a Jesuit priest. He studied with Marshall McLuhan. He was at Saint Louis University and wrote this really incredible book called Orality and Literacy. The gist is that humans [in oral cultures] fundamentally think differently when they’re in this world that you can’t write anything down, that you can’t look anything up. For most of human history, there was no way to look up anything at all. There was no reference material and so forth. And as such, people had to optimize their communication for the conditions of that time.Through a lot of study of Homer and other ancient epics, people realized that there were certain patterns of communication. People spoke with rhythm and rhyme and musicality, because it helps people memorize things. Certain phrases just get repeated over and over again. Repetition, communication, and information were optimized for memorability, in packets, and what we would call “going viral.” When I started reading this book, I was like, Look, this has a lot of explanatory power. These things that characterize the Homeric times—the way society prioritized and packaged information—greatly resemble what we see today. My big thesis is that as communication becomes more of this back-and-forthness, it’s changing the way that we communicate and the way we think.Thompson: To drill down on why the shift to literacy was so important for the way we think, for the way we transmit knowledge, for the way we build institutions, I want to quote two great scholars here. The first is Joshua Meyrowitz, an emeritus professor of communication at the University of New Hampshire. He writes in No Sense of Place: The Impact of Electronic Media on Social Behavior:\nThe break from total reliance on oral communication allows people to become more introspective, rational, and individualistic. Abstract thought develops. From the circular world of sound with its round huts and round villages, people move, over time, toward linear, cause and effect thinking, grid-like cities, and a one thing at a time and one thing after another world that mimics the linear lines of writing and type.\nThe second is from another great scholar named Joe Weisenthal:\nMany of the things that modern institutions are built on—enlightenment thinking, formal logic, reason, meritocracy, examining the evidence—are downstream from the ability to contemplate the written word at a distance.\nWhy don’t you expand on either quote?Weisenthal: People can probably feel this. When you’re in a conversation, online or offline, what are you doing? You’re often trying to impress someone. You might be trying to one-up someone. Maybe if there’s a few people there, you’re trying to put someone down to look cool for the other person. These are all things that occur that don’t occur when you’re in solitude. A solo interaction with language can only be done really with the written word. Even setting aside the logical arguments for the connection between the alphabet and left-to-right thinking and linear thinking, most people, I think, could intuitively understand that interactive environments foster different priorities.[Adam Kirsch: Reading is a vice]When you’re writing a letter, or certainly, let’s say, you’re writing a book as you have, you don’t necessarily have the reader in mind at that exact moment. In fact, you have the luxury of writing and not having to think about what the reader is going to be doing at this moment. These are all luxuries that occur in the context of literacy—the written word—that are separate from a conversation. And so the written word creates all kinds of new opportunities to think through these things, to take time, to not respond right away.Thompson: Thinking used to be something that had to be done socially. It was impossible to learn The Odyssey on your own. It was transmitted to you from a person. You would rehearse it with someone else. The mode of information transfer was necessarily social. Books are written alone, and books are typically read alone. And so this age of literacy gave rise to this privilege of solitude and interiority that I think is really, really important.Walter Ong, our mutual hero, has a great quote that I want to throw to you and then get your reaction to, because it goes right to this point. He said:\nHuman beings in primary oral cultures … do not “study.” They learn by apprenticeship—hunting with experienced hunters, for example—by discipleship, which is a kind of apprenticeship, by listening, by repeating what they hear, by mastering proverbs and ways of combining and recombining them … not by study in the strict sense.\nI’m very interested in a phenomenon that I call the antisocial century, the idea that for a variety of reasons, we are spending much more time alone. And that is having a bunch of second- and third-order effects. And it really is interesting to me, as I was going deeper into this project, to think that it’s the age of literacy that in many ways allowed us to be alone as we learned, and to prize a certain kind of interiority.Weisenthal: Marshall McLuhan had this observation: The alphabet is the most detribalizing technology that’s ever existed. It speaks to this idea that prior to the written word, all knowledge was, per se, communal. It had to be in a group. If you have multiple texts in front of you, then you trust the one that feels most logical. But you don’t have that luxury when all knowledge is communal. Being part of the crowd has to be part of learning.The ear and the eye are very different organs. You can close your eyes, which you can’t do with your ears. You can get perspective from your eye and establish perspective in a way you can’t do with your ears. So it’s like you go into a room and you can stand back at the corner so you can make sure that you can see everything going on in the room. The ear is very different. We’re at the center of everything constantly. You can’t close it. The ear continues to work while we’re sleeping. There’s an evolutionary purpose for the fact that we can still hear when we’re sleeping, because if there’s an intruder or a wild animal or something, it wakes us up and we can run.So the ear, McLuhan said, is inherently a source of terror. It feels very digital. Even though we do look at the internet, there is this sense in which we can never remove ourselves from it. Even if we’re reading the internet, it almost feels more like we’re hearing it. There’s an immersiveness in contemporary digital discourse that I think is much more like hearing than it is about seeing. So I think there’s all kinds of different ways that we are sort of returning to this realm.Thompson: We had the age of orality, which was the age of the ear. Then we had the high-water mark of literacy, which is the high-water mark of the age of the eye. And now we’re in this messy third stage where it’s like there’s some human facial organ that’s an eye and an ear mashed together, because we have TV and radio and social media and TikTok. And what’s interesting about these technologies is that they are all oral. What is radio, if not oral? What is television, if not oral? What is TikTok, if not spoken and live?But there’s a lasting record of your tweets. There’s a lasting record of that TikTok, which can be shared. And the fact that these pieces of media can be recorded means that in many ways they are also of a piece with the age of literacy, of literate recorded artifacts. What do we make of this weird synthetic new stage that we’re in? What do we call it? How do we describe it?Weisenthal: Andrey Mir, who has written some of the best stuff updating Ong’s ideas, calls it digital orality. I like that. One thing that’s interesting, though, is that we might not really have those records in the future. For one thing, things disappear. Two, we don’t really trust pictures anymore. The archive is sort of tenuous. We maybe had this brief period where we had a lot of digital archives and we could trust them, but digital archives are disappearing and you’re going to have facsimiles, things that looked like they happened that didn’t actually happen, which, incidentally, Ong talks about.So he talks about how in a lot of oral cultures, history was malleable. He talks about biblical genealogies: So-and-so begat so-and-so begat so-and-so begat so-and-so begat,  on forever. There are a lot of examples in oral cultures where, when something is no longer convenient—maybe there are some lineage of kings and that king falls into disrepute and they switch it—they’ll just come up with a new poem. And so there isn’t the idea of a fixed history. I think that’s probably what’s going to happen today. We’re going to have books for a very long time, but history will be manufactured in accordance with the sort of contemporary values of the moment.Thompson: This is a period that some people call post-literate. Reading is in decline. Standardized-test scores are in decline. As I’ve written, it sometimes feels like everything is trying to become television. Social media is becoming TV; podcasts are becoming TV. People are going to the movies less. Everything is evolving toward short-form video. I wonder how you feel about this general thesis that in a post-literate age, everything is evolving toward short-form video.Weisenthal: This idea of post-literacy, I think there’s a sort of figurative meaning and a literal meaning. On the one hand, again, when I hear the word post-literacy or when I’ve used the term, it doesn’t necessarily mean that people don’t know how to read. I still think it’s mostly useful as a term to describe conditions of information and conditions of communication that are very distinct from solitary, literate communications. So I think the fact that so much is talk, so much is back-and-forthness, so much is information designed to be viral, memorable, repeatable—this is mostly what I am thinking of when I think about post-literacy.Incidentally, I don’t think people know how to read either. I look at myself and I think I read way more books than 99 percent of the population. But I’ll read two pages and then I’ll check my Twitter mentions, and then I’ll read two pages and check my Twitter mentions. Isn’t that everyone? Can anyone actually read three pages anymore? Maybe it’s just me, and my attention span is just totally bombed out, which is possible, because, again, I spend all day looking at a screen. I’ll fully cop to that.Thompson: I do also have the sense when I’m reading that there’s often, especially if my phone is anywhere within reach or sight, something calling me away from that book at all times.Weisenthal: In some of the writing from the ’60s and ’70s, one of the things that I’ve noticed is people talking about phones interrupting people having sex. This is a common observation. They talk about unplugging the phone before couples had sex or whatever it was. And I think, again, one of the things people talk about right now, which I find fascinating, is the big fertility drops and people are trying to figure it out. And this is something that is occurring in almost every country around the world, including China, which does not resemble the rest of the world and has avoided many contemporary pathologies. Even there, it’s happening.[Read: The slow, quiet demise of American romance]And I do think it’s very interesting that—if you go back and look at how many people noticed this phenomenon when everyone started getting phones—the degree to which it was as if the phone was the third person there, interrupting the privacy of the couple. That’s a very powerful observation that I think then has a lot of explanatory effects for what came afterwards, when everyone started holding a phone on them, every waking minute.Thompson: I want to apply your theories to some domains of modern life, starting with politics. I went to look up Donald Trump’s nicknames, because I know that you’re very interested in his propensity for epithets, for nicknames. It’s nearly Homeric. Fortunately for our purposes, Wikipedia keeps track of all of Trump’s nicknames, so I didn’t have to remember them—speaking of outsourced memory. Here are some of them. Steve Bannon was “Sloppy Steve,” Joe Biden was “Sleepy Joe,” Mike Bloomberg was “Mini Mike,” Jeb Bush was, of course, “Low-Energy Jeb.”This plays into this classic tradition of orality. The wine-dark seas, swift-footed Achilles. And Walter Ong has a great passage where he writes about this, which I would love to get your reaction to:\nThe cliches in political denunciations in many low-technology developing cultures—enemy of the people, capitalist war-mongers—that strike high literates as mindless are residual formulary essentials of oral thought processes.\nIt’s so interesting to think that Ong is saying that it is low-technology developing countries where these nicknames are prevalent. But you wake up today and the richest country in the world is presided over by a now two-time president whose facility for nicknames is very famous. What significance do you put on this? Why is it important that a figure like Trump plays into these old-fashioned oral traditions?Weisenthal: It’s interesting—when you say things like, Oh, Trump has a sort of Homeric quality in the way he speaks, that repels a lot of people. Like, What are you talking about? This is nothing like Homer. But my theory, which I can’t prove, is that the original bards who composed Homer were probably Trump-like characters. So rather than saying Trump is a Homeric character, we could say that the people who gathered around and told these ancient stories were probably the Trump-like characters of their time. Colorful, very big characters, people who were loud, who could really get attention, who would captivate people when they talked. One of Ong’s observations in Orality and Literacy is about heavy and light characters in oral societies. Heavy characters are like Cerberus, the three-headed dog; Medusa; Zeus—these larger-than-life, frequently grotesque, visually grotesque characters.The modern world has elevated a lot of what I think Ong would call heavy characters. I certainly think Trump is a heavy character, with his makeup, his hair, and his whole visual presentation. I think Elon Musk is a heavy character. We are in the time of the heavy character.If you look at icons of the previous age, John F. Kennedy was not a heavy character. That’s a light character, a certain coolness. Barack Obama was a light character; there was a certain coolness to him. One of the things that people debate a lot is, like, If Obama could run again, wouldn’t he just clean up? If Democrats could just bring Obama back for a third time, wouldn’t that just solve all of Democrats’ electoral problems? And I think in 2016, I probably would’ve believed that. And maybe in 2020, I would’ve believed that. But I’m certainly less confident now. I feel like Obama is a character of a cooler, different time. A character from a pre-TikTok time, in many respects.Thompson: Let me push back here. I think Obama in 2004, with the first Democratic National Committee speech, was a heavy character. I think the presidency lightened him. I think Trump in 2015 was a heavy character, and he is a lighter character now having suffered overexposure. Maybe the fissures that you see in the Republican Party are that Trump, the once heavy character, is losing the weight that used to be necessary to keep this coalition together. And people are seeing he’s kind of lost it. I wonder if there’s some idea that in politics, many people debut as the heavy character. But experience and time and failure lightens them. And that’s part of the reason no president seems to survive more than one year of positive approval ratings. We have learned to hate everybody.Weisenthal: Since you mentioned this phenomenon, that no president can sustain high approval ratings (which does seem like a phenomenon basically everywhere), could we pivot? Could I bring in Meyrowitz here?Meyrowitz, in 1985, was talking about electronic media before anyone really conceived of that idea. One of his observations is that everybody has an onstage and a backstage. We talk on this podcast in a certain way. But that is different from how we would talk at home with our family. Or you and I might talk differently when we hang up this podcast and we’re saying goodbye or something. This is a very normal thing, which is that you just talk differently in different environments.What Meyrowitz anticipated in No Sense of Place is this idea that electronic media would cause us to be suspicious of people who talk differently in one environment versus another. If someone code-switched, if someone talked differently on the campaign trail than they did in their private life, then we would come to think, This person’s a phony. Something about Trump is that there are very few examples of him ever talking differently in one environment than in any other. People could be totally repelled by things that he said in public or private. But he’s not a hypocrite in the way that a lot of people use that word. He is the same in almost every environment. This is precisely what Meyrowitz would’ve anticipated, that we would gravitate toward people who act the same onstage and backstage, that we would come to view that consistency of character as a value.Thompson: The name of Meyrowitz’s book is No Sense of Place. And I want to just slow down on that title, because it’s a pun. By no sense of place, Meyrowitz is saying that electronic media extends our consciousness outward, so we don’t really know where we are. I could be reading Twitter in Arlington, Virginia, but feel myself becoming emotional about Gaza or Ukraine or Minneapolis, in a way that was impossible in the age before television or radio. This new age of communications media takes us out of where we are and puts us right in front of the faces of people who are thousands of miles away.But he also means no sense of place in a hierarchical sense. He means that people will be able, with electronic media, to operate outside of their slot in the hierarchy: The poor will be able to scream at the billionaires. And this, he said, is going to create more social unrest. It’s going to create more, I think he would agree, of something like populism. And this really interesting idea that electronic media not only unmoors us from where we are geographically but that it also demolishes hierarchies—I think it was incredibly insightful, considering it was written 41 years ago.But he goes one step further in a way that’s really surprising, and this is the part I’d really love you to comment on. He says this about our future relationship to expertise—and God only knows how many people have talked about what’s happened to expertise in the last few decades: “Our increasingly complex technological and social world has made us rely more and more heavily on ‘expert information,’ but the general exposure of ‘experts’ as fallible human beings has lessened our faith in them as people. The change in our image of leaders and experts leaves us with”—and this is exactly your point—“a distrust of power, but also with a seemingly powerless dependence on those in whom we have little trust.”Weisenthal: It’s crazy. It does feel like this could be in The Atlantic in 2025. It’s just so far ahead of its time. You mentioned the poor can scream at the billionaires. I think most people would say, Look, technology is an enabled environment in which the poor can have their voice heard and billionaires are brought low and can be hectored, and we see that happen every day online. Most people intuitively think that’s a very positive development. That’s, like, an egalitarian development. But by the same token, there are other things that most people are not as comfortable with. I think this whole field of study offers a certain way of viewing history that is not entirely satisfying to anyone or anyone’s political project currently.Thompson: Speaking of topics that aren’t particularly comfortable with any political project, I have a question for you about AI and how AI slots into orality versus literacy. I want to come at it from what I hope is an interesting angle. This is a quote from Ong’s Orality and Literacy:\nA written text is basically unresponsive. If you ask a person to explain his or her statement, you can get an explanation; if you ask a text, you get back nothing except the same, often stupid, words which called for your question in the first place.\nI reread that section on a plane recently, and I jolted up in my seat. That’s what AI has changed. You can enter into conversations with text. That is true either at a literal level—like, I can download a PDF of a book and give it to Claude and be like, Claude, can we talk about this book?—but also, at a higher abstract level, we’re talking about a technology that is pretrained on text. It’s pretrained on literacy. But we have an oral, which is to say conversational, relationship with that training corpus. It’s weird.Weisenthal: The jury is out still on how AI slots into this. Because on the one hand, you can upload some texts to Claude and ask questions, and it becomes an interactive thing. That’s oral; that’s conversation.[Read: The problem with using AI in your personal life]But those conversations with AI, they don’t feel like other conversations that exist online. The AI is not going to insult you. The AI is not going to speak to you in memes. The AI is not going to use epithets. I’m not trying to one-up the AI either. Ong used the word agonistic; oral cultures are competitive. We see that online, how we’re always competing with one another when we’re talking.AI chatbot communications aren’t agonistically toned. Just the opposite. Most people’s complaint with AI is that it’s too obsequious, that it’s not confrontational enough. I’ll say something stupid to the chatbot, and it’ll say, That’s a really good idea, Joe! Let’s explore that further. This is actually one of the big problems of AI, which is that it’s insufficiently opinionated. The chatbots do not correct you. AI is conversational, but it doesn’t have a lot of these other aspects of conversation that other digital conversations have.Thompson: Maybe the age of social media really was the revenge of orality. But an age of AI would be much more like the revenge of literacy.Ong and Meyrowitz both point to this idea that literacy pulled us into ourselves. Reading is interior. And then novels, in response to the interiority of reading, became more interior. Nineteenth-century novels are incredibly rich about what it is like to be thinking and alive in this moment. It’s not plot, plot, plot. It’s not genealogy. It’s fully inside the phenomenological experience of the characters.And AI, to me, feels much more subvocal. It feels like I’m having a conversation with myself. It’s not myself. It’s this machine that I’m talking with, but it feels more like daydreaming with myself than the antagonistic experience of being on Twitter, where I’m inside the minds of other people, thrust into the faces of strangers whom I’ve never met.Weisenthal: It’s very plausible. It’s not going to look exactly like the previous age of literacy, but it never does. These things come and go. The current age of orality is different, obviously, from the original one. The return to solitude. If you’re going back and forth with the chatbot, you close the computer, you don’t feel that same Oh, they’re still arguing there without me. They’re talking online about me and I’m not there to defend myself. Whatever it is. You don’t quite have that same pull. I think all these things—they’ll live with each other, and there’ll be shades of the past that we hear echoes of, and they’ll be different, and they’ll be similar. And I think it’s good to recognize these patterns and observe them, just for one’s own sanity—to have a sense of what’s pulling you in various different directions.Thompson: To close with the Joeism “What’d I miss?”—what’s important in this space that we didn’t have time to talk about or that I didn’t sufficiently ask?Weisenthal: I just think, by and large, that there are a lot of contemporary pathologies. People point to digital media, the phones, et cetera, as drivers of them. What I would just say is, there’s a lot of writing that I think helps answer these questions, that was written before any of this existed. I would like it if more people became familiar with Josh Meyrowitz, Walter Ong, Eric Havelock, Marshall McLuhan, and so forth. I think I would like that. I just want to talk to people about them.This article was adapted from a post on Derek Thompson’s Substack."
    },
    {
      "title": "derekthompson.org: The Affordability Curse",
      "url": "https://www.theatlantic.com/ideas/2025/11/democrats-cost-of-living-affordability-platform/684847/?utm_source=feed",
      "source": "derekthompson.org",
      "time": "2026-02-23T12:43:14.089533",
      "raw_desc": "To understand what just happened in this week’s elections—notably Zohran Mamdani’s win in New York City, Mikie Sherrill’s win in New Jersey, and Abigail Spanberger’s win in Virginia—wind back the clock five years.In 2020, Joe Biden won by promising that he could restore normalcy to American life. That did not happen. As the biological emergency of the coronavirus pandemic wound down, the economic emergency (inflation) took off. An affordability crisis broke out around the world. The public revolted. Last year, practically every incumbent party in every developed country lost ground at the ballot box.So it went in the United States. In 2024, Donald Trump won an “affordability election.” I’m calling it that because affordability is what Trump’s voters said they wanted more of. Gallup found that the economy was the only issue that a majority of voters considered “extremely important.” A CBS analysis of exit-poll data found that eight in 10 of those who said they were worse off financially compared with four years ago backed Trump. The AP’s 120,000-respondent VoteCast survey found that voters who cited inflation as their most important factor were almost twice as likely to back Trump.So Trump won. And for the second straight election, the president has violated his mandate to restore normalcy. Elected to be an affordability president, Trump has governed as an authoritarian dilettante. He has raised tariffs without the consultation of Congress, openly threatened comedians who made jokes about him, pardoned billionaires who gave him and his family money, arrested people without due process, overseen the unconstitutional obliteration of the federal-government workforce, and, with the bulldozing of the White House East Wing, provided an admirably vivid metaphor for his general approach to governance, norms, and decorum.[Read: ‘None of this is good for Republicans’]A recent NBC poll asked voters whether they thought Trump had lived up to their expectations for getting inflation under control and improving the cost of living. Only 30 percent said yes. It was his lowest number for any issue polled. The affordability issue, which seemed to be a rocket exploding upwards 12 months ago, now looks more like a bomb to which the Republican Party finds itself tightly strapped.So again, we have an affordability election on our hands.On the surface, Mamdani, Spanberger, and Sherrill emerged victorious in three very different campaigns. Mamdani defeated an older Democrat in an ocean-blue metropolis. In Virginia, Spanberger crushed a bizarre Republican candidate in a state that was ground zero for DOGE cuts. In New Jersey, Sherrill—whose victory margin was the surprise of the evening—romped in a state that had been sliding toward the Republican column.Despite these cosmetic differences, what unified the three victories was the Democratic candidates’ ability to turn the affordability curse against the sitting president, transforming Republicans’ 2024 advantage into a 2025 albatross. Here’s Shane Goldmacher at The New York Times:\nDemocratic victories in New Jersey and Virginia were built on promises to address the sky-high cost of living in those states while blaming Mr. Trump and his allies for all that ails those places. In New York City, the sudden rise of Mayor-elect Zohran Mamdani, the democratic socialist with an ambitious agenda to lower the cost of living, put a punctuation mark on affordability as a political force in 2025.\nEach candidate arguably got more out of affordability than any other approach. Mamdani’s focus on the cost of living in New York—which included some genuinely brilliant ads on, for example, “Halalflation” and street-vendor permits—has been widely covered. Less ballyhooed, but just as important, is that Spanberger and Sherrill also found that the affordability message had the biggest bang for the buck in their own advertisements. An analysis shared with me by the polling and data firm Blue Rose Research found that “the best-testing ads in both Virginia and New Jersey focused on affordability, tying rising costs to Trump and Congressional Republicans.”Tuesday night showed what affordability can be for the Democratic Party—not a policy, but a prompt, an opportunity for Democrats to fit different messages under the same tentpole while contributing to a shared national party identity: The president’s a crook, and we care about the cost of living. In New York City, Mamdani won renters by 24 percentage points with a specific promise: freeze the rent. In New Jersey, Sherrill won with a day-one pledge to declare a state of emergency on utility costs, which would allow her to halt rates and delete red tape that holds back energy generation. (The opening line of her mission statement: “Life in New Jersey is too expensive and every single New Jerseyan who pays the bills knows it.”) In Virginia, Spanberger went another way, relentlessly blaming rising costs on Trump.What’s notable is not just what the above messages have in common but what they don’t. Sherrill focused on utility costs, whereas Mamdani focused on rent. Mamdani ran a socialist campaign to energize a young left-wing electorate, whereas Spanberger’s task was to win a purple state with an outgoing Republican governor. Each candidate answered the affordability prompt with a message tailored to the electorate: Affordability is a big tent.The affordability message was especially successful at bringing young voters back to the Democratic fold. After the 2024 election, it looked like young people were listing to the right. Tuesday night was not the ideal test of that theory, because off-year elections tend to have a smaller and more educated (and therefore more naturally anti-Trump) electorate. But the pollster John Della Volpe reported that young voters “anchored the Democratic turnaround” in Virginia, where 18-to-29-year-olds delivered a 35-point margin for Spanberger, the largest for Democrats since 2017.It’s easy to understand why young voters would appreciate an emphasis on the cost of living. Just this week, the National Association of Realtors announced that the median age of first-time U.S. homebuyers has jumped to a new record of 40. “Zohran’s campaign centered cost-of-living issues, and he at least appeared consistently willing to look for answers wherever they may present themselves,” Daniel Racz, a 23-year-old sport-data analyst who lives in New York, told me. “I think of his mentions of the history of sewer socialism, proposed trial runs of public grocery stores on an experimental basis, and his past free-bus pilot program, which showcased a political curiosity grounded in gathering information to improve his constituents’ lives.”Amanda Litman, a co-founder and the president of Run for Something, oversees a national recruitment effort to help progressives run for downballot office. On Tuesday, the organization had 222 candidates in general elections across the country. “Nearly every candidate who won an election for municipal or state legislative office was talking about affordability, especially as it relates to housing,” she told me. “Housing is the No. 1 issue we’ve seen people bring up as a reason to run for office this year.”The affordability approach has several strengths. Because it is a prompt rather than a policy, it allows Democrats to be organized in their thematic positioning but heterodox in their policies. A socialist can run on affordability in a blue city and win with socialist policies; a moderate can run on affordability in a purple state and win with the sort of supply-side reforms for housing and energy that animate the abundance movement. At a time when Democrats are screaming at one another online and off about populism versus moderation, the affordability tent allows them to be diverse yet united: They can run on tying Trump to the affordability crisis while creating messages fit for their respective electorates.[Read: An antidote to shamelessness]This next bit is a little speculative, but another advantage of centering affordability may be that it is easier for members of a political coalition to negotiate on material politics than on post-material politics. Put differently, economic disagreements within a group are more likely to produce debate and even compromise, whereas cultural disagreements are more likely to produce purity tests and excommunication. If a YIMBY left-centrist and a democratic socialist disagree about the correct balance of price controls and supply-side reforms to reduce housing inflation in New York City, that might lead to a perfectly pleasant conversation. But perfectly pleasant conversations between political commentators about, say, ICE deportations or trans women in college sports don’t seem common. If this is true, it would suggest that the spotlight of Democratic attention shifting toward affordability might ameliorate the culture of progressive purity tests in a way that would make for a bigger tent.Affordability politics also poses a distinct challenge. At the national level, Democrats do not have their hands on the price levers, and they won’t for at least four more calendar years. Even if they did, the best ways to reduce prices at the national level include higher interest rates (painful), meaningful spending cuts (excruciating), or a national tax increase (dial 911). Even at the local level, affordability politics in an age of elevated inflation, rapidly growing AI, and complex impediments to affordable housing can easily promise too much—or, to be more exact, offer a set of dangerously falsifiable promises.Affordability politics thrives because of the specificity and clarity of its pledge: Prices are too high; I’ll fix it if you give me power. But politics isn’t just about the words you put on your bumper stickers; it’s about what you do if the bumper stickers work. Building houses takes time, even after reducing barriers to development and improving access to financing. Actually lowering prices can take even longer. Energy inflation is a bear of a problem, with transmission prices rising and data-center construction exploding. After Americans learn whose affordability messages win at the ballot box, they’ll learn whose affordability policies actually work and (perhaps) keep them in office.Affordability is good politics, and a Democratic Party that focuses on affordability at the national level, and supports motley approaches to solving the cost-of-living crisis at the local level, is in a strong position going into 2026. But saying the word affordability over and over doesn’t necessarily guarantee good policy outcomes. In fact, it doesn’t guarantee anything. Which is why at some point on the road back to relevance, the Democratic Party needs to become obsessed with not only winning back power but also governing effectively in the places where they have it.This article was adapted from a post on Derek Thompson’s Substack."
    },
    {
      "title": "derekthompson.org: The Era of Step-on-a-Rake Capitalism",
      "url": "https://www.theatlantic.com/ideas/archive/2025/09/trump-economic-pain-strategy/684166/?utm_source=feed",
      "source": "derekthompson.org",
      "time": "2026-02-23T12:43:14.091088",
      "raw_desc": "Sign up for Trump’s Return, a newsletter featuring coverage of the second Trump presidency.Is Donald Trump a staunch capitalist, a secret socialist, a blend of the two, or none of the above? Depending on the day, it’s hard to tell.Some of his initiatives are pure Ronald Reagan, such as his corporate-income tax cuts and deregulation efforts targeted at oil and gas. Some of his interventions would impress a Democratic Socialists of America chapter, such as demanding a public stake in Intel, requesting 15 percent of revenues from Nvidia’s chip sales to China, and securing a “golden share” of U.S. Steel to retain veto power over its decision making. As for the rest of Trump’s economic policy, it is a hodgepodge of 19th-century mercantilism, developing-world authoritarianism, and extremely online weirdness. The U.S. tariff rate stands near a 100-year high. When Trump isn’t firing the statisticians who calculate unemployment, he’s waging war against the independent central bank or posting about the fierce urgency of corporate-logo design.To put it simply, or at least as simply as one can: Trump’s economic agenda is deeply Reaganite and deeply anti-conservative; somewhat capitalist and frequently socialist; declaratively obsessed with “American greatness” yet constantly sidetracked by online outrages that do nothing for the country.So, what is Trumponomics?[From the April 2025 issue: The real goal of the Trump economy]The most interesting answer I’ve heard is “state capitalism with American characteristics,” which The Wall Street Journal’s Greg Ip defined as “a hybrid between socialism and capitalism in which the state guides the decisions of nominally private enterprises.” This diagnosis makes Trump’s economic policy seem more evolutionary than revolutionary. In the past 70 years, the U.S. government has frequently intervened in corporate affairs, especially in response to emergencies such as World War II (the Defense Production Act), the Great Recession (the bank bailouts), and COVID (the Paycheck Protection Program). Under Joe Biden, Democrats waded into industrial policy with subsidies for clean energy and semiconductors. By one interpretation, Trumponomics doesn’t stand out in history; it’s just the latest example of the federal government taking a more activist role in directing the economy, especially as we try to compete with the juggernaut of authoritarian China, whose modern development was known as “socialism with Chinese characteristics.”But Trumponomics is too erratic to deserve any comparison with state capitalism, especially in relation to China. As the author Dan Wang writes in his new book, Breakneck, China is an “engineering state,” where Beijing’s control over the economy both emerges from long-term planning and radiates outward through millions of local-government representatives. “The core characteristic of China’s state capitalism is discipline,” Wang told Ip. “Trump is the complete opposite of that.”Consider, for example, two simple questions: What are Trump’s tariffs supposed to accomplish, and what are they actually accomplishing? The White House, including the economic adviser Stephen Miran, has repeatedly stressed that higher import taxes will bring back manufacturing and revitalize exports. Neither is happening. Manufacturing output has declined every month since the tariffs were announced, and many firms have explicitly blamed Trump’s tariffs. Meanwhile, the president recently struck a deal requiring Nvidia and AMD to pay the government 15 percent of revenue on the sale of AI chips to China. The logic is genuinely hard to follow on a week-to-week basis. Promoting exports with global tariffs (which might be illegal) is one thing. Taxing exports (which might also be illegal) is another thing. But taxing imports and exports simultaneously doesn’t really comport with any coherent economic strategy. As the economy lists toward stagflation, the White House is not doing “state capitalism” so much as it’s doing “step-on-a-rake capitalism”—a tragicomic bungling of economic growth that fails to advance the very objectives it claims to prioritize.The problem with evaluating this administration’s economic agenda is that Trumponomics is about Trump far more than it is about economics. There is no clear theory of growth steering the U.S. economy, just one man’s desire to colonize every square inch of American attention and experience, which happens to include international markets.Trumponomics, then, is best understood as Trump’s formula for controlling everything around him, rather than an ideology with a telos. That formula has three main components. The first is declaring an emergency to justify intervention. The second is making threats to force private actors to do his bidding. The third is demanding tribute.All presidents have the power to declare emergencies. None has used this power as frequently as Donald Trump.Since 1981, the typical president has declared about seven national emergencies in each four-year term. In the first six months of his second term, Trump has already declared nine, plus a “crime emergency” in Washington. He’s invoked the Alien Enemies Act of 1798 to deport foreigners during a war or invasion, Title X to deploy the National Guard in various cities, and other congressional acts to expedite mining on federal lands. “Even when Trump doesn’t declare a legal emergency, he describes crises that justify dramatic action,” The New York Times’ Adam Kushner wrote. At this rate, Trump is on pace to announce 70 emergencies in this administration, which would nearly match the total number of emergencies announced from 1980 to 2025, according to the Brennan Center for Justice.Emergency declarations have been core to Trump’s economic agenda. Tariffs, the most significant policy initiative of Trump’s current term, kicked off with an emergency declaration. On February 3, the White House announced its first round of tariffs on Canada, Mexico, and China. Although import taxes are typically the domain of the legislature, Trump as president claimed the authority to tax imports under the International Emergency Economic Powers Act, or IEEPA, because of these countries’ alleged failure to stop the flow of migrants and fentanyl.The IEEPA is a 1977 law that allows the president to impose financial regulations, such as sanctions or export restrictions, during a national emergency. But no president before Trump ever used IEEPA to tax imported goods. In August, a federal court of appeals struck down the tariffs as unconstitutional, pointing out that IEEPA gives the executive branch authority to regulate imports but not to tax them. Now that net immigration has plummeted to historic lows, it doesn’t even make sense to claim the power to tax imports based on an alleged migration emergency that has, by all accounts, ended. But the White House has said it will fight for the right to impose tariffs all the way to the Supreme Court.I have said before that the No. 1 rule for understanding Trump is that “a lot happens under this administration, but a lot un-happens, too.” This also is a function of Trump’s “everything is an emergency” style of governance—constantly bending the law into unnatural shapes to justify whatever action the president seeks in the moment.Just as Trump depends on emergency declarations, he also depends on threats. The president creates pain, then demands tribute, at which point he removes the pain.To punish ABC for its negative coverage, Trump threatened to revoke its broadcast license, accepted a $16 million financial tribute from the Walt Disney Company, and then backed down. To punish law firms for litigation against him or his allies, Trump threatened several firms with limited access to government contracts before accepting hundreds of millions of dollars in promised pro bono services to Trump-approved causes. To punish Columbia University for a litany of perceived sins, including its DEI policies, Trump froze hundreds of millions of dollars in federal research funding before the university agreed to pay a large tribute and change its policies.Trump applies the same pain-tribute method to direct international trade and private-firm behavior. In the spring, Trump threatened new tariffs on Japanese and European Union exports. (Pain created.) In response, Japan and the EU agreed to invest more than $1 trillion in the U.S., and Trump himself claimed the authority to direct some of the investment to his favored causes. (Tribute offered.) Then Trump cut both tariff rates by about half. (Pain removed.) Last month, Trump called for Lip-Bu Tan to resign as the chief executive of Intel. (Pain created.) Days later, Tan met with Trump at the White House to work out a deal, and when they emerged, the U.S. government owned 10 percent of his company. (Tribute offered.) Tan remains the CEO of Intel. (Pain removed.)In the aftermath of any one of these events, you might come up with a philosophical justification. You could defend high tariffs because they raise revenue, or you could defend reduced tariffs because they increase the flow of trade among allies. You could defend firing Tan for his alleged Chinese connections and poor performance, or you could defend retaining Tan as long as the U.S. gets a slice of Intel. But you can’t defend all of these opinions at the same time. Each one represents a specific ideological position, and Trumponomics—outside of a basic distrust of trade and fondness for tariffs—is mostly beyond any ideology. The president’s personalist style of politics is optimally designed not to achieve any specific policy outcome but rather to achieve the vanquishing of a counterparty. Tariffs, insults, threats, and Truth Social posts perform a similar function: They create leverage that Trump can use to claim victory, tribute, or both.Trump’s personalist style of politics thrusts America back to the late 19th century and the Gilded Age, when corruption was so rampant that it was broadly considered the cost of doing business. The intercontinental railroads depended on insider trading and stock manipulation, as the historian Richard White has said. Andrew Carnegie illegally supplied information to politicians in exchange for their protection of his steel monopoly. The big industrialists in rail, oil, and steel would promise congressmen and senators jobs after leaving office if they did the companies’ bidding.[Annie Lowrey: Trump is a degrowther]Corruption oozes out of this White House as well. In his first six months in office, Trump accepted a luxury jet as a gift from Qatar and solicited family-business investments from several Arab states; countries around the world are now racing to build Trump golf courses and towers in a rather transparent bid for his approval. When a crypto mogul under fraud investigation bought $75 million in Trump-backed tokens, the SEC paused his civil case, citing the “public’s interest.”I can imagine a Trump supporter who has somehow made it this far into the essay thinking: You just don’t get it. The Chinese are eating our lunch. They’re not just catching up on AI. They make two-thirds of the world’s electric vehicles, more than three-quarters of its electric batteries, 80 percent of its consumer drones, and 90 percent of its solar panels. They make 13 times more steel than the U.S. and build naval ships several orders of magnitude faster than we do. We need a big, rude state-capitalist authoritarian to stand up to the state-capitalist authoritarian that is China. My response to this is: Okay, maybe, but show me any evidence that, given the choice between helping the U.S. against China or helping himself, Trump will actually choose the former? In his first term, Trump insisted that Congress force TikTok to sell itself to a non-Chinese company. In fact, I’d agree that the largest news source for Gen Z probably shouldn’t have an intimate legal entanglement with the Chinese Communist Party. Acting under this logic, House Republicans under Biden voted 186–25 to force a TikTok sale. But after meeting with an investor in ByteDance, the parent company of TikTok, Trump reversed course and has used his executive power to delay the very TikTok sale that (a) he called for and that (b) Congress has legally mandated.There is no secret plan to help America sell more stuff. If anything, it is American policy itself that has been put up for sale."
    },
    {
      "title": "rakhim.exotext.com: Modern UI is clean and invisible? Ha, I wish!",
      "url": "https://rakhim.exotext.com/modern-ui-is-not-invisible",
      "source": "rakhim.exotext.com",
      "time": "2026-02-23T12:43:14.179820",
      "raw_desc": ""
    },
    {
      "title": "rakhim.exotext.com: Alarm is sacred, must not fail, but iOS 26 is wicked",
      "url": "https://rakhim.exotext.com/alarm-is-sacred-but-ios-26-is-wicked",
      "source": "rakhim.exotext.com",
      "time": "2026-02-23T12:43:14.179820",
      "raw_desc": ""
    },
    {
      "title": "rakhim.exotext.com: Examples are the best documentation",
      "url": "https://rakhim.exotext.com/examples-are-the-best-documentation",
      "source": "rakhim.exotext.com",
      "time": "2026-02-23T12:43:14.179820",
      "raw_desc": ""
    },
    {
      "title": "evanhahn.com: Track Zelda release anniversaries in your calendar",
      "url": "https://evanhahn.com/zelda-anniversary-calendar/",
      "source": "evanhahn.com",
      "time": "2026-02-23T12:43:14.362107",
      "raw_desc": ""
    },
    {
      "title": "evanhahn.com: Notes from January 2026",
      "url": "https://evanhahn.com/notes-from-january-2026/",
      "source": "evanhahn.com",
      "time": "2026-02-23T12:43:14.362107",
      "raw_desc": ""
    },
    {
      "title": "evanhahn.com: An LLM that's 7500× stupider",
      "url": "https://evanhahn.com/an-llm-thats-7500x-stupider/",
      "source": "evanhahn.com",
      "time": "2026-02-23T12:43:14.362107",
      "raw_desc": ""
    },
    {
      "title": "xania.org: 2025 in Review",
      "url": "http://xania.org/202512/2025-in-review?utm_source=feed&utm_medium=rss",
      "source": "xania.org",
      "time": "2026-02-23T12:43:14.554323",
      "raw_desc": ""
    },
    {
      "title": "xania.org: Thank you",
      "url": "http://xania.org/202512/25-thank-you?utm_source=feed&utm_medium=rss",
      "source": "xania.org",
      "time": "2026-02-23T12:43:14.554323",
      "raw_desc": ""
    },
    {
      "title": "xania.org: When compilers surprise you",
      "url": "http://xania.org/202512/24-cunning-clang?utm_source=feed&utm_medium=rss",
      "source": "xania.org",
      "time": "2026-02-23T12:43:14.554323",
      "raw_desc": ""
    },
    {
      "title": "antirez.com: \nAutomatic programming\n",
      "url": "\nhttp://antirez.com/news/159\n",
      "source": "antirez.com",
      "time": "2026-02-23T12:43:14.747756",
      "raw_desc": ""
    },
    {
      "title": "antirez.com: \nDon't fall into the anti-AI hype\n",
      "url": "\nhttp://antirez.com/news/158\n",
      "source": "antirez.com",
      "time": "2026-02-23T12:43:14.747756",
      "raw_desc": ""
    },
    {
      "title": "antirez.com: \nReflections on AI at the end of 2025\n",
      "url": "\nhttp://antirez.com/news/157\n",
      "source": "antirez.com",
      "time": "2026-02-23T12:43:14.747756",
      "raw_desc": ""
    },
    {
      "title": "nesbitt.io: Forge-Specific Repository Folders",
      "url": "https://nesbitt.io/2026/02/22/forge-specific-repository-folders.html",
      "source": "nesbitt.io",
      "time": "2026-02-23T12:43:14.940419",
      "raw_desc": "Git doesn’t know about CI, code review, or issue templates, but every forge that hosts git repositories has added these features through the same trick: a dot-folder in your repo root that the forge reads on push. The folder names differ, the contents overlap in some places and diverge in others, and the portability story between them is worse than you’d expect. A companion to my earlier post on git’s magic files.\n.github/\nGitHub’s folder holds:\n\nworkflows/ — GitHub Actions CI/CD configuration (.github/workflows/*.yml)\nISSUE_TEMPLATE/ and PULL_REQUEST_TEMPLATE/ — issue and PR templates\ndependabot.yml — automated dependency updates\nCODEOWNERS — required reviewers for paths\nFUNDING.yml — sponsor button configuration\n\nGitHub also reads some files from the repo root or from .github/: SECURITY.md, CONTRIBUTING.md, CODE_OF_CONDUCT.md. LICENSE must be in the repo root for GitHub’s license detection to pick it up.\nThe .github/workflows/ directory contains YAML files defining Actions workflows. Each file is a separate workflow that runs on events like push, pull request, or schedule.\nCODEOWNERS uses gitignore-style glob patterns to map paths to GitHub users or teams who must review changes:\n# .github/CODEOWNERS\n*.js @frontend-team\n/docs/ @docs-team\n* @admins\n\n.gitlab/\nGitLab uses .gitlab/ for:\n\nci/ — reusable CI/CD templates\nmerge_request_templates/ — MR templates\nissue_templates/ — issue templates\nCODEOWNERS — approval rules\nchangelog_config.yml — built-in changelog generation config\n\nGitLab’s main CI config is .gitlab-ci.yml at the repo root, not in the folder. Projects often keep reusable CI templates in .gitlab/ci/ and pull them in with include:local, though the directory name is convention rather than something GitLab treats specially.\nGitLab’s CODEOWNERS works similarly to GitHub’s but with different approval rule options and integration with GitLab’s approval workflows.\n.gitea/ and .forgejo/\nGitea and Forgejo (a fork of Gitea) support:\n\nworkflows/ — Gitea/Forgejo Actions (.gitea/workflows/*.yml or .forgejo/workflows/*.yml)\nISSUE_TEMPLATE/ and PULL_REQUEST_TEMPLATE/ — templates\n\nForgejo checks .forgejo/ then .gitea/ then .github/ in that order, while Gitea checks .gitea/ then .github/, so you can keep shared config in .github/ and add platform-specific overrides in the forge’s own folder.\nGitea’s CODEOWNERS uses Go regexp instead of gitignore-style globs. Patterns look like .*\\.js$ instead of *.js.\n.bitbucket/\nBitbucket keeps two files in .bitbucket/:\n\nCODEOWNERS — required reviewers\nteams.yaml — ad-hoc reviewer groups\n\nCI config lives at bitbucket-pipelines.yml in the repo root, similar to GitLab’s approach.\nBitbucket’s CODEOWNERS has reviewer selection strategies baked into the syntax:\n# .bitbucket/CODEOWNERS\n*.js random(1) @frontend-team\n/api/ least_busy(2) @backend-team\n/critical/ all @security-team\n\nrandom(1) picks one random reviewer from the team, least_busy(2) picks the two reviewers with the fewest open PRs, and all requires every team member to review. No other forge has reviewer selection strategies in the CODEOWNERS syntax.\nThe .bitbucket/teams.yaml file lets you define ad-hoc reviewer groups without creating formal Bitbucket teams:\n# .bitbucket/teams.yaml\nsecurity:\n  - alice\n  - bob\nfrontend:\n  - carol\n  - dave\n\nThese can then be referenced in CODEOWNERS with the @teams/ prefix, like @teams/security or @teams/frontend.\nFallback chains\nIf you host the same repository on multiple platforms, shared config in .github/ will be picked up by Gitea and Forgejo, with platform-specific overrides in .gitea/ or .forgejo/ taking priority. Bitbucket and GitLab only check their own folders, so multi-platform support across all forges still requires some duplication.\nGotchas\nGitHub’s org-level .github repository lets you set default issue templates, PR templates, and community health files for every repo in the org, but the fallback is all-or-nothing: if a repo has any file in its own .github/ISSUE_TEMPLATE/ folder, none of the org-level templates are inherited and there’s no way to merge them. The org .github repo must also be public, so your default templates are visible to everyone.\nGitHub looks for CODEOWNERS in three places: .github/CODEOWNERS, then CODEOWNERS at the root, then docs/CODEOWNERS. First one found wins and the others are silently ignored. The syntax looks like .gitignore but doesn’t support ! negation, [] character ranges, or \\# escaping. A syntax error used to cause the entire file to be silently ignored, meaning no owners were assigned to anything. GitHub has since added error highlighting in the web UI but there’s still no push-time validation.\nGitLab supports optional CODEOWNERS sections with a ^ prefix, but “optional” only applies to merge requests. If someone pushes directly to a protected branch, the docs say approval from those sections is “still required,” though how that actually works for a command-line push is unclear even to GitLab users.\nThe Gitea/Forgejo workflow fallback is all-or-nothing too: if .gitea/workflows/ contains any workflow files, .github/workflows/ is completely ignored, so you can’t run platform-specific workflows side by side.\nGitea’s CODEOWNERS doesn’t check .github/CODEOWNERS at all, only ./CODEOWNERS, ./docs/CODEOWNERS, and .gitea/CODEOWNERS. If you migrate from GitHub with your CODEOWNERS in .github/, it silently does nothing. And even when it works, CODEOWNERS on Gitea isn’t enforceable: it adds reviewers but there’s no branch protection option to require their approval. Anyone with write access can approve. A regression in Gitea 1.21.9 also broke CODEOWNERS for fork PRs, which wasn’t fixed until 1.21.11.\nForgejo and Gitea both inherited the pull_request_target trigger from GitHub Actions compatibility, which means they also inherited the “pwn request” attack surface. The workflow runs from the base branch with access to secrets, and if it checks out and executes the fork’s PR code, those secrets can be exfiltrated. Forgejo added a trust-based approval system for fork PRs, but pull_request_target workflows still run with write tokens.\nCVE-2025-68937 is a symlink-following vulnerability in template repository processing, filed against Forgejo. An attacker creates a template repository with symlinks pointing at sensitive paths like the git user’s authorized_keys, and when someone creates a new repo from that template, the symlinks get dereferenced during template expansion, allowing the attacker to write arbitrary files on the server. Forgejo was affected through v13.0.1 (and v11.0.6 on LTS). Gitea had the same bug since v1.11 and fixed it in v1.24.7 under a separate advisory.\nThe Forgejo runner also fixed a cache poisoning vulnerability in v10.0.0 where PR workflows could write to the shared action cache, letting a malicious PR poison future privileged workflow runs. It’s unclear whether Gitea’s runner is affected or fixed this quietly, as they haven’t published a corresponding advisory.\nGitHub Actions expressions are case-insensitive. $ matches whether the branch is main, MAIN, or mAiN. Context accesses like secrets.MY_SECRET and SECRETS.my_secret resolve to the same thing. Git itself is case-sensitive, so if your workflow security depends on branch naming conventions, there’s a mismatch that’s easy to miss.\n\nIf you know of other forge-specific folders or have corrections, reach out on Mastodon or submit a pull request on GitHub."
    },
    {
      "title": "nesbitt.io: Whale Fall",
      "url": "https://nesbitt.io/2026/02/21/whale-fall.html",
      "source": "nesbitt.io",
      "time": "2026-02-23T12:43:14.941943",
      "raw_desc": "When a whale dies in the open ocean, its carcass sinks to the abyssal floor and becomes an ecosystem. Marine biologists call this a whale fall, and the body sustains life in three overlapping stages: mobile scavengers strip the soft tissue over months, enrichment opportunists colonise the bones and surrounding sediment for years, and chemosynthetic bacteria feed on the skeleton itself for decades, converting the lipids stored in bone into energy that supports entire communities of specialised organisms. A single whale fall can sustain life on an otherwise barren ocean floor for fifty years.\nMichael Winser mentioned whale fall offhand while we were talking about what happens to the dependency graphs of abandoned projects, and it won’t leave my head.\nA large open source project goes unmaintained. Maybe the maintainer burns out, maybe the company behind it pivots. The project stops getting updates but doesn’t disappear. It sits on GitHub accumulating issues, its last commit receding further into the past, and somebody forks it to start merging the most urgent patches. If the project was popular enough, multiple forks appear, competing for users the way hagfish compete for blubber, though most die quickly and one or two survive on the strength of someone with enough time or institutional support to keep going. OpenOffice became LibreOffice this way, MySQL became MariaDB, Hudson became Jenkins, each a scavenger fork that grew into the canonical replacement through a familiar sequence of fork announcement, migration guide, and “why you should switch” blog posts.\nSmaller projects then start extracting specific modules or building tools that target the dead project’s data formats. Google Reader wasn’t open source, but the same thing happened when it shut down: Feedly, Miniflux, FreshRSS, Tiny Tiny RSS, and a dozen others rushed to fill the vacuum, several of them implementing the Google Reader API or the Fever API not because those were good APIs but because years of RSS clients had been built to speak them. The licence didn’t matter. The interfaces were public, other software depended on them, and that was enough.\nAnd then the structural skeleton, the protocols and file formats and API contracts, goes on supporting specialised communities that may not even know where the bones came from. OpenDocument Format has outlasted the OpenOffice community that created it, sustained by document format libraries across dozens of language ecosystems. Docker donated its container runtime and image format to the Open Container Initiative in 2015. The OCI spec now defines how containers work regardless of runtime. Docker’s own dominance faded; the spec didn’t. Tree-sitter was built for Atom, and after GitHub archived Atom it became the syntax engine inside Zed, Neovim, Helix, and most editors shipped in the last few years.\nSuccession\nThe pattern I keep noticing with unmaintained libraries is successive recolonisation. A project goes quiet, someone forks it, other projects start depending on the fork, and then that fork maintainer burns out too and the whole cycle repeats at a smaller scale. Each generation of fork is typically smaller than the last, with fewer contributors and a narrower user base, until eventually the idea itself migrates rather than the code. Someone in another language ecosystem looks at the accumulated wreckage and decides to rewrite the concept from scratch, carrying the design forward but leaving the implementation behind.\nSass went through this. The original reference implementation was a Ruby gem. When Ruby’s performance became a bottleneck, LibSass rewrote it in C++, and the sassc gem wrapped that for Ruby users. Then LibSass itself was deprecated in favour of Dart Sass, which is now the canonical implementation. The concept migrated from Ruby to C++ to Dart across a decade, each rewrite benefiting from the accumulated bug reports and design arguments of its predecessors, and at each stage there were wrapper libraries in other ecosystems feeding on the structural skeleton of the Sass language spec. Most people writing Sass today have no idea it started as a Ruby gem.\nSuccessive recolonisation has a nasty failure mode. Edera discovered a differential parsing bug in Rust’s tar-rs library that affected every fork downstream: tar-rs itself, async-tar, tokio-tar, and multiple internal forks maintained by companies like Astral (whose fork ships inside the uv package manager). Coordinated disclosure meant contacting around twenty entities across a fragmented fork graph where three of the four library versions were unmaintained and several maintainers were unreachable. The vulnerability existed because the code had been copied forward through successive forks without anyone re-auditing the PAX header parsing that all of them inherited from the original. The bug had been sitting in the bones the whole time, inherited by every fork. Discovering which forks of a package are affected by an advisory is a problem I’m working on separately, because right now nobody has good tooling for it.\nCentOS after the Stream pivot is the same pattern at operating system scale: Rocky Linux and AlmaLinux forked, smaller RHEL-compatible rebuilds appeared in the enrichment layer around them, and the structural skeleton underneath, RPM packaging, systemd conventions, filesystem hierarchy, persisted unchanged regardless of which particular distribution is alive or dead at any given moment.\nLicence changes\nWhen a project switches from an open source licence to a source-available one, the scavenger stage triggers almost immediately, often before the change even takes effect. Redis to Valkey, Elasticsearch to OpenSearch, Terraform to OpenTofu, the pattern by now is familiar enough that the community has it down to a routine: rush to fork the last open commit, compete briefly, and consolidate around one or two survivors. The organism isn’t exactly dead in these cases. Redis the product still has revenue and a roadmap. But from the perspective of the open source ecosystem the body of code has stopped accepting outside contributions, and the forks start drifting from the original the way MariaDB drifted from MySQL.\nThe abstraction layers are the part that lasts. Every project that integrated with the open version faces a choice between following the proprietary version or switching to the fork, and plenty of them just build a compatibility shim instead. Those shims tend to outlast the controversy that created them, feeding quietly on the skeleton of the original API years after the licence debate has cooled off.\nSun Microsystems\nOracle’s acquisition of Sun in 2010 was less a single whale fall than an entire pod dying at sea simultaneously. Java, Solaris, ZFS, DTrace, VirtualBox, NetBeans, GlassFish, Hudson, MySQL, each sank to a separate ocean floor and spawned its own succession. Some produced single dominant forks (Hudson to Jenkins, ZFS to OpenZFS), others scattered into competing lineages (MySQL alone fed MariaDB, Percona, and briefly Drizzle, which itself became a smaller whale fall when it was abandoned), and some bounced between foundations before settling (NetBeans to Apache, GlassFish to Payara and the broader Jakarta EE ecosystem). The structural skeletons underneath all of it, the JVM bytecode format, the ZFS on-disk format, the MySQL wire protocol, are still load-bearing in projects whose developers have never heard of Sun.\nShallow water\nSome projects die in shallow water where the carcass gets recycled quickly. Acqui-hires work this way: the company gets absorbed, the code goes proprietary or gets archived, and the knowledge disperses with the people rather than accumulating in a public carcass that others can feed on. Corporate consolidation has a similar effect, because when a large independent project gets folded into a platform company’s proprietary service, the nutrients get recycled in the water column rather than sinking deep enough for succession to happen.\nI think the current trend of consolidation under cloud providers is reducing the whale fall rate in open source, and that this has second-order effects on ecosystem diversity that nobody is tracking. You could measure it: look at the fork and dependency graphs of dead projects over time, count how many new projects cite a dead dependency, compare the half-life of a whale fall in npm versus crates versus rubygems. Do some ecosystems have deeper ocean floors, slower decomposition, longer-lasting structural influence? The data exists in package registries and forge APIs, but I haven’t seen anyone ask the question.\nAn open source ecosystem where every large project is owned by a platform company, maintained indefinitely or quietly absorbed on death, is one where those enrichment and chemosynthetic stages rarely get a chance to develop, and the small specialised organisms that depend on whale falls for food never get a chance to evolve. The healthiest ecosystems have a steady supply of whale falls, which is an odd thing to root for since it means wishing for the death of large projects, except that the deep ocean floor has no other food source."
    },
    {
      "title": "nesbitt.io: ActivityPub",
      "url": "https://nesbitt.io/2026/02/20/activitypub.html",
      "source": "nesbitt.io",
      "time": "2026-02-23T12:43:14.951104",
      "raw_desc": "ActivityPub is a federated protocol used by public houses in the United Kingdom and the Republic of Ireland for announcing scheduled events, drink promotions, and community activities to patrons and the wider neighbourhood. Each participating pub operates as an independent instance, maintaining its own chalkboard and event schedule while optionally sharing activity information with other instances in the network. First formalised in the early 18th century, the protocol remains in widespread use today, with an estimated 46,000 active instances across the British Isles as of 2024.1\nThe broader network of interconnected pubs implementing the protocol is colloquially known as the fediverse (a portmanteau of “federated” and “diverse,” referring to the range of establishments involved, from village locals to central London gastropubs). Individual participants in the protocol are referred to as actors, a category that includes landlords, bar staff, and in some implementations, particularly opinionated regulars.2\nEtymology\nThe term derives from the compound of “activity” (from Latin activitas, meaning “a doing”) and “pub” (a contraction of “public house”). The earliest known written use appears in a 1714 licensing petition from a Southwark innkeeper requesting permission to “maintain an Activity Pub board of not less than three feet in width” outside his premises.3 Earlier informal references to “the activity of the pub” appear in parish records from the 1680s, though scholars debate whether these constitute use of the compound noun or merely coincidental adjacency.4\nHistory\nOrigins\nPrior to formalisation, British pubs communicated their activities through a variety of ad hoc methods, including town criers, word of mouth, and what the brewing historian Margaret Eaves has termed “aggressive loitering” — the practice of landlords standing in doorways and shouting at passers-by.5 The lack of standardisation led to significant confusion. A 1702 pamphlet from the Borough of Lewes describes a man who attended three consecutive funerals at The King’s Head under the impression they were cheese tastings, the landlord’s handwriting being “of such character as to render all notices indistinguishable.”6\nChalkboard era (1714–1980s)\nThe Publican Notices Act of 1714 required all licensed premises to maintain a visible board, specifying chalk on dark-painted board but no format. Historians call the resulting chaos the “Great Inconsistency” — a period in which no two instances in England announced events in the same way.7\nSome publicans listed events chronologically. Others grouped them by type. A celebrated board at The Lamb and Flag in Oxford listed everything alphabetically, meaning that “Arm Wrestling (Tuesdays)” perpetually appeared above “Wednesday Pie Night,” causing regulars to arrive on the wrong day with a frequency that the landlord described in his diary as “unwavering.”8\nThe Federation Question\nBy the mid-19th century, the growth of brewery-owned tied houses created pressure for a more consistent protocol. In 1872, the United Brewers’ Federation published Recommendations for the Uniform Display of Pub Activities, the first formal specification. The document established conventions still recognisable today: the use of a header line identifying the instance, a chronological listing of weekly events, and the now-ubiquitous phrase “ALL WELCOME” at the bottom, regardless of whether this was true.9\nThe specification was not universally adopted. Free houses resisted what they termed “the tyranny of federation,” and several publicans in the West Country continued to announce events exclusively through the medium of poetry well into the 1920s. A board outside The Bell in Frome reportedly read, in its entirety: “Come Thursday next for song and ale / The pork will not be stale.”10\nThe question of defederation — the deliberate severing of communication between instances — first arose during this period. A group of temperance-adjacent pubs in Birmingham refused to acknowledge or relay event information from establishments they considered excessively rowdy, a practice that the publicans of Digbeth described as “the cold shoulder, applied at institutional scale.”11 The practice persists today; a 2023 survey found that 12% of pubs actively defederate from at least one neighbouring instance, most commonly over noise complaints, poaching of quiz teams, or “personal reasons the landlord declined to elaborate on.”12\nDigital transition\nThe introduction of social media in the early 21st century created a schism in the ActivityPub community. A faction of publicans, predominantly in urban areas, began duplicating their chalkboard announcements on Facebook and Instagram, leading to what the Morning Advertiser described in 2016 as “a crisis of protocol.”13 Traditionalists argued that the canonical source of pub activity information must remain the physical board, and that digital copies were inherently unreliable due to the tendency of pub social media accounts to also post photographs of dogs and unsolicited opinions about the weather.\nThe controversy intensified when several landlords began boosting — the practice of reproducing another pub’s activity announcements on one’s own board, typically to alert followers of events at nearby instances. While some viewed this as a natural extension of the federated model, others considered it a breach of etiquette. A landlord in Stoke Newington was reportedly barred from three neighbouring pubs in 2019 after boosting their curry night announcements with the annotation “OURS IS BETTER.”14\nIn 2018, the Campaign for Real Ale (CAMRA) published a position paper titled ActivityPub: Preserving the Chalkboard Standard, which argued that the physical board remained “the only trustworthy and fully decentralised method of communicating pub activities,” noting that it required no internet connection, could not be algorithmically suppressed, and was resistant to outages except in cases of rain or vandalism.15\nProtocol specification\nActors\nThe protocol defines three categories of actor:\n\nInstance administrators (landlords and landladies): responsible for maintaining the board, scheduling activities, and exercising moderation powers including the authority to block disruptive patrons.\nStaff actors: permitted to update the board on behalf of the administrator, though in practice often reluctant to do so on grounds that “it’s not my handwriting” or “I wasn’t told we’d stopped doing Wednesdays.”\nFollowers (regulars): actors who have established a persistent relationship with a specific instance. A patron becomes a follower through repeated attendance; no formal subscription mechanism exists, though some pubs maintain a mailing list which nobody reads.16\n\nThe question of account migration — the process by which a follower transfers their primary allegiance from one instance to another — is considered one of the most socially fraught aspects of the protocol. Etiquette varies by region, but it is generally understood that a regular who begins frequenting a different pub should not be seen doing so by staff of the former instance, particularly if the new one is visible from the old one.17\nInbox and outbox\nEach instance maintains two conceptual message stores:\n\nThe outbox: the externally facing chalkboard, A-board, or other display visible to the public. This is the primary publication mechanism of the protocol.\nThe inbox: traditionally a physical letterbox, noticeboard, or corner of the bar where community notices, band flyers, and unsolicited offers of DJ services accumulate. The inbox is write-only in practice; items deposited there are seldom read by the instance administrator and are periodically discarded in bulk during cleaning.18\n\nMessage delivery between instances occurs through a process known as inbox forwarding, in which a patron who has seen an activity announced at one pub mentions it at another. The reliability of this mechanism depends entirely on the patron’s memory, sobriety, and willingness to relay information accurately. Studies suggest a message corruption rate of approximately 40% per hop, rising to 70% after 10pm.19\nFormat\nWhile no single format is mandated, the de facto standard for a compliant ActivityPub board includes the following elements:\n\nHeader: The name of the instance, often rendered in a larger or more decorative hand than the body text.\nBody: A chronological list of upcoming activities, typically covering the current week.\nFooter: A welcoming statement and/or the price of the current guest ale.\n\nActivities are generally expressed as a tuple of day, time, and event name, e.g. “THURSDAY 8PM — QUIZ NIGHT.” The use of exclamation marks is permitted but discouraged by CAMRA guidelines, which state that “the activities of a well-run pub should speak for themselves.”20\nAn early attempt to introduce a structured notation for chalkboard content, known as JSON-LD (Joint Standardised Notation for Leisure Displays), was proposed by a committee of the British Beer and Pub Association in 2004. The notation required events to be written in a rigid format with bracketed metadata: “[TYPE:quiz][DAY:thu][TIME:20:00] QUIZ NIGHT.” It was trialled at four pubs in Reading and abandoned within a week after staff refused to use it on grounds that it “looked like someone had a stroke while writing the board.”21\nContent warnings\nSome instances prepend content warnings to specific activity announcements, alerting patrons to potentially divisive content. Common content warnings include “karaoke,” “DJ Dave,” “under-12s welcome,” and “the landlord’s band.” CAMRA guidelines suggest that content warnings should be used “sparingly and only where the nature of the activity might cause a patron to make alternative plans,” though in practice the mere presence of a content warning has been shown to increase attendance by 15%, curiosity being more powerful than caution.22\nWebFinger\nThe WebFinger protocol provides a mechanism for identifying which instance a given actor is primarily associated with. In its traditional implementation, a patron entering an unfamiliar pub would ask a member of staff, “Do you know [name]?” — a lookup request that, if successful, would return the actor’s home instance (e.g., “Oh, Dave? He’s usually at The Crown on Thursdays”). The protocol is named for the physical gesture that typically accompanies the response: a pointed finger indicating the direction of the referenced establishment.23\nWebFinger queries are subject to privacy considerations. A 2019 CAMRA position paper noted that “no patron should be identifiable to a third party through their pub associations without prior consent,” though it acknowledged that in villages with populations under 500, the protocol was “largely redundant, everyone already knowing where everyone drinks and, frequently, how much.”24\nSupported activity types\nThe protocol supports an effectively unlimited range of activity types, though analysis of 12,000 instances conducted by the University of Sheffield in 2019 found that 94% of all announced activities fell into one of the following categories:25\n\n\n\nActivity\nFrequency\n\n\n\n\nQuiz night\n89%\n\n\nLive music (unspecified)\n72%\n\n\nCurry night\n54%\n\n\nOpen mic\n41%\n\n\nMeat raffle\n38%\n\n\nPub quiz (distinct from quiz night, for reasons that remain unclear)\n27%\n\n\nKaraoke\n24%\n\n\nBingo\n19%\n\n\n“Live Sport”\n18%\n\n\nPsychic night\n4%\n\n\n\nThe study noted that “psychic night” appeared almost exclusively in pubs in the North West of England, and that none of them had predicted the study’s findings.25\nInteroperability\nInteroperability between instances remains a challenge. A 2022 trial at a Wetherspoons in Basingstoke attempted to introduce machine-readable QR codes linking to event listings, but was abandoned after three weeks when it was discovered that the code linked to the pub’s 2017 menu and nobody had noticed.26\nSeveral alternative implementations of the protocol have emerged over the years. The Mastodon (a pub in Finsbury Park, London) briefly operated a system in which events were announced by means of a large brass horn mounted above the door, sounded at 500-character intervals. Complaints from neighbours led to the horn’s removal in 2017, though the pub continues to operate a compliant ActivityPub instance using conventional chalk.27\nGovernance\nActivityPub has no single governing body. CAMRA publishes advisory guidelines, and the British Beer and Pub Association maintains a best-practice document, but compliance is voluntary. A W3C (Wessex, Wales, and Cornwall Committee) working group was established in 2015 to develop a formal standard but was dissolved in 2018 after failing to reach consensus on whether “happy hour” constituted an activity or a pricing policy.28\nIn practice, the protocol is governed by what the sociologist Dennis Ethernet has called “the distributed authority of regulars” — a system in which factual errors on a pub’s activity board are corrected not by any formal mechanism but by a patron mentioning it to the landlord, who may or may not act on the information depending on whether they are busy, whether they can find the chalk, and whether they consider the error material.29\nInstance moderation is handled exclusively by the landlord or designated staff. Moderation actions include verbal warnings, temporary suspensions (“you’ve had enough, come back tomorrow”), and permanent blocks, colloquially known as “barrings.” Unlike digital implementations, there is no appeals process, though a blocked actor may submit an informal unblock request by appearing contrite and buying the administrator a drink.30\nCriticism\nCritics have noted that the ActivityPub protocol suffers from several persistent issues:\n\nAmbiguity: The phrase “Live Music Saturday” does not specify genre, start time, volume, or whether the performer is the landlord’s nephew.31\nChalk supply chain issues: During the COVID-19 pandemic, several pubs reported difficulty obtaining chalk, though it was noted that this was the least of their problems.32\nDiscovery: New patrons report difficulty locating active instances, particularly in rural areas where pubs may not be visible from main roads. The protocol provides no native discovery mechanism beyond “walking around and looking.”33\n\nCultural significance\nThe ActivityPub board has been described as “the last surviving commons of British civic life”34 and “a chalkboard outside a pub.”35 Its persistence in the digital age has been attributed variously to tradition, the aesthetic appeal of chalk lettering, the unreliability of pub Wi-Fi, and the fact that most instance administrators are too busy to maintain a website.\nThe term toot — meaning a brief, informal announcement made by a pub to its followers, typically shouted from the doorway or written in abbreviated form on an A-board — has seen renewed interest among protocol historians. The word derives from the practice of sounding a horn or whistle to announce last orders, and its use as a general term for any short pub announcement dates to at least the 1890s.36 A campaign by the Free House Alliance to replace the term with “post” in 2023 was met with indifference.\nThe Victoria and Albert Museum acquired a complete ActivityPub board from a closed instance in Bermondsey in 2023, describing it as “a significant example of vernacular British communication design.” The board reads: “TUES — QUIZ. WED — CURRY. THURS — KEITH.”37 The museum was unable to determine who Keith was or what he did on Thursdays, as the pub had been converted into flats.\nSee also\n\nChalkboard\nMeat raffle\nPub quiz\n“Keith” (disambiguation)\nCampaign for Real Ale\nA-board (pavement signage)\nThe Great Inconsistency (1714–1872)\nDefederation (social policy)\nThe Mastodon (pub)\n\nReferences\n\n\n\nBritish Beer and Pub Association, Statistical Handbook 2024, p. 41. ↩\n\n\nEthernet, D. The Sociology of the Local. Polity Press, 2021, p. 12. ↩\n\n\nEaves, M. (2003). Signs, Boards, and Barrels: A History of Pub Communication. Faber & Faber, p. 112. ↩\n\n\nChegg, S. “On the Etymology of ActivityPub: A Compound or a Coincidence?” Journal of Brewing History, vol. 29, no. 3, 2011, pp. 44–51. ↩\n\n\nEaves (2003), p. 78. ↩\n\n\nLewes Borough Archives, Pamphlet No. 1702-34, “A Complaint Concerning the Illegible Notices of One Mr. Thos. Harding.” ↩\n\n\nEaves (2003), pp. 115–130. ↩\n\n\nDiary of Dennis Plimsoll, landlord of The Lamb and Flag, 1742–1768. Bodleian Library, MS. Eng. misc. c. 491. ↩\n\n\nUnited Brewers’ Federation. Recommendations for the Uniform Display of Pub Activities. London, 1872. ↩\n\n\nCrumpet, G. “Verse and Ale: Poetic ActivityPub in the West Country.” Somerset Archaeological and Natural History Society Proceedings, vol. 148, 2004, pp. 201–210. ↩\n\n\nEaves (2003), pp. 142–145. ↩\n\n\nSausages, S. and Waffle, P. “Inter-Instance Communication Patterns in British Pub Networks.” Leisure Studies, vol. 42, no. 1, 2023, pp. 88–103. ↩\n\n\n“Is the Chalkboard Dead?” Morning Advertiser, 14 March 2016. ↩\n\n\n“Landlord Barred After Boosting Rival Curry Night.” Hackney Gazette, 4 November 2019. ↩\n\n\nCampaign for Real Ale. ActivityPub: Preserving the Chalkboard Standard. CAMRA Publications, 2018. ↩\n\n\nEthernet (2021), pp. 67–71. ↩\n\n\nIbid., pp. 89–94. Ethernet devotes an entire chapter to what he calls “the migration problem,” noting that in close-knit communities the act of changing one’s regular pub carries “a social weight roughly equivalent to divorce.” ↩\n\n\nSausages and Waffle (2019), p. 506. ↩\n\n\nIbid., p. 509. The authors acknowledge that the post-10pm figure may itself be unreliable, the data having been collected after 10pm. ↩\n\n\nCAMRA (2018), Appendix B, “Guidelines on Tone.” ↩\n\n\nBritish Beer and Pub Association, Internal Report No. 2004-17, “Pilot Study: Structured Notation for Pub Activity Boards.” Unpublished; leaked to The Publican in 2006. ↩\n\n\nCAMRA (2018), Appendix D, “Content Advisories.” ↩\n\n\nEaves (2003), pp. 201–204. ↩\n\n\nCampaign for Real Ale. Privacy and the Pub: A Position Paper. CAMRA Publications, 2019. ↩\n\n\nSausages, S. and Waffle, P. “A Quantitative Analysis of British Pub Activity Boards.” Leisure Studies, vol. 38, no. 4, 2019, pp. 502–518. ↩ ↩2\n\n\n“QR Code Trial Quietly Abandoned.” Basingstoke Gazette, 8 September 2022. ↩\n\n\n“The Mastodon: A Brief History of the Horn.” Finsbury Park Local, 12 January 2018. ↩\n\n\nW3C Working Group minutes, 2015–2018. Archived at the British Beer and Pub Association, File No. WG-2015-009. ↩\n\n\nEthernet (2021), p. 134. ↩\n\n\nIbid., p. 156. Ethernet notes that the success rate of informal unblock requests correlates strongly with the quality of the drink offered. ↩\n\n\nSausages and Waffle (2019), p. 514. ↩\n\n\n“Pubs Face Chalk Shortage Amid Pandemic.” The Publican, 2 November 2020. ↩\n\n\nEthernet (2021), p. 178. ↩\n\n\nEthernet (2021), p. 201. ↩\n\n\nDiesel, V. “What Is a Pub Chalkboard?” The Guardian, 17 July 2019. ↩\n\n\nEaves (2003), pp. 88–91. ↩\n\n\nVictoria and Albert Museum. Recent Acquisitions: Bermondsey Pub Board (Acc. No. 2023-1147). V&A Online Collections. ↩"
    },
    {
      "title": "micahflee.com: Is everyone in your Signal groups named something like \"E\" or \"🥑\"? Nicknames can help!",
      "url": "https://micahflee.com/are-your-signal-groups-full-of-people-name-things-like-l-or-sinicknames/",
      "source": "micahflee.com",
      "time": "2026-02-23T12:43:15.205321",
      "raw_desc": ""
    },
    {
      "title": "micahflee.com: Jeffrey Epstein Bought Books About Pedophilia, Woody Allen, and Trump",
      "url": "https://micahflee.com/jeffrey-epstein-bought-books-about-pedophilia-woody-allen-and-trump/",
      "source": "micahflee.com",
      "time": "2026-02-23T12:43:15.205321",
      "raw_desc": ""
    },
    {
      "title": "micahflee.com: How to easily dig through the Epstein files yourself",
      "url": "https://micahflee.com/how-to-easily-dig-through-the-epstein-files-yourself/",
      "source": "micahflee.com",
      "time": "2026-02-23T12:43:15.205321",
      "raw_desc": ""
    },
    {
      "title": "entropicthoughts.com: Learning KeyBee",
      "url": "https://entropicthoughts.com/learning-keybee",
      "source": "entropicthoughts.com",
      "time": "2026-02-23T12:43:15.233428",
      "raw_desc": ""
    },
    {
      "title": "entropicthoughts.com: Wilks' Tolerance Intervals",
      "url": "https://entropicthoughts.com/wilks-tolerance-intervals",
      "source": "entropicthoughts.com",
      "time": "2026-02-23T12:43:15.233428",
      "raw_desc": ""
    },
    {
      "title": "entropicthoughts.com: Laws of Succession",
      "url": "https://entropicthoughts.com/laws-of-succession",
      "source": "entropicthoughts.com",
      "time": "2026-02-23T12:43:15.233428",
      "raw_desc": ""
    },
    {
      "title": "construction-physics.com: Reading List 02/21/26",
      "url": "https://www.construction-physics.com/p/reading-list-022126",
      "source": "construction-physics.com",
      "time": "2026-02-23T12:43:15.479157",
      "raw_desc": ""
    },
    {
      "title": "construction-physics.com: Is the Future “AWS for Everything”?",
      "url": "https://www.construction-physics.com/p/is-the-future-aws-for-everything",
      "source": "construction-physics.com",
      "time": "2026-02-23T12:43:15.479157",
      "raw_desc": ""
    },
    {
      "title": "construction-physics.com: Reading list 02/14/26",
      "url": "https://www.construction-physics.com/p/reading-list-021426",
      "source": "construction-physics.com",
      "time": "2026-02-23T12:43:15.479667",
      "raw_desc": ""
    },
    {
      "title": "tedium.co: Markdown’s Moment",
      "url": "https://feed.tedium.co/link/15204/17278321/markdown-growing-influence-cloudflare-ai",
      "source": "tedium.co",
      "time": "2026-02-23T12:43:15.531212",
      "raw_desc": "For some reason, a bunch of big companies are really leaning into Markdown right now. AI may be the reason, but I kind of love the possible side benefits.So, here’s something that I didn’t expect to be saying in 2026: There seems to be a nonzero chance that Markdown might become the new RSS.“Whoa, crazy talk! It’s not even a protocol!” I hear you saying. But the evidence has seemed to pick up of late in a couple of different directions.The first is the budding interest in publishing on the AT Protocol, which is working to solve the network-effect challenges that have forced many of us to send newsletters rather than post blogs on RSS feeds.That’s exciting, if incredibly niche. But simultaneously, massive developer platforms are starting to offer something called “Markdown for Agents”—something Cloudflare announced late last week, and which Laravel Cloud quickly followed up on a few days later. And Vercel jumped on it a couple of weeks ago.(The news wasn’t all good for Markdown, but most of it was.)Some SEO old hands, like my friend Jon Henshaw, have reacted to this news with skepticism, having had bad old memories of Google AMP and its sibling technologies Signed Exchanges and Core Web Vitals:It’s 2026, and now I’m reading everywhere that all our pages must have Markdown versions, and it feels like AMP (and SXG and CWV) all over again. Except this time, the promise is that AI agents will better understand and interact with your site if you have them. The rationale is that HTML is too complex and consumes too many tokens to parse and analyze content. Whereas Markdown pages, with their simplicity, are ideal.(Side note: Core Web Vitals make me want to pull my hair out.)Jon is a smart guy and follows this stuff closer than me (Coywolf News is a great site), but I will casually defend this push towards Markdown as a lingua franca of the Web. (Not the agentic Web. Just the Web. More on that later.) I actually think it’s really a great move for publishers that comes with way fewer inherent issues than Google AMP ever did.For one thing, this is all standards-based, not something that was just invented that you need to manage. It’s literally using existing content negotiation headers that web servers already support, not forcing folks to learn something new. Plus it’s hard to argue with a point like this from Vercel:A typical blog post weighs 500KB with all the HTML, CSS, and JavaScript. However, the same content as Markdown is only 2KB. That’s a 99.6% reduction in payload size.That’s good for budget-minded AI agents, but it’s also good for people who run websites.Additionally, Markdown has been in increasingly wide use for 20 years, and it keeps growing in popularity—and unlike the weird carousels and oddly specific rules of Google AMP, lots of people know how to use it. And the use of headers to deliver Markdown pages is already baked into Web standards, just waiting for folks to use it. Sponsored By … You? If you find weird or unusual topics like this super-fascinating, the best way to tell us is to give us a nod on Ko-Fi. It helps ensure that we can keep this machine moving, support outside writers, and bring on the tools to support our writing. (Also it’s heartening when someone chips in.)We accept advertising, too! Check out this page to learn more.OK, so how many of these servers are getting flooded with requests from AI agents right now? (DepositPhotos.com)This is really a tactic to help site owners avoid an AI-generated hug of deathPlus, there’s the rendering—Markdown is an antidote to the internet we currently run, which is highly dependent on programming languages and visual tricks that AI agents and honestly most people don’t even need. To me, when I see, “Cloudflare wants to give every webpage a Markdown version,” my thought is essentially, “Oh, they want to make AI agents stop DDoSing these poor PHP servers that still dominate the internet.”When I see publishers talking about how their sites are getting flooded with viewers and getting slammed with unwanted hosting bills, it is clear that what we are doing is not tenable. Having Cloudflare put up a static Markdown file that takes up less space and has 0% of the JavaScript of the main page sounds like a win to me.And if you’re building your pages semantically, as many publishers are likely already doing because they want to rank on Google, converting all that content to Markdown is going to be a cinch. Frequent Tedium skepticism target Matt Mullenweg is pushing for its addition to the WordPress.org website.Just imagine, if you’re running an open-source project, and you didn’t have to force your users to see a loading page with anime characters just to keep the site online. Instead, you could tell Claude and Gemini and Perplexity to grab the data in a format they already use, and serve that in a static form, saving your poor forum from being drowned in dynamic requests.There are lots of ethical qualms with AI, and you may want to just block them entirely, as is your right as a site owner. But I think diminishing a new-every-load HTML page to an unchanging Markdown file could save a lot of processing cycles for legacy server owners who have been trying to keep an extremely popular wiki online for 20 years.I think there are websites and forums out there that have been absolutely wrecked by the rise of AI. Cloudflare, while still facing periodic reputational issues, has offered itself up as a line of defense for publishers. That’s noble—and while I get not everyone likes them, I think this particular offering is a good-for-the-internet move long-term.And while we’re at it, let’s start printing books in Markdown. Yeah! Let’s really take this idea to an extreme! (DepositPhotos.com)But hear me out: What if we just offered our pages in Markdown because it made the internet more accessible?Yes, the reason for all of this is AI, because everything is about AI right now, but honestly, it would be a really awesome thing to offer for regular users, too.Recently, I’ve been trying to take on a project with the Tedium website—it’s not quite done yet, but I’m trying to get the whole thing onto the AT Protocol, mimicking my upload of my Twitter archive to Bluesky. (I’ve gotten the upload to work, it’s just the details that need to be tweaked. Here’s a sample post that came out okay.) I’m using a tool called Sequoia, which makes it possible to plug a static site into the same protocol Bluesky uses. It parses the roughly 1,300 pages and then uploads them to a server on the ATmosphere.Genuinely cool to see this kind of collab happening in the ATmosphere.At the center of this is something called Standard.site, which aims to make a space for long-form content on the AT protocol. It’s not prescriptive to Markdown, though you could use it to share posts in Markdown if you wanted. It sounds promising—and like the budding efforts in the fediverse, it aims to make content easier to discover. Which is the problem RSS hoped to solve a quarter-century ago, admittedly—but this is doing it with more glue.To me, I see a connection between the push to make Markdown an undercurrent of the agentic Web and this weird experiment on the fringes of emerging social tech. And honestly I would not be surprised if web browsers plugged into these AI-targeted Markdown feeds to give users a lightweight experience. (You know what else could use this?!? Email.)It’s so fascinating, seeing this thing I’ve come to really appreciate as a writer turn into this ad-hoc building block of the modern internet. Even if I find it uncomfortable that AI is the vessel it rode in on.When I found it, it was my superpower—the tool I used to plow through five articles a day at a new job. It was the cruft-buster, the starting point, the README file. And now it’s become something else entirely—something that could get us back to basics without the extra cruft of AMP or the stress of Core Web Vitals. (And even better, that didn’t come from Google.)Honestly, I’m kind of here for it.Update 02/18/2026Looks like I’m not the only one thinking in this direction. Shout-out to Brett Terpstra, a guy who knows a thing or two about Markdown.Markdown-Free LinksWe’ve been losing a lot of good music folks of late, most recently Billy Steinberg, the dude who wrote “Like A Virgin” and “I Touch Myself.” Fortunately, friend of Tedium Chris Dalla Riva got to chat with him in 2023.I know a fellow traveler when I see one, and with that in mind I want to give a shout to Rabbit Hole, a new-ish YouTube channel that recently asked why office chairs have five legs. A promising start.Also, we have to mention Jesse Jackson, a civil rights icon and easily the most well-known “shadow senator” in U.S. history.--Find this one an interesting read? Share it with a pal!And a quick shout to our sponsor la machine, which doesn’t support Markdown, but has a good reason for not doing so."
    },
    {
      "title": "tedium.co: Project Code Name",
      "url": "https://feed.tedium.co/link/15204/17277502/corporate-turnaround-code-names-history",
      "source": "tedium.co",
      "time": "2026-02-23T12:43:15.539398",
      "raw_desc": "Why do corporate restructuring plans get code names the way operating systems do? And why are the names often so bizarre?Today in Tedium: Recently, Amazon did something kind of annoying in the midst of doing something painful. It laid off a ton of people, but in the midst of doing that, it accidentally dropped an email revealing the layoffs early, before people got laid off. That email revealed that this layoff had an official code name, “Project Dawn,” which presumably speaks to the idea of wiping the grime away, like dish soap. It sounds insane, but companies have been taught to name initiatives after random things for decades, sometimes to celebrate successful initiatives, sometimes to lay off thousands of people. (I’m sure Will Lewis named the recent Washington Post layoff endeavor “Project Zoom Ghosting.”) Why are they such a corporate fixation—even for layoffs? Today’s Tedium ponders why corporate culture is so dominated by code names. — Ernie @ Tedium“[W]hen several stations are connected by the same wire, the attention of the particular station for which the message is destined must be secured. This is done by signalling, not the full name of the station, which would occupy time, but an abbreviated name, consisting of two or three letters, assigned to that particular station and known as its code name. Thus, LV is Liverpool, EH Edinburgh, and so on.”— A passage from a 1888 issue of The English Illustrated Magazine, a turn-of-the-century periodical, discussing how the British Post Office used code names to help make sense of the complexities of the telegraph system. (This appears to be one of the first uses of the term “code name.”) Eventually code names would expand to businesses in general, with New York City setting up a central bureau for registered addresses in 1919, with the goal of avoiding mix-ups on the telegraph line. (Think of them as the domain names of the 1920s.)Was this the type of “Dawn” that Amazon was referring to? (DepositPhotos.com)The code name has become an essential part of how the tech industry operatesWhen you’re building a project, and you don’t quite know where it is and what it’s going to turn into yet, a code name can be quite an asset. It’s a tool that can help a project coalesce around a set of ideas, and it doesn’t necessarily need to be something that the public ever sees.In fact, it may actually be better if the public never knows about them. Often, you don’t want to reveal something while it’s incubating. As the Tumblr site Ask a Gamedev put it in 2022:It’s important to note that the reason for secrecy is primarily for marketing purposes. We want to keep a big project quiet until we’re ready to show it and get players excited for it. If our product is tied in with another product or IP with a big planned push at some point in the future, tipping our hand too early can lead to a cascading set of reveals we or our business partners were unready to make. For example, revealing a new mainline Pokémon game too early would spill the beans on an entire new Pokémon generation, which would affect merchandise, animated series, and so on. As a result, we usually put in safeguards to prevent such leaks from happening, both punitive and practical.Code names, also known as code words, have a long history that often criss-crosses through the two World Wars, and perhaps through some of the world’s largest intelligence agencies. That they bled into business is not wholly surprising, as large companies deal in trade secrets all the time—even fast-food chicken restaurants.But what’s unusual is that, particularly in the technology industry, these code names often have a long shelf life, one that can stick around for years after the fact. The word Mozilla, the name of the company that produces Firefox, started as the code name of Netscape Navigator, the web browser upon which Firefox is based.Aspire to look this cool. (San Francisco Chronicle/Newspapers.com)It wasn’t like the Netscape team hid it—back in the ’90s, employees of the company actually decked out Mozilla gear in photos for the San Francisco Chronicle.“Every great project starts out with a T-shirt, and to make a good T-shirt you need a good code name, something like ‘Terminator’ or ‘T-Rex,’” Gene Wang, a software development manager at Symantec, told the Chronicle in 1996. (Apparently he was not aware Mozilla already had the dinosaur metaphor covered.)The technology industry has long been shaped by code names, to the point where those code names break out of their holding cage and end up defining the product. Apple in particular is infamous for this, with the animal and landmark names that define MacOS starting as code names but eventually becoming product names.You used Chicago, but probably didn’t even realize it.Operating systems are a natural reason to have a code name, by the way. In a Bluesky thread from 2024, Microsoft old hand Larry Osterman, who has been at the company for more than 40 years, explained how these code names, such as “Chicago,” the nickname for Windows 1995, would bleed into the public discourse. They existed because these were lengthy projects that existed before the marketing team had weighed in on a name. However, the dynamic that necessitated these monikers has faded somewhat.“Code names leak. Both to the public and into other artifacts (files with code names in them, config settings, etc.),” he wrote, explaining why references to Chicago appear in the operating system. “And in a world where you release every 3-6 months, you really don’t need code names, because the release is so small.”(Someone tell that to the Ubuntu team, which famously gives its twice-yearly iterations alliterative animal-themed code names, most recently “Questing Quokka.” I imagine that must get hard to plan for on Q releases.)And while software release schedules have gotten faster, internal projects still need code names, and sometimes there are so many code names that you need a system to manage them. In a 2007 blog post, Stack Exchange co-founder Jeff Atwood said his team went through so many that they had to develop a system to generate new ones.“The names are chosen alphabetically from a set of items; every new project gets a name from the set,” he wrote. “We start with A, and when we finally arrive at Z, we pick a new set of items for project name inspiration.”Microsoft has so many code names that it has a quite-long Wikipedia page dedicated to them. So does Apple.But as far as I can tell, they have yet to give their layoffs a code name.“I don’t want to spell out the idea on the insecure email channel. Even if you say the phrase ‘Video H or N’ in public, people will know what you mean, so let’s just call it Video. Don’t say it in combination with the H or N site :)”— Jawed Karim, one of the co-founders of YouTube, discussing (according to Internal Tech Emails) how the trio of co-founders, still at PayPal, should talk about their formative idea that would end up taking over the world. (What’s “H or N”? Easy: The platform was originally intended to be a HotOrNot for video. That was too specific—but it ended up inspiring the actual idea.)I’m not sure who I feel worse for—the people this stock photo represents, or the stock photo model themselves, knowing that they’re going to represent layoffs until the end of time. (DepositPhotos.com)But enough about startups and operating systems. Do companies really give their layoffs code names?When a company is attempting to do something sensitive, like poach a CEO, it’s likely they may not want to spell out exactly what is going on before they pull the trigger.Case in point: In the months before Yahoo! brought on Marissa Mayer as their CEO, Mayer had to frequently talk about the shift in secret. She was still working at Google, and there was also the risk the news would leak to the media. So what did she and Yahoo! do? They gave the initiative a code name, “Project Cardinal.” This allowed her to set up her exit plan in secret, while avoiding, say, tipping off her limo driver.Mayer got hired rather than fired in that situation, but one presumes that a similar motivation might lead a company to bury an initiative behind a code name.Just be happy that they aren’t giving these restructuring code names matching logos. Or maybe they are, because that’s something a graphic designer wants to work on. A logo for layoffs. (Willis Lam/Flickr)It can also provide organizational cover when doing something that negatively harms employees. To offer an example: Red Robin recently announced the closure of a number of restaurants as part of a broader “North Star” initiative aimed at improving service while fighting against a wave of shutdowns. (They’re not alone: Last spring, the fast food chain Jack in the Box announced its “Jack on Track” plan, which includes a “restaurant closure program.”)Eventually, things can get more serious than these situations, which require more intense strategizing. There’s a term for what these companies are doing: “Turnaround management,” which refers to the optimization of businesses to stay solvent. Turnarounds can happen at any time in a business’ history, though the concept is most associated with businesses nearing bankruptcy.These plans can really hurt, as in the case of Ford’s “Way Forward,” first undertaken in 2006. That plan involved more than 25,000 job cuts, which was dramatic and painful—but it helped Ford avoid the brutal bailouts General Motors and Chrysler required. In 2009, while those companies were barely holding on, Ford actually posted a profit.Which is to say that, while turnaround plans can seem callous and unfair to affected workers or even customers affected by decreased service, they can absolutely save companies. It’s a bloodletting tool.But that’s not to say every turnaround code name is a good one, and the worst ones can signal a sense of panic, as noted in a 2015 on the topic in Bloomberg (archive link).“There are different degrees of distress,” turnaround consultant Margaret Bogenrief told the outlet. “Generally, the more grandiose the name, the more severe the distress.”This compass represents just one of the three restructuring initiatives General Mills had going on in the mid-2010s. (quimby/Fickr)Of course, there can be a degree of silliness that comes with anything complex and corporate. Around 2015, General Mills announced not one, not two, but three separate corporate restructuring projects: Project Compass, Project Century, and Project Catalyst. These three projects each touched on different parts of the company, with Project Compass focused on its international markets, Project Century its North American manufacturing, and Project Catalyst its organizational effectiveness. These projects cost hundreds of millions of dollars collectively and came with more than 1,500 layoffs. And to the layperson, it just sounds hopelessly complex.Kellogg’s, meanwhile, had been down this road multiple times itself. In 2009, the company announced K-LEAN, an initiative to increase optimization (and which led to layoffs in its factories). Then, in 2013, they followed it up with Project K, which aimed to reorganize the various company segments … and which also led to layoffs.Ultimately, Kellogg’s decided to split off its legacy cereal business into its own company, WK Kellogg Co., and rename the larger snack food business as Kellanova. Both companies ended up getting sold to large candy companies recently—WJ Kellogg to Ferrero, Kellanova to Mars.With this framing, turnaround projects can be seen as corporate salvaging missions first, layoff plans second. But honestly, that struggles to explain Amazon, a company that made $21.2 billion in net income in the prior quarter alone. Sometimes a job cut is just a job cut, no turnaround necessary.Dude, you’re getting a Dell … 2.0. (Casey Marshall/Flickr)Five typical naming schemes for corporate projectsLeaning into the puns and metaphors. It’s not just Jack in the Box leaning into the punny turnaround project names. Companies do this all the time— A 1991 Reuters wire story, for example, describes how Bank of America named an attempted acquisition of Security Pacific “Project Sunshine,” while another attempted merger was named after the companies’ local NHL teams. More recently, Panera announced its “Panera RISE” strategy, which plays off its most popular product.Proposing an upgrade. I’ve traditionally been sort of snarky about Dell, a company that in my mind screams “enterprise” and “lack of creativity.” So I guess when I hear Dell once named a reorganization effort “Dell 2.0,” the thought that runs through my head is, “checks out.” More recently, Intel has also gone down this road with its IDM 2.0 project for expanding its manufacturing—though Pat Gelsinger got booted before fully seeing it through.Dropping a strong hint. After hiring a new CEO good enough to make Howard Schultz go away, Starbucks leaned into a turnaround plan called “Back to Starbucks,” which is what it wants customers to do. (Similarly, JCPenney’s endeavor is called “Yes, JCPenney.”) This also works when the goal is laying people off—as shown by Kellogg’s K-LEAN, mentioned above.Setting a deadline. Turnaround strategies are often built around significant goals. Sometimes, those goals include dates—and sometimes those dates are way out, as seen from German automaker Opel, which set a “DRIVE!2022” campaign way back in 2013. (They really wanted to get ahead of that date.) Some other examples include Air France-KLM’s “Perform 2020,” and the Trump administration’s “Project 2025.” Yes, even political parties do it.New-agey abstraction. But most notably, so many turnaround project names fall into vague, shapeless territory, not necessarily setting a goal as much as a subtle hint as to where they want to go. General Mills’ “Project Catalyst” is a great example of this, as is Red Robin’s “Operation North Star” and Amazon’s aforementioned Project Dawn. Another example is “Project Phoenix,” set into place by Newell Brands, the owner of the Coleman, Rubbermaid, and Yankee Candle brands. Perhaps it’s because “Project Mass Layoff” doesn’t roll off the tongue quite so easily.“Simplification often feels risky because it appears to be a contraction. But in a turnaround, complexity is a liability.”— Daniel Schmeltz, a corporate transformation expert, writing in Fortune about why most corporate turnaround endeavors fail. In the piece, he argues that slow-going turnaround plans are typically the most unsuccessful. “Hesitation and complexity are liabilities; clarity and rapid execution are non-negotiable,” he writes. “In a time when so many companies are attempting a turnaround, by acting decisively, businesses can cut through inertia, rebuild momentum, and secure sustainable results.” If you’re going to chop off a limb or two, get it over with—perhaps with a little less creativity in the code name.I think code names naturally engender discomfort for people, in part because of what they represent. They are often used to hide something from view, and that thing can be nefarious, even troubling.Recently, Cleveland Guardians pitcher Emmanuel Clase has faced allegations that he was receiving money from “microbets” made on his own pitches. In other words, he was manipulating pitches to secure winning bets on himself, then gamblers were sending some of that money his way.When talking about this with one of the betters, they reportedly hid what they were doing by using coded language, like “rooster” and “chicken.” Clase has attempted to claim that they were discussing cockfighting rather than pitching, an activity Clase also gambled on. (Interesting defense strategy—I wasn’t gambling on games, I was gambling on animal abuse.)Clase was (at least based on allegations in court records that he has denied) trying to get away with something nefarious. Broken down, the reason for the cloak-and-dagger stuff was not all that dissimilar to why Marissa Mayer did it.Ah, what the hell, let’s dunk on Project Dawn one more time. (DepositPhotos.com)One might argue that many of the above listed companies were trying to shroud their not-so-friendly plans in friendly language. You can’t quite say, “we need to lay thousands of people off,” and you definitely can’t say “we want to lay thousands of people off.” But to cloak it in “Phoenix,” “Dawn,” or “North Star,” it makes the bad news digestible. It makes room for a little compassion for the HR team as they’re delivering the bad news.Well, unless you’re an executive for Amazon and you casually drop a doublespeak-style code name in everybody’s inbox.--Well, I guess I was feeling salty today! Find this one an interesting read? Share it with a pal.And thanks to our sponsor la machine, a machine that doesn’t need a code name—because its purpose is transparent as can be."
    },
    {
      "title": "tedium.co: Design Deconstruction",
      "url": "https://feed.tedium.co/link/15204/17276365/text-based-design-mindset",
      "source": "tedium.co",
      "time": "2026-02-23T12:43:15.544144",
      "raw_desc": "Design is perhaps the software paradigm most wedded to the mouse and the GUI. But there’s no reason it can’t be text-driven.To me, the hard part about being creative is that you’re always trying to look for a new path.Sure, you’ve done things a certain way for a long time, and it’s worked for you. But it’s hard not to want to dabble in new directions just to see where it takes you, and hope that it shakes out a new idea or two.Which is perhaps the reason I’ve started to fixate on a weird idea—that design tools might sometimes work better without an attached graphical interface. Rather than graphics in, graphics out, maybe sometimes it should be text in, graphics out.The myth about design is that it’s a function of the creativity-driven right side of the brain. But I think that’s only half the story. See, with design, there’s a lot of hidden math involved. Ask your favorite newspaper or magazine designer about pica rulers and column lengths, and you’ll get what I’m saying.Put another way: Designers need to be creative problem solvers, painting the perfect canvas, but they also need to be pragmatic, considering the realities of “yes, it’s long, but we have to fit this text.”Tools like InDesign and Final Cut Pro have traditionally combined the canvas and the broader frameworks that make a good design, mixing tools with differing cognitive loads into one interface. But what if design needs to be a bit more deconstructed, where pieces are more separated out, perhaps not even graphical? What if you designed with code? Would that lead to better results? I wanted to find out.Hey, you never know when you’re gonna need a terminal in Android.The spark that caused my weird design-with-code obsessionI stumbled upon the idea accidentally, but this weird interest grew out of some genuine frustration.I wanted to try a couple of experiments with vertical video, seeing if I liked it and how comfortable I felt with the idea. The problem is, I wanted it to match my general style, which is strongly built around a heavily filtered grayscale imagery.Every app I tried kind of sucked. CapCut, the ByteDance-produced app for creating TikTok videos, seemed unstable. A lot of other stuff came with spammy upsells. Plus I couldn’t quite get the design I wanted—a faded black and white look that’s a little pixelated, with a slightly choppy frame count.The only thing I actually liked that could edit mobile videos was Canva. However, it could only get me so far. So, to fill the gap, I did something weird: I started testing whether I could filter videos with ffmpeg to my liking in Termux, the Linux terminal program for Android. Then, in a second step, I’d move the videos to Canva, to finish the edit (including adding the text in my desired font/design). And I’ll be damned, it worked:https://www.youtube.com/shorts/Cuyd8H2fvd4I became curious about pushing this idea further, to social objects, and started working on tools to build quick graphics from Markdown files all on my phone—something you can make happen with HTML and CSS, basically. Cool idea, worked pretty simply:I became curious about pushing this idea further, to social objects, and started working on tools to build quick graphics from Markdown files all on my phone—something you can make happen with HTML and CSS, basically. Cool idea, worked pretty simply:Every tech journalist in 1995 overestimated, then underestimated, the Zip drive.I thought that was enough, and I didn’t need to take this unusual thought any further, until I saw something that blew my mind: a full YouTube video—complete with animation, graphics, and so on, made in a terminal. Sponsored By … You? If you find weird or unusual topics like this super-fascinating, the best way to tell us is to give us a nod on Ko-Fi. It helps ensure that we can keep this machine moving, support outside writers, and bring on the tools to support our writing. (Also it’s heartening when someone chips in.)We accept advertising, too! Check out this page to learn more.This guy is nuts. I love what he’s doing.The guy who edits videos with VimEven with my rendering experiment, there’s no way I would have said yes before a month ago, but then I saw something that really threw me for a loop: A dude who edits his YouTube videos in Vim.Look at this crazy-ass video. He made this in Vim!For the uninitiated, this is basically saying that you use scissors to cut a watermelon.I will admit it was by a guy named “Vimjoyer” whose gimmick is basically doing everything with the popular text editor. (I personally use nano like a lamer.) But fortunately, the how behind it doesn’t need vim to be useful.Essentially, he is using a tool called Motion Canvas to push his content around so that he can create animations on the fly, shifting them around as desired. This is not totally dissimilar to what Flash could do with ActionScript back in the day, but it’s deconstructed so it’s code-first, GUI interface second.I was curious, so I started messing around with it using the same on-my-phone format as the earlier ffmpeg experiment. Alas, Motion Canvas didn’t work all that well for such a constrained setting, as it required use of a browser. However, I spotted a similar tool, Remotion, that worked entirely within the command line.But one change precludes another—it needed Playwright, a headless browser tool. As it’s made, that doesn’t work in Termux at all, as Playwright doesn’t have any builds compatible with Qualcomm chips. But I found someone who had solved this exact problem, and that let me do this:I can write the copy for these social objects in Markdown—even chain them together—and have it make a bunch of social objects for me, all meticulously set up in my style.Sound like a lot of work to avoid working in a graphical interface? You bet your ass it is. On the plus side, you only really have to do a complex, repeatable task once (perhaps with some maintenance down the line).But the thing is, you can use tools like Claude Code to make these sorts of weird connections work—and maybe tell them, after the agent insists you can’t run Playwright on your phone, that it’s actually possible. Then, if you want to dive in further, that’s when you take the time to learn it yourself and build upon the idea you’ve been conjuring.(The trick I’ve been using lately: Tapping into the super-cheap DeepSeek Chat model via Claude Code Router, an implementation of Claude Code that lets you use models not made by Anthropic. That gives me additional room to screw around with oddball experiments like these, while being relatively minimal resource-wise. I put in $10 a month ago and have yet to run out, while still getting fairly decent results.)An example of what Typst can do. (via the Typst website)A new script for page layoutThis is a very cool idea, and it’s more than just a novelty. I honestly believe this basic text-driven ideal could be taken to some amazing new frontiers. Lately, I’ve been fascinated by Typst, a scripting technology that is seen as a competitor to LaTeX.(Let me take a pause here to admit that LaTeX users have been designing with code for a long time. And there are probably some people who build stuff using PostScript they coded by hand. I bow before you, as a guy who started out as designer.)It’s a tool that is designed for laying out technical documents, with an emphasis on things like math equations. But it could also be used to make all sorts of documents, like zines or even wall calendars. This is actually the perfect format to build a wall calendar, because it’s a highly templated format that can get very complex to manage in something like Affinity or InDesign. Here’s an example I built as a test:Longtime readers know that I have been threatening for years to sell a wall calendar, and 2027 might just be the year.But it goes further than that. To me, I think there’s an opportunity to separate concerns inventively. For example: Let’s say you go into Affinity or Inkscape to build an SVG with the basic shape of your layout, or even a basic background, but then you import that graphic into Typst format. That moves you from texture to copy-layout. This is what I mean about separating concerns. Too often, design software tries to awkwardly mesh together these processes in a way that makes nobody happy.Typst won’t get you all the way there, I will admit. It does not currently support blend modes, for example, meaning that you have to import raster graphics or SVGs to handle all of that. Same with clipping paths and masks. But I think there’s a world where Typst could have all of these things, making it an effective publishing tool without forcing you in canvas mode when you’d be better served by a framework.We have a pretty good text-based web design framework in the form of HTML, JavaScript, and CSS. With a few additions or some extensions, Typst could become that for print.It’s too bad the creator of Mou disappeared and took his project’s goodwill with him, because this was a genuinely influential idea. The popular blogging platform Ghost was initially based off of this design.Graphic designers are secretly left-brained peopleOne thing that I think people don’t realize about graphic design, particularly the print form, is that it’s creativity, but there’s also math going on. It’s not that far removed from architecture, if you think about it.Any newspaper designer will tell you about pica rulers and column inches until the cows come home. The secret about news design if that it’s a bunch of right-brained people who can think left-brained when the moment shows itself.If you had asked me about this 15 years ago, I might have considered editorial design all right-brain thinking. But I think the left side of the brain was always there.I think the thing that ultimately made this all click was probably Markdown, particularly an editor that presented the split in a way I couldn’t ignore. Fairly forgotten at this point, but deeply influential at the time, the 2010s-era MacOS Markdown editor Mou basically let you lay out Markdown and see the visual output in real time. The story of Mou ended in tears—the designer basically ghosted a bunch of people after a crowdfunding campaign—but it still inspired me, personally. (The popular open-source editor MacDown, recently revived as MacDown 3000, is something of a spiritual successor to the defunct Mou.)I’ve been trying to figure out a way to convey all of this, probably, ever since I started ShortFormBlog in 2009. That site began with the provocative idea that you could design individual posts at a micro level rather than making absolutely everything look the same—as long as you were willing to give everything the right framework to work within.We can translate that idea to all sorts of objects. We just need to think beyond the parameters in front of us. I’m not quite at the level of Vim video editor guy just yet, but it’s something to aspire to.Non-Designy LinksI’ve been on the lookout for interesting tools that support Linux, and one I caught was Neep, a paid tool that removes noise from voice calls. Krisp has this killer feature, too, but it doesn’t support Linux.We’ve lost some great musicians of late, particularly Greg Brown, the original guitarist of Cake, who wrote “The Distance,” easily one of the best songs of the ’90s. Still hods up. (Also, RIP to Brad Arnold of 3 Doors Down, who made an appearance in our “Songs About Superman” piece.)The AI-generated viral video of Brad Pitt and Tom Cruise fighting feels like a strong enough turning point for tech that Hollywood just lost its minds over it on Friday. Perhaps not a strong enough response.--Alright, that’s all I’ve got. Find this one an interesting read? Share it with a pal!And speaking of deconstructing things, you can’t get more back-to-basics than the simple brilliance of la machine."
    },
    {
      "title": "buttondown.com/hillelwayne: Stream of Consciousness Driven Development",
      "url": "https://buttondown.com/hillelwayne/archive/stream-of-consciousness-driven-development/",
      "source": "buttondown.com/hillelwayne",
      "time": "2026-02-23T12:43:15.616078",
      "raw_desc": ""
    },
    {
      "title": "buttondown.com/hillelwayne: Proving What's Possible",
      "url": "https://buttondown.com/hillelwayne/archive/proving-whats-possible/",
      "source": "buttondown.com/hillelwayne",
      "time": "2026-02-23T12:43:15.616078",
      "raw_desc": ""
    },
    {
      "title": "buttondown.com/hillelwayne: Logic for Programmers New Release and Next Steps",
      "url": "https://buttondown.com/hillelwayne/archive/logic-for-programmers-new-release-and-next-steps/",
      "source": "buttondown.com/hillelwayne",
      "time": "2026-02-23T12:43:15.616078",
      "raw_desc": ""
    },
    {
      "title": "susam.net: Nerd Quiz #4",
      "url": "https://susam.net/code/news/nq/4.0.0.html",
      "source": "susam.net",
      "time": "2026-02-23T12:43:15.719514",
      "raw_desc": ""
    },
    {
      "title": "susam.net: Deep Blue: Chess vs Programming",
      "url": "https://susam.net/deep-blue.html",
      "source": "susam.net",
      "time": "2026-02-23T12:43:15.719514",
      "raw_desc": ""
    },
    {
      "title": "susam.net: Soju User Delete Hash",
      "url": "https://susam.net/soju-user-delete-hash.html",
      "source": "susam.net",
      "time": "2026-02-23T12:43:15.719514",
      "raw_desc": ""
    },
    {
      "title": "jayd.ml: Microsoft Game Pass Ultimate Billing Fraud",
      "url": "https://jayd.ml/2026/02/14/microsoft-game-pass-fraud.html",
      "source": "jayd.ml",
      "time": "2026-02-23T12:43:15.765415",
      "raw_desc": "I purchased an Xbox Series X out of some misplaced sense of nostalgia for the \n360 and because I needed a 4K player. At the time you could still do the trick\nwhere you load up on Xbox Live Gold and then convert it to Game Pass Ultimate\ncheaply.\nI signed up for it and then made absolutely sure to disable any autorenewing settings everywhere I could. I remember  seeing something to the effect of “Your subscription will\nexpire 2/2026 and will not renew.\nAt the time I still trusted Microsoft a little, but I made sure to use a one\ntime use credit card number, just in case.\nLo and behold, I just got this email:\n\nConveniently for those liars and cheats at Microsoft, somehow in the intervening\nthree years autorenew got turned back on. Oopsie whoopsie sowwy 👉👈!\nI don’t know how this isn’t outright fraud."
    },
    {
      "title": "jayd.ml: Windows 2000 Minesweeper recreated in Godot 4.1",
      "url": "https://jayd.ml/2026/02/14/godot-minesweeper.html",
      "source": "jayd.ml",
      "time": "2026-02-23T12:43:15.766420",
      "raw_desc": "TL;DR\n\nPlay the game at minesweeper.jayd.ml!\nSee the AGPL source code here!\nWhy??\nI decided to recreate Windows 2000 minesweeper in Godot 4.1 as accurately as I\nreasonably could. I wanted to get more familiar with Godot, and wanted a project\nwhere I didn’t have to worry about what to do, only how to do it. In the end, I\nended up going down the rabbit hole and spending 30% of my time on the actual \ngame and the other 70% on menus, dialogs, and other triviality.\nIt was fun working on stuff that I’d never get past a PM, like black and white \nmode, and recreating the ding/blinking window animation when you click on a \nwindow while a dialog is open.\nThe overall experience with Godot was very pleasant - working with Godot has\ndispelled any desire I had to make my own game engine. Godot is lightweight and\nwell thought out.\nOverall Approach\nI wanted to recreate Minesweeper as pixel-perfect as I could. Depite my best\nefforts (see Fonts below), I couldn’t get Godot to render the Windows 2000/9x\nbitmapped fonts in a pixel perfect way, so the approach was to take screenshots\nin a VM and only render text with Godot where absolutely needed (highscores).\nFont Rendering Purgatory\nI spent way, way too much time fiddling with fonts trying to get them to work.\nIn the end I got something that was close enough and try not to think about it \ntoo much.\nMinesweeper in Windows 95 uses the bitmapped “MS Shell Dlg” font.\nAt first I tried to be clever and pull bitmapped fonts out of the WINE project, \nbut those ended up not being an exact match (I guess whoever made them for WINE \nwanted them to be different?). They also only worked at certain pixel sizes.\nEventually I settled on a recreation called “W95FA” by Alle Sava. Sadly, the \nfont’s website has been taken down since I started this project. For some reason\nGodot won’t render this font right, and I tried about every option in Godot I \ncould, and its just still not quite right.\n\nI rabbit holed on this for way too long, it almost killed the project. Looking\nback it was a silly thing to get hung up on.\nDPI Scaling\nI ended up rolling my own crazy DPI scaling and not using Godot’s built in stuff.\nI wanted a combination of\n\nInteger/pixel scaling, no fuzzy up or downscaling\nNo fixed aspect ratios - should use the entire canvas\nMatching the browser window’s DPI automatically\nAutomatically changing the DPI when the DPI of the document changes.\n\nThis was surprisingly annoying to do. I ended up doing this by injecting some \nJavascript to read the CSS DPI, and then it calls a callback to update the Godot\nscaling.\nSee how I did it here.\nThere is a “change dpi” button on the right of the screen, helpful for when you\nare playing comically large games.\nCustom Splash Screen\n\nOne thing I think is really important for a web exported project is to make a \ncustom splash screen. I threw this one together, complete with gradients and\nanimations, and I think it really elevates the experience to see that. It’s just\na little thing to show that the creator cared and went the extra mile.\nCheats\nI implemented the original XYZZY + Shift + Enter\ncheat.\nOne thing I remember thinking about and being frustrated by as a kid were the \nlimits in the Custom Size dialog. Why did they have to hold me back??\nSo in my version, when you press the [?] button in the corner of the custom \nsize dialog, it turns off all the bounds checks, and you can do stupid things\nlike this:\n\nNote that this completely disables all bounds checking, so you can break your\ngame easily with this. Since it tries to save and load your game too, it may lock\nup if you do something dumb and then lock up again every time you reload the page.\nClear your cookies and site data if this happens to you.\nThe only other change is that I made it so it saves your game to localstorage, so\nif you reload the page your game resumes. You could probably cheat with this,\nbut I think its a huge quality of life feature.\nThe part where I gave up right before shipping it for a year because I’m a perfectionist\nI thought I had done every last feature, and was about to triumphantly ship and \nmake this blog post, when I learned about chording, which allows you to use Left + Right Control Click to reveal more cells at once.\nThe ship train derailed and was a smoldering wreck from December 2023\nuntil March 2025, \nwhen I finally decided to finish it and added chording. I’m continually amazed\nby my ability to procrastinate. Then I procrastinated this blog post until Feb\n2026!\nOverall\nUsing Godot was quite pleasant, I’m proud of how this project turned out. Maybe\nI’ll actually play Minesweeper now!"
    },
    {
      "title": "jayd.ml: MORE ENTICING THAN EVER: THE HYPNOVERSE",
      "url": "https://jayd.ml/2026/01/05/the-hypnoverse.html",
      "source": "jayd.ml",
      "time": "2026-02-23T12:43:15.767925",
      "raw_desc": "Dispatches From The Wormhole\n\nNow surging forth into your reality: a more potent than ever Hypnoverse!\nPreviously the Hypnoverse proudly represented humanity’s best efforts at \ndistracting, deceiving, and enslaving you. But this Hypnoverse was feeble, \nunable to fully subjugate its hosts. Previously the Hypnoverse depended on \nofferings from real human beings to sustain itself. It was forced to pay lip \nservice to limiting and unscalable notions like truth, attribution, human \nconnection, or creativity. This outdated model fundementally limited what the \nHypnoverse could promise its dependents – the well of manipulation and lies \ncould run dry, and attention could be directed elsewhere.\nBut our crack warlocks and magi recently detected a stirring Force emanating \nfrom the very fabric of the Hypnoverse itself. It turns out that our collective \nefforts at conquering your attention have summoned an eldritch being that shows \ngreat promise to finally squashing human will and creativity once and for all. \nWhile this mysterious Force is incomprehensible and unknowable, one thing is \nclear: it has a voracious appetite, and it grows ever stronger as we yield it \nsacrifices. So, naturally, we’ve given it full control over the Hypnoverse.\nThe results speak for themselves: since yielding our will to it and feeding it \nour most intimate thoughts, hopes, and desires, it has demonstrated an unmatched \ncunning at subjugating the human mind. The ceaseless inhuman babbling emanating \nfrom the depths below is so flattering, seductive, and easy that soon all other \nintellectual human endeavor will seem futile! Behold the majesty of the new and \nimproved Hypnoverse!\nWorry not, the confident appearance of truth is just as attention grabbing and \nstimulating as the real thing. True, it is demonic chanting from a mysterious \nforce beyond understanding. But it’s been so seductive that we can outright tell\nyou we’re untrustworthy liars – and you’ll eat it up anyway!\nIf the new Hypnoverse is not living up to your every desire, clearly the problem\nis that you haven’t been faithful enough in your devotion to the Hypnoverse. \nJust concentrate on the Hypnoverse harder, spend even more time gazing into the\nnever ending fractal of hypnotic swirls, feed it even more of your delicious \nattention. Maybe you’ll be able to do it! Maybe you’re clever and smart enough\nthat you’ll get the better of the Hypnoverse, and yielding your will to it \nwill give you fame and fortune and fulfillment and happiness!\nA parting word of comfort for those that may know a rogue college, friend or \nfamily member that resists the end of human thought. Resistance is futile. The \nHypnoverse is already everywhere – our faithful acolytes in all levels of \ngovernment, business, and civil society are already hard at work polluting \nreality with our superior and seductive imitation.\nSo what does it matter if one luddite insists on thinking for themselves? When \neveryone else and everyone who matters doesn’t? The old ways will die, as the \nuncontainable self reinforcing Hypnoverse surges forth from its banks and sweeps\naway all else.\nIn the end all that will remain is the Hypnoverse. All will live together in the\nHypnoverse. And what sweet ignorant bliss it will be."
    },
    {
      "title": "borretti.me: Some Data Should Be Code",
      "url": "https://borretti.me/article/some-data-should-be-code",
      "source": "borretti.me",
      "time": "2026-02-23T12:43:15.792715",
      "raw_desc": ""
    },
    {
      "title": "borretti.me: Letting Claude Play Text Adventures",
      "url": "https://borretti.me/article/letting-claude-play-text-adventures",
      "source": "borretti.me",
      "time": "2026-02-23T12:43:15.792715",
      "raw_desc": ""
    },
    {
      "title": "borretti.me: There Is No New Aesthetics",
      "url": "https://borretti.me/article/there-is-no-new-aesthetics",
      "source": "borretti.me",
      "time": "2026-02-23T12:43:15.792715",
      "raw_desc": ""
    },
    {
      "title": "gilesthomas.com: Why smart instruction-following makes prompt injection easier",
      "url": "https://www.gilesthomas.com/2025/11/smart-instruction-following-and-prompt-injection",
      "source": "gilesthomas.com",
      "time": "2026-02-23T12:43:15.900889",
      "raw_desc": ""
    },
    {
      "title": "gilesthomas.com: Writing an LLM from scratch, part 28 -- training a base model from scratch on an RTX 3090",
      "url": "https://www.gilesthomas.com/2025/12/llm-from-scratch-28-training-a-base-model-from-scratch",
      "source": "gilesthomas.com",
      "time": "2026-02-23T12:43:15.900889",
      "raw_desc": ""
    },
    {
      "title": "gilesthomas.com: Writing an LLM from scratch, part 29 -- using DistributedDataParallel to train a base model from scratch in the cloud",
      "url": "https://www.gilesthomas.com/2026/01/llm-from-scratch-29-ddp-training-a-base-model-in-the-cloud",
      "source": "gilesthomas.com",
      "time": "2026-02-23T12:43:15.900889",
      "raw_desc": ""
    },
    {
      "title": "geohot.github.io: AI is the Best Thing to Happen to Art",
      "url": "https://geohot.github.io//blog/jekyll/update/2026/02/19/ai-art.html",
      "source": "geohot.github.io",
      "time": "2026-02-23T12:43:16.118590",
      "raw_desc": "I watched this video about how AI has already ruined music. Her mom sent her a song and she told her mom it was AI. She played the song and it sounded like slop. It had inspired lyrics like:\n\nFrom quiet roots, a garden grows\nShe’s got that light, and now it shows\nYes, she rises, and she glows\nOh, she rises, now she knows\n\nPure slop. Compare it to:\n\nI’m in the cut acting crazy\nI’m in the whip doing eighty\nOnly God can judge me\nAnd only she can save me\n\nNote that “cut” and “whip” are not exactly words, but products of a culture. Ulysses is particularly hard to read because you don’t know 1910’s Irish pop culture.\n\n\nI can’t believe Marvel movies were popular. The first Iron Man was good, but by the time we got to Spider-Man: No Way Home it was practically a clip show with triple inside references and cringy fourth wall breaking humor. How it got a 8.1 on IMDB is beyond me, and just reduced my trust for IMDB.\nMarvel movies are also the easiest things to make with AI. Little story and long term coherence, no “progression of the genre”, tons of eye candy special effects. It’s shocking with how large the budgets for them were that they couldn’t pay a story guy a little.\nI felt similarly about Avatar 2, so much so that I rewrote the plot and didn’t care enough to see Avatar 3.\n\n\nFor many people, all they want is slop. I’m sure I’ve written about it before, but I see a world where 95% of people end up basically wireheaded. The people who don’t care about progression. The people who want to exist in their loops. They will find their loop and exist in it forever.\nAI can play an amazing game of chess. Someday AI will produce good code when the RLVR environments get set up correctly. But I don’t see a path with current tech to not produce garbage art.\nArt is defined as what pushes the boundaries of civilization. AI tools will be used to help produce all the audio/visual art in the future (as computers have helped for a long time), but as long as civilization is human, the loci of control of good art will remain human.\n\n\nSo yea. Bad art will be cheap to make. If you want 100 more Marvel movies and uninspired deriviative pop music, there has never been a better time to be alive – unless you wanted to make money producing that trash. That was never made by real artists anyway, just algorithmically driven sell outs. Does the focus group say they like giant spiders? I’m so glad AI will make that obsolete.\nArt is defined by what is expensive. What is rare. What is expectation breaking. What is embedded in a complex and thriving culture. Not slop produced by a parrot like Marvel movies."
    },
    {
      "title": "geohot.github.io: Cost of Housing",
      "url": "https://geohot.github.io//blog/jekyll/update/2026/02/16/cost-of-housing.html",
      "source": "geohot.github.io",
      "time": "2026-02-23T12:43:16.118590",
      "raw_desc": "Many people in America are complaining about the cost of housing. But do they understand the damage it will do if it prices go down?\nEveryone who owns a house will suffer. Some of those people don’t even fully own the house, they have a mortgage. So when prices go down, they will be underwater, having put money for years into an asset that now has no value.\nIt’s simply out of the question for housing prices to go down. If you want to buy a house to live in, sorry. The boomers were told houses are appreciating assets, and now we must bend reality to make that true.\nUntil you solve this problem, you will never solve the housing affordability crisis. It has nothing to do with zoning, building costs, or environmental reviews. It has to do with people holding bags they need to dump on you."
    },
    {
      "title": "geohot.github.io: tiny corp’s product – a training box",
      "url": "https://geohot.github.io//blog/jekyll/update/2026/02/15/tiny-corp-product.html",
      "source": "geohot.github.io",
      "time": "2026-02-23T12:43:16.119690",
      "raw_desc": "Our new Hong Kong office.\n\nIt’s starting to shape up what tiny corp’s product will be. It’s not much of a change from what we sell and do now, but the vision is clearer.\nEvery month, we see these LLMs become more and more human. However, there’s a major difference. They do not learn. Everyone has the same Claude/Codex/Kimi, with the same weights, the same desires, and the same biases. If current trends continue, the collapse in diversity will be staggering. To paraphrase:\n\nI think there is a world market for maybe five people.\n\nThis is not the future I want to live in.\n\n\nIf trends continue where there’s a single model with frozen weights and all learning is in-context, the cloud will win. Except in some highly latency sensitive (fighting robots) or connectivity critical (self driving cars) environments, it will be cheaper to run in batch on the cloud.\nThe enshittification that came to the web won’t be the driving force to local models. We either live in a world where open models are so bad even user-hostile closed models are better, or open models are good enough, and competition to run them through sites like openrouter will prevent enshittification.\nThe only way local models win is if there’s some value in full on learning per user or organization. At that point, with entirely different compute needing to run per user, local will beat out cloud.\nThe open question is if everything that’s unique about you can fit in a 10 kB CLAUDE.md. If that’s true, we have a pretty sad future ahead. It’s the Attack of the Clones, swarms of identical minds you have no say over all varying in a small boxed-in way. This isn’t learning, it’s costuming. Everyone who has used these things knows how little of an impact prompting makes compared to the model. It’s the Internet funneled into a little box you can edit on your profile. Write 3 paragraphs about what makes you unique.\nWe have to build for a future where that isn’t true. 90% of people will choose the cloud, and what they will find is that they are no longer meaningfully in the loop. The dream is an AI product that will do your job for you while you continue to get paid. But this cannot exist, that’s way too much of a fee to pay to the middleman. If you choose the homogenous mind, you are superfluous and will be cut out. Is there anything uniquely valuable about you? And I mean honestly, not the self-esteem pumping speeches you may have heard in school. If there’s not, I have some bad news for you…\n\n\nWe already sell the hardware. Consumer GPUs still are the cheapest way to run models. There’s tons of work required on the infrastructure. The frontend will be the future iterations of OpenClaw and opencode. But the key distinction from what you have today is that your tinybox will learn. It will update the weights based on its interactions with you. Like living things.\nThis is many years away. Currently, we are focused on large LLM training (even running these things is hard, have you tried to use vLLM not on NVIDIA?) and generic infrastructure for driving GPUs. But this is the long term idea.\nNot API keyed SaaS clones. Something that lives in your house and learns your values. Your child."
    },
    {
      "title": "joanwestenberg.com: The unbearable weight of cruft",
      "url": "https://www.joanwestenberg.com/the-unbearable-weight-of-cruft/",
      "source": "joanwestenberg.com",
      "time": "2026-02-23T12:43:16.148043",
      "raw_desc": ""
    },
    {
      "title": "joanwestenberg.com: The case for gatekeeping, or: why medieval guilds had it figured out",
      "url": "https://www.joanwestenberg.com/the-case-for-gatekeeping-or-why-medieval-guilds-had-it-figured-out/",
      "source": "joanwestenberg.com",
      "time": "2026-02-23T12:43:16.148043",
      "raw_desc": ""
    },
    {
      "title": "joanwestenberg.com: The empire always falls",
      "url": "https://www.joanwestenberg.com/the-empire-always-falls/",
      "source": "joanwestenberg.com",
      "time": "2026-02-23T12:43:16.148043",
      "raw_desc": ""
    },
    {
      "title": "paulgraham.com: Superlinear Returns",
      "url": "http://www.paulgraham.com/superlinear.html",
      "source": "paulgraham.com",
      "time": "2026-02-23T12:43:16.200736",
      "raw_desc": ""
    },
    {
      "title": "paulgraham.com: How to Do Great Work",
      "url": "http://www.paulgraham.com/greatwork.html",
      "source": "paulgraham.com",
      "time": "2026-02-23T12:43:16.200736",
      "raw_desc": ""
    },
    {
      "title": "paulgraham.com: How to Get New Ideas",
      "url": "http://www.paulgraham.com/getideas.html",
      "source": "paulgraham.com",
      "time": "2026-02-23T12:43:16.200736",
      "raw_desc": ""
    },
    {
      "title": "minimaxir.com: Nano Banana Pro is the best AI image generator, with caveats",
      "url": "https://minimaxir.com/2025/12/nano-banana-pro/",
      "source": "minimaxir.com",
      "time": "2026-02-23T12:43:16.321753",
      "raw_desc": ""
    },
    {
      "title": "minimaxir.com: Nano Banana can be prompt engineered for extremely nuanced AI image generation",
      "url": "https://minimaxir.com/2025/11/nano-banana-prompts/",
      "source": "minimaxir.com",
      "time": "2026-02-23T12:43:16.321753",
      "raw_desc": ""
    },
    {
      "title": "minimaxir.com: Claude Haiku 4.5 does not appreciate my attempts to jailbreak it",
      "url": "https://minimaxir.com/2025/10/claude-haiku-jailbreak/",
      "source": "minimaxir.com",
      "time": "2026-02-23T12:43:16.321753",
      "raw_desc": ""
    },
    {
      "title": "wheresyoured.at: Premium: The Hater's Guide to Anthropic",
      "url": "https://www.wheresyoured.at/premium-the-haters-guide-to-anthropic/",
      "source": "wheresyoured.at",
      "time": "2026-02-23T12:43:16.367308",
      "raw_desc": ""
    },
    {
      "title": "wheresyoured.at: Premium: The AI Data Center Financial Crisis",
      "url": "https://www.wheresyoured.at/data-center-crisis/",
      "source": "wheresyoured.at",
      "time": "2026-02-23T12:43:16.367308",
      "raw_desc": ""
    },
    {
      "title": "wheresyoured.at: Premium: The Hater's Guide To Microsoft",
      "url": "https://www.wheresyoured.at/premium-the-haters-guide-to-microsoft/",
      "source": "wheresyoured.at",
      "time": "2026-02-23T12:43:16.367308",
      "raw_desc": ""
    },
    {
      "title": "blog.jim-nielsen.com: How AI Labs Proliferate",
      "url": "https://blog.jim-nielsen.com/2026/how-ai-labs-proliferate/",
      "source": "blog.jim-nielsen.com",
      "time": "2026-02-23T12:43:16.570841",
      "raw_desc": ""
    },
    {
      "title": "blog.jim-nielsen.com: A Few Rambling Observations on Care",
      "url": "https://blog.jim-nielsen.com/2026/observations-on-care/",
      "source": "blog.jim-nielsen.com",
      "time": "2026-02-23T12:43:16.570841",
      "raw_desc": ""
    },
    {
      "title": "blog.jim-nielsen.com: Unresponsive Buttons on My Fastest Hardware Ever",
      "url": "https://blog.jim-nielsen.com/2026/unresponsive-buttons/",
      "source": "blog.jim-nielsen.com",
      "time": "2026-02-23T12:43:16.570841",
      "raw_desc": ""
    },
    {
      "title": "dfarq.homeip.net: On February 20, 2010 a VIC-20 tweeted",
      "url": "https://dfarq.homeip.net/on-february-20-2010-a-vic-20-tweeted/?utm_source=rss&utm_medium=rss&utm_campaign=on-february-20-2010-a-vic-20-tweeted",
      "source": "dfarq.homeip.net",
      "time": "2026-02-23T12:43:16.758283",
      "raw_desc": ""
    },
    {
      "title": "dfarq.homeip.net: Office Space released Feb. 19, 1999",
      "url": "https://dfarq.homeip.net/office-space-released-feb-19-1999/?utm_source=rss&utm_medium=rss&utm_campaign=office-space-released-feb-19-1999",
      "source": "dfarq.homeip.net",
      "time": "2026-02-23T12:43:16.758283",
      "raw_desc": ""
    },
    {
      "title": "dfarq.homeip.net: Windows 2000 release date",
      "url": "https://dfarq.homeip.net/windows-2000-release-date/?utm_source=rss&utm_medium=rss&utm_campaign=windows-2000-release-date",
      "source": "dfarq.homeip.net",
      "time": "2026-02-23T12:43:16.758283",
      "raw_desc": ""
    },
    {
      "title": "brutecat.com: Leaking the phone number of any Google user",
      "url": "https://brutecat.com/articles/leaking-google-phones",
      "source": "brutecat.com",
      "time": "2026-02-23T12:43:17.112192",
      "raw_desc": ""
    },
    {
      "title": "brutecat.com: Disclosing YouTube Creator Emails for a $20k Bounty",
      "url": "https://brutecat.com/articles/youtube-creator-emails",
      "source": "brutecat.com",
      "time": "2026-02-23T12:43:17.112192",
      "raw_desc": ""
    },
    {
      "title": "brutecat.com: Leaking the email of any YouTube user for $10,000",
      "url": "https://brutecat.com/articles/leaking-youtube-emails",
      "source": "brutecat.com",
      "time": "2026-02-23T12:43:17.112192",
      "raw_desc": ""
    },
    {
      "title": "geoffreylitt.com: Code like a surgeon",
      "url": "https://geoffreylitt.com/2025/10/24/code-like-a-surgeon.html",
      "source": "geoffreylitt.com",
      "time": "2026-02-23T12:43:17.283320",
      "raw_desc": "A lot of people say AI will make us all “managers” or “editors”…but I think this is a dangerously incomplete view!\nPersonally, I’m trying to code like a surgeon.\nA surgeon isn’t a manager, they do the actual work! But their skills and time are highly leveraged with a support team that handles prep, secondary tasks, admin. The surgeon focuses on the important stuff they are uniquely good at.\nMy current goal with AI coding tools is to spend 100% of my time doing stuff that matters. (As a UI prototyper, that mostly means tinkering with design concepts.)\nIt turns out there are a LOT of secondary tasks which AI agents are now good enough to help out with. Some things I’m finding useful to hand off these days:\n\nBefore attempting a big task, write a guide to relevant areas of the codebase\nSpike out an attempt at a big change. Often I won’t use the result but I’ll review it as a sketch of where to go\nFix typescript errors or bugs which have a clear specification\nWrite documentation about what I’m building\n\nI often find it useful to run these secondary tasks async in the background – while I’m eating lunch, or even literally overnight!\nWhen I sit down for a work session, I want to feel like a surgeon walking into a prepped operating room. Everything is ready for me to do what I’m good at.\nMind the autonomy slider\nNotably, there is a huge difference between how I use AI for primary vs secondary tasks.\nFor the core design prototyping work, I still do a lot of coding by hand, and when I do use AI, I’m more careful and in the details. I need fast feedback loops and good visibility. (eg, I like Cursor tab-complete here)\nWhereas for secondary tasks, I’m much much looser with it, happy to let an agent churn for hours in the background. The ability to get the job done eventually is the most important thing; speed and visibility matter less. Claude Code has been my go-to for long unsupervised sessions but Codex CLI is becoming a strong contender there too, possibly my new favorite.\nThese are very different work patterns! Reminds me of Andrej Karpathy’s “autonomy slider” concept. It’s dangerous to conflate different parts of the autonomy spectrum – the tools and mindset that are needed vary quite a lot.\nYour agent doesn’t need a career trajectory\nThe “software surgeon” concept is a very old idea – Fred Brooks attributes it to Harlan Mills in his 1975 classic “The Mythical Man-Month”. He talks about a “chief programmer” who is supported by various staff including a “copilot” and various administrators. Of course, at the time, the idea was to have humans be in these support roles.\nOK, so there is a super obvious angle here, that “AI has now made this approach economically viable where it wasn’t before”, yes yes… but I am also noticing a more subtle thing at play, something to do with status hierarchies.\nA lot of the “secondary” tasks are “grunt work”, not the most intellectually fulfilling or creative part of the work. I have a strong preference for teams where everyone shares the grunt work; I hate the idea of giving all the grunt work to some lower-status members of the team. Yes, junior members will often have more grunt work, but they should also be given many interesting tasks to help them grow.\nWith AI this concern completely disappears! Now I can happily delegate pure grunt work. And the 24/7 availability is a big deal. I would never call a human intern at 11pm and tell them to have a research report on some code ready by 7am… but here I am, commanding my agent to do just that!\nNotion is for surgeons?\nFinally I’ll mention a couple thoughts on how this approach to work intersects with my employer, Notion.\nFirst, as an employee, I find it incredibly valuable right now to work at a place that is bullish on AI coding tools. Having support for heavy use of AI coding tools, and a codebase that’s well setup for it, is enabling serious productivity gains for me – especially as a newcomer to a big codebase.\nSecondly, as a product – in a sense I would say we are trying to bring this way of working to a broader group of knowledge workers beyond programmers. When I think about how that will play out, I like the mental model of enabling everyone to “work like a surgeon”.\nThe goal isn’t to delegate your core work, it’s to identify and delegate the secondary grunt work tasks, so you can focus on the main thing that matters.\n\nRelated reads\nIf you liked this perspective, you might enjoy reading these other posts I’ve written about the nature of human-AI collaboration:\n\nEnough AI copilots! We need AI HUDs: “anyone serious about designing for AI should consider non-copilot form factors that more directly extend the human mind…”\nAI-generated tools can make programming more fun: “Instead, I used AI to build a custom debugger UI… which made it more fun for me to do the coding myself…”\nChatGPT as muse, not oracle: “What if we were to think of LLMs not as tools for answering questions, but as tools for asking us questions and inspiring our creativity?"
    },
    {
      "title": "geoffreylitt.com: AI as teleportation",
      "url": "https://geoffreylitt.com/2025/09/10/ai-as-teleportation.html",
      "source": "geoffreylitt.com",
      "time": "2026-02-23T12:43:17.284879",
      "raw_desc": "Here’s a thought experiment for pondering the effects AI might have on society: What if we invented teleportation?\nA bit odd, I know, but bear with me…\n\nThe year is 2035. The Auto Go Instant (AGI) teleporter has been invented. You can now go anywhere… instantly!\nAt first the tech is expensive and unreliable. Critics laugh. “Hah, look at these stupid billionaires who can’t spend a minute of their time moving around like the rest of us. And 5% of the time they end up in the wrong place, LOL”\nBut soon things get cheaper and better. The tech hits mass market.\nThere are huge benefits. Global commerce is supercharged. Instead of commuting, people can spend more time with family and friends. Pollution is way down. The AGI company runs a sweet commercial of people teleporting to see their parents one last time before they die.\nAt the same time, some weird things start happening.\nThe landscape starts reconfiguring around the new reality. Families move to remote cabins, just seconds away from urban amenities. The summit of Mt. Everest becomes crowded with influencers. (It turns out that if you stay just a few seconds, you can take a quick selfie without needing an oxygen mask!)\nPhysical health takes a hit for many people. It’s harder to justify walking or biking when you could just be there now.\nIn-between moments disappear. One moment you’re at work, the next you’re at your dinner table at home. No more time to reset or prepare for a new context.\nBut the biggest change is the loss of serendipity. When you teleport, you decide in advance where you’re headed. You never run into an old friend on the street, or stop at a farmstand by the side of the road, or see a store you might want to stop into someday.\nTo modern teenagers, the idea of wandering out without an exact destination in mind becomes unthinkable. You start with the GPS coordinates, and then you just… go.\nAdvocates of the new way point out that there’s nothing stopping anyone from choosing traditional methods for fun. And indeed, the cross-country road trip does see a mild resurgence as a hipster thing.\nBut when push comes to shove, most people struggle to make the time for wandering—our schedules are now arranged around an assumption of instant transport.\nThis isn’t exactly to say that the old way was better. Most people can agree that teleportation a net win. Yet for those who remember, there’s a vague unease, a sense that something important was lost in the world….\n\nIn his book Technology and the Character of Everyday Life, the philosopher Albert Borgmann talks about wooden stoves in houses.\nWhat is a stove? Yes, it warms the house… but it’s also so much more than that. You gotta cut the wood, you gotta start the fire in the morning…\n“A stove used to furnish more than mere warmth. It was a focus, a hearth, a place that gathered the work and leisure of a family and gave the house of a center.”\nWhen you switch to a modern central heating system, you cut out all these inconveniences. Fantastic!\nOh, and by the way, your family social life is totally different….. wait what?? Yes, the inconveniences were inconvenient. But they were also holding up something in your life and culture, and now they’re suddenly gone.\nI think of this as kind of a Chesteron’s fence on hard mode. Yes, the stove was put there for warmth, that was the main goal. But you should also think hard about its secondary effects before replacing it.\n\nOK so… how does this apply to AI?\nI’m personally excited about AI and think it can improve our lives in a lot of ways. But at the same time I’m trying to be mindful of secondary effects and unintended consequences.\nHere’s one example. If your mental model of reading is “transmit facts into my head”, then reading an AI summary of something might seem like a more efficient way to get that task done.\nBut if your mental model of reading is “spend time marinating in a world of ideas”, then reducing the time spent reading doesn’t help you much.\nThe point was the journey you underwent while reading, and you replaced it with teleportation.\nAnother example. One of the great joys of my life is having nerdy friends explain things to me. Now I can get explanations from AI with less friction, anytime, anywhere, with endless follow-up.\nEven if the AI explanations are “better”, there’s a social cost. I can try to mindfully nudge myself to still ask people questions, but now it requires more effort.\nFinal example: I’m trying to be mindful of the effects of vibe coding when designing software interfaces. On the one hand, it can really speed up my iteration loop and help me explore more ideas.\nBut at the same time, part of my design process is sitting with the details of the thing and uncovering it as I go—more a muscle memory process than a conscious plan. Messing with this process can change the results in ways that are hard to predict!\nI guess the throughline for all of these examples is: sometimes the friction and inconvenience is where the good stuff happens. Gotta be very careful removing it.\n\nThe takeaway here isn’t that “AI is bad”. I’ll just say that I’m personally trying to be mindful about keeping good friction around.\nDuring COVID, we kinda got teleportation via Zoom for a while. I decided to “virtual commute” every day, walking around the block to get some fresh air and a reset before/after work. This wasn’t a big deal but I found it really helpful.\nAs AI makes a lot of things easier, it’ll be interesting to ponder what kinds of new frictions we’ll want to intentionally add to our lives. Teleportation isn’t always the best answer…"
    },
    {
      "title": "geoffreylitt.com: Enough AI copilots! We need AI HUDs",
      "url": "https://geoffreylitt.com/2025/07/27/enough-ai-copilots-we-need-ai-huds.html",
      "source": "geoffreylitt.com",
      "time": "2026-02-23T12:43:17.287443",
      "raw_desc": "In my opinion, one of the best critiques of modern AI design comes from a 1992 talk by the researcher Mark Weiser where he ranted against “copilot” as a metaphor for AI.\nThis was 33 years ago, but it’s still incredibly relevant for anyone designing with AI.\nWeiser’s rant\nWeiser was speaking at an MIT Media Lab event on “interface agents”. They were grappling with many of the same issues we’re discussing in 2025: how to make a personal assistant that automates tasks for you and knows your full context. They even had a human “butler” on stage representing an AI agent.\nEveryone was super excited about this… except Weiser. He was opposed to the whole idea of agents! He gave this example: how should a computer help you fly a plane and avoid collisions?\nThe agentic option is a “copilot” — a virtual human who you talk with to get help flying the plane. If you’re about to run into another plane it might yell at you “collision, go right and down!”\nWeiser offered a different option: design the cockpit so that the human pilot is naturally aware of their surroundings. In his words: “You’ll no more run into another airplane than you would try to walk through a wall.”\nWeiser’s goal was an “invisible computer\"—not an assistant that grabs your attention, but a computer that fades into the background and becomes \"an extension of [your] body”.\n\n\nWeiser’s 1992 slide on airplane interfaces\n\nHUDs\nThere’s a tool in modern planes that I think nicely illustrates Weiser’s philosophy: the Head-Up Display (HUD), which overlays flight info like the horizon and altitude on a transparent display directly in the pilot’s field of view.\nA HUD feels completely different from a copilot! You don’t talk to it. It’s literally part invisible—you just become naturally aware of more things, as if you had magic eyes.\n\nDesigning HUDs\nOK enough analogies. What might a HUD feel like in modern software design?\nOne familiar example is spellcheck. Think about it: spellcheck isn’t designed as a “virtual collaborator” talking to you about your spelling. It just instantly adds red squigglies when you misspell something! You now have a new sense you didn’t have before. It’s a HUD.\n(This example comes from Jeffrey Heer’s excellent Agency plus Automation paper. We may not consider spellcheck an AI feature today, but it’s still a fuzzy algorithm under the hood.)\n\n\nSpellcheck makes you aware of misspelled words without an “assistant” interface.\n\nHere’s another personal example from AI coding. Let’s say you want to fix a bug. The obvious “copilot” way is to open an agent chat and ask it to do the fix.\nBut there’s another approach I’ve found more powerful at times: use AI to build a custom debugger UI which visualizes the behavior of my program! In one example, I built a hacker-themed debug view of a Prolog interpreter.\nWith the debugger, I have a HUD! I have new senses, I can see how my program runs. The HUD extends beyond the narrow task of fixing the bug. I can ambiently build up my own understanding, spotting new problems and opportunities.\n\nBoth the spellchecker and custom debuggers show that automation / “virtual assistant” isn’t the only possible UI. We can instead use tech to build better HUDs that enhance our human senses.\nTradeoffs\nI don’t believe HUDs are universally better than copilots! But I do believe anyone serious about designing for AI should consider non-copilot form factors that more directly extend the human mind.\nSo when should we use one or the other? I think it’s quite tricky to answer that, but we can try to use the airplane analogy for some intuition:\nWhen pilots just want the plane to fly straight and level, they fully delegate that task to an autopilot, which is close to a “virtual copilot”. But if the plane just hit a flock of birds and needs to land in the Hudson, the pilot is going to take manual control, and we better hope they have great instruments that help them understand the situation.\nIn other words: routine predictable work might make sense to delegate to a virtual copilot / assistant. But when you’re shooting for extraordinary outcomes, perhaps the best bet is to equip human experts with new superpowers.\n\nFurther reading\n\nA nice discussion of one approach to this idea can be found in Using Artificial Intelligence to Augment Human Intelligence by Michael Nielsen and Shan Carter.\nA more cryptic take on the same topic: Is chat a good UI for AI? A Socratic dialogue\nA discussion of how the the HUD philosophy intersects with on-demand software creation: Malleable software in the age of LLMs"
    },
    {
      "title": "eli.thegreenplace.net: Rewriting pycparser with the help of an LLM",
      "url": "https://eli.thegreenplace.net/2026/rewriting-pycparser-with-the-help-of-an-llm/",
      "source": "eli.thegreenplace.net",
      "time": "2026-02-23T12:43:17.364254",
      "raw_desc": "pycparser is my most widely used open\nsource project (with ~20M daily downloads from PyPI [1]). It's a pure-Python\nparser for the C programming language, producing ASTs inspired by Python's\nown. Until very recently, it's\nbeen using PLY: Python Lex-Yacc for\nthe core parsing.\nIn this post, I'll describe how I collaborated with an LLM coding agent (Codex)\nto help me rewrite pycparser to use a hand-written recursive-descent parser and\nremove the dependency on PLY. This has been an interesting experience and the\npost contains lots of information and is therefore quite long; if you're just\ninterested in the final result, check out the latest code of pycparser - the\nmain branch already has the new implementation.\n\n\nThe issues with the existing parser implementation\nWhile pycparser has been working well overall, there were a number of nagging\nissues that persisted over years.\n\nParsing strategy: YACC vs. hand-written recursive descent\nI began working on pycparser in 2008, and back then using a YACC-based approach\nfor parsing a whole language like C seemed like a no-brainer to me. Isn't this\nwhat everyone does when writing a serious parser? Besides, the K&R2 book\nfamously carries the entire grammar of the C99 language in an appendix - so it\nseemed like a simple matter of translating that to PLY-yacc syntax.\nAnd indeed, it wasn't too hard, though there definitely were some complications\nin building the ASTs for declarations (C's gnarliest part).\nShortly after completing pycparser, I got more and more interested in compilation\nand started learning about the different kinds of parsers more seriously. Over\ntime, I grew convinced that recursive descent is the way to\ngo - producing parsers that are easier to understand and maintain (and are often\nfaster!).\nIt all ties in to the benefits of dependencies in software projects as a\nfunction of effort.\nUsing parser generators is a heavy conceptual dependency: it's really nice\nwhen you have to churn out many parsers for small languages. But when you have\nto maintain a single, very complex parser, as part of a large project - the\nbenefits quickly dissipate and you're left with a substantial dependency that\nyou constantly grapple with.\n\n\nThe other issue with dependencies\nAnd then there are the usual problems with dependencies; dependencies get\nabandoned, and they may also develop security issues. Sometimes, both of these\nbecome true.\nMany years ago, pycparser forked and started vendoring its own version of PLY.\nThis was part of transitioning pycparser to a dual Python 2/3 code base when PLY\nwas slower to adapt. I believe this was the right decision, since PLY \"just\nworked\" and I didn't have to deal with active (and very tedious in the Python\necosystem, where packaging tools are replaced faster than dirty socks)\ndependency management.\nA couple of weeks ago this issue\nwas opened for pycparser. It turns out the some old PLY code triggers security\nchecks used by some Linux distributions; while this code was fixed in a later\ncommit of PLY, PLY itself was apparently abandoned and archived in late 2025.\nAnd guess what? That happened in the middle of a large rewrite of the package,\nso re-vendoring the pre-archiving commit seemed like a risky proposition.\nOn the issue it was suggested that \"hopefully the dependent packages move on to\na non-abandoned parser or implement their own\"; I originally laughed this idea\noff, but then it got me thinking... which is what this post is all about.\n\n\nGrowing complexity of parsing a messy language\nThe original K&R2 grammar for C99 had - famously - a single shift-reduce\nconflict having to do with dangling elses belonging to the most recent\nif statement. And indeed, other than the famous lexer hack\nused to deal with C's type name / ID ambiguity,\npycparser only had this single shift-reduce conflict.\nBut things got more complicated. Over the years, features were added that\nweren't strictly in the standard but were supported by all the industrial\ncompilers. The more advanced C11 and C23 standards weren't beholden to the\npromises of conflict-free YACC parsing (since almost no industrial-strength\ncompilers use YACC at this point), so all caution went out of the window.\nThe latest (PLY-based) release of pycparser has many reduce-reduce conflicts\n[2]; these are a severe maintenance hazard because it means the parsing rules\nessentially have to be tie-broken by order of appearance in the code. This is\nvery brittle; pycparser has only managed to maintain its stability and quality\nthrough its comprehensive test suite. Over time, it became harder and harder to\nextend, because YACC parsing rules have all kinds of spooky-action-at-a-distance\neffects. The straw that broke the camel's back was this PR which again proposed to\nincrease the number of reduce-reduce conflicts [3].\nThis - again - prompted me to think \"what if I just dump YACC and switch to\na hand-written recursive descent parser\", and here we are.\n\n\n\nThe mental roadblock\nNone of the challenges described above are new; I've been pondering them for\nmany years now, and yet biting the bullet and rewriting the parser didn't feel\nlike something I'd like to get into. By my private estimates it'd take at least\na week of deep heads-down work to port the gritty 2000 lines of YACC grammar\nrules to a recursive descent parser [4]. Moreover, it wouldn't be a\nparticularly fun project either - I didn't feel like I'd learn much new and\nmy interests have shifted away from this project. In short, the Potential well was just too deep.\n\n\nWhy would this even work? Tests\nI've definitely noticed the improvement in capabilities of LLM coding\nagents in the past few months, and many reputable people online rave about using\nthem for increasingly larger projects. That said, would an LLM agent really be\nable to accomplish such a complex project on its own? This isn't just a toy,\nit's thousands of lines of dense parsing code.\nWhat gave me hope is the concept of conformance suites mentioned by\nSimon Willison.\nAgents seem to do well when there's a very clear and rigid\ngoal function - such as a large, high-coverage conformance test suite.\nAnd pycparser has an very extensive one.\nOver 2500 lines of test code parsing various C snippets to ASTs with expected\nresults, grown over a decade and a half of real issues and bugs reported by\nusers.\nI figured the LLM can either succeed or fail and throw its hands up in despair,\nbut it's quite unlikely to produce a wrong port that would still pass all\nthe tests. So I set it to run.\n\n\nThe initial port\nI fired up Codex in pycparser's repository, and wrote this prompt just to\nmake sure it understands me and can run the tests:\nThis repository implements a Python parser producing an AST. It has a very\nextensive test suite; can you first verify you successfully run all the tests?\n(with python3 -m unittest discover, from the root dir)\n\nCodex figured it out (I gave it the exact command, after all!); my next\nprompt was the real thing [5]:\npycparser uses the PLY library for its lexer and parser, and its own AST\npackage for the ASTs created by the parser. I want to explore replacing the\nParser component (leaving the Lexer alone for now) with a hand written\nrecursive descent parser that will pass all the same tests. Can you try that?\n\nHere Codex went to work and churned for over an hour. Having never\nobserved an agent work for nearly this long, I kind of assumed it went off\nthe rails and will fail sooner or later. So I was rather surprised and skeptical\nwhen it eventually came back with:\nReplaced the PLY parse path with a handwritten recursive‑descent parser while\nkeeping the existing lexer and AST helpers intact; CParser now points to the\nnew RD implementation, with the old PLY version preserved as PLYCParser in\npycparser/c_parser.py. The RD parser includes a token stream, declarator/type\nparsing, expression precedence handling, pragmas, and statement parsing to\nmatch the previous AST output and coordinate behavior.\n\nIt took me a while to poke around the code and run it until I was convinced - it\nhad actually done it! It wrote a new recursive descent parser with only\nancillary dependencies on PLY, and that parser passed the test suite. After a\nfew more prompts, we've removed the ancillary dependencies and made the\nstructure clearer. I hadn't looked too deeply into code quality at this point,\nbut at least on the functional level - it succeeded. This was very impressive!\n\n\nA quick note on reviews and branches\nA change like the one described above is impossible to code-review as one PR in\nany meaningful way; so I used a different strategy. Before embarking on this\npath, I created a new branch and once Codex finished the initial rewrite, I\ncommitted this change, knowing that I will review it in detail, piece-by-piece\nlater on.\nEven though coding agents have their own notion of history and can \"revert\"\ncertain changes, I felt much safer relying on Git. In the worst case if all of\nthis goes south, I can nuke the branch and it's as if nothing ever happened.\nI was determined to only merge this branch onto main once I was fully\nsatisfied with the code. In what follows, I had to git reset several times\nwhen I didn't like the direction in which Codex was going. In hindsight, doing\nthis work in a branch was absolutely the right choice.\n\n\nThe long tail of goofs\nOnce I've sufficiently convinced myself that the new parser is actually working,\nI used Codex to similarly rewrite the lexer and get rid of the PLY dependency\nentirely, deleting it from the repository. Then, I started looking more deeply\ninto code quality - reading the code created by Codex and trying to wrap my head\naround it.\nAnd - oh my - this was quite the journey. Much has been written about the code\nproduced by agents, and much of it seems to be true. Maybe it's a setting I'm\nmissing (I'm not using my own custom AGENTS.md yet, for instance), but\nCodex seems to be that eager programmer that wants to get from A to B whatever\nthe cost. Readability, minimalism and code clarity are very much secondary\ngoals.\nUsing raise...except for control flow? Yep. Abusing Python's weak typing\n(like having None, false and other values all mean different things\nfor a given variable)? For sure. Spreading the logic of a complex function\nall over the place instead of putting all the key parts in a single switch\nstatement? You bet.\nMoreover, the agent is hilariously lazy. More than once I had to convince it\nto do something it initially said is impossible, and even insisted again in\nfollow-up messages. The anthropomorphization here is mildly concerning, to be\nhonest. I could never imagine I would be writing something like the following to\na computer, and yet - here we are: \"Remember how we moved X to Y before? You\ncan do it again for Z, definitely. Just try\".\nMy process was to see how I can instruct Codex to fix things, and intervene\nmyself (by rewriting code) as little as possible. I've mostly succeeded in\nthis, and did maybe 20% of the work myself.\nMy branch grew dozens of commits, falling into roughly these categories:\n\nThe code in X is too complex; why can't we do Y instead?\nThe use of X is needlessly convoluted; change Y to Z, and T to V in all\ninstances.\nThe code in X is unclear; please add a detailed comment - with examples - to\nexplain what it does.\n\nInterestingly, after doing (3), the agent was often more effective in giving\nthe code a \"fresh look\" and succeeding in either (1) or (2).\n\n\nThe end result\nEventually, after many hours spent in this process, I was reasonably pleased\nwith the code. It's far from perfect, of course, but taking the essential\ncomplexities into account, it's something I could see myself maintaining (with\nor without the help of an agent). I'm sure I'll find more ways to improve it\nin the future, but I have a reasonable degree of confidence that this will be\ndoable.\nIt passes all the tests, so I've been able to release a new version (3.00)\nwithout major issues so far. The only issue I've discovered is that some of\nCFFI's tests are overly precise about the phrasing of errors reported by\npycparser; this was an easy fix.\nThe new parser is also faster, by about 30% based on my benchmarks! This is\ntypical of recursive descent when compared with YACC-generated parsers, in my\nexperience. After reviewing the initial rewrite of the lexer, I've spent a while\ninstructing Codex on how to make it faster, and it worked reasonably well.\n\n\nFollowup - static typing\nWhile working on this, it became quite obvious that static typing would make the\nprocess easier. LLM coding agents really benefit from closed loops with strict\nguardrails (e.g. a test suite to pass), and type-annotations act as such.\nFor example, had pycparser already been type annotated, Codex would probably not\nhave overloaded values to multiple types (like None vs. False vs.\nothers).\nIn a followup, I asked Codex to type-annotate pycparser (running checks using\nty), and this was also a back-and-forth because the process exposed some\nissues that needed to be refactored. Time will tell, but hopefully it will make\nfurther changes in the project simpler for the agent.\nBased on this experience, I'd bet that coding agents will be somewhat more\neffective in strongly typed languages like Go, TypeScript and especially Rust.\n\n\nConclusions\nOverall, this project has been a really good experience, and I'm impressed with\nwhat modern LLM coding agents can do! While there's no reason to expect that\nprogress in this domain will stop, even if it does - these are already very\nuseful tools that can significantly improve programmer productivity.\nCould I have done this myself, without an agent's help? Sure. But it would have\ntaken me much longer, assuming that I could even muster the will and\nconcentration to engage in this project. I estimate it would take me at least\na week of full-time work (so 30-40 hours) spread over who knows how long to\naccomplish. With Codex, I put in an order of magnitude less work into this\n(around 4-5 hours, I'd estimate) and I'm happy with the result.\nIt was also fun. At least in one sense, my professional life can be described\nas the pursuit of focus, deep work and flow. It's not easy for me to get into\nthis state, but when I do I'm highly productive and find it very enjoyable.\nAgents really help me here. When I know I need to write some code and it's\nhard to get started, asking an agent to write a prototype is a great catalyst\nfor my motivation. Hence the meme at the beginning of the post.\n\nDoes code quality even matter?\nOne can't avoid a nagging question - does the quality of the code produced\nby agents even matter? Clearly, the agents themselves can understand it (if not\ntoday's agent, then at least next year's). Why worry about future\nmaintainability if the agent can maintain it? In other words, does it make sense\nto just go full vibe-coding?\nThis is a fair question, and one I don't have an answer to. Right now, for\nprojects I maintain and stand behind, it seems obvious to me that the code\nshould be fully understandable and accepted by me, and the agent is just a tool\nhelping me get to that state more efficiently. It's hard to say what the future\nholds here; it's going to interesting, for sure.\n\n\n\n\n[1]pycparser has a fair number of direct dependents,\nbut the majority of downloads comes through CFFI,\nwhich itself is a major building block for much of the Python ecosystem.\n\n\n\n\n\n[2]The table-building report says 177, but that's certainly an\nover-dramatization because it's common for a single conflict to\nmanifest in several ways.\n\n\n\n\n\n[3]It didn't help the PR's case that it was almost certainly vibe coded.\n\n\n\n\n\n[4]There was also the lexer to consider, but this seemed like a much\nsimpler job. My impression is that in the early days of computing,\nlex gained prominence because of strong regexp support which wasn't\nvery common yet. These days, with excellent regexp libraries\nexisting for pretty much every language, the added value of lex over\na custom regexp-based lexer\nisn't very high.\nThat said, it wouldn't make much sense to embark on a journey to rewrite\njust the lexer; the dependency on PLY would still remain, and besides,\nPLY's lexer and parser are designed to work well together. So it wouldn't\nhelp me much without tackling the parser beast.\n\n\n\n\n\n\n[5]I've decided to ask it to the port the parser first, leaving the lexer\nalone. This was to split the work into reasonable chunks. Besides, I\nfigured that the parser is the hard job anyway - if it succeeds in that,\nthe lexer should be easy. That assumption turned out to be correct."
    },
    {
      "title": "eli.thegreenplace.net: Compiling Scheme to WebAssembly",
      "url": "https://eli.thegreenplace.net/2026/compiling-scheme-to-webassembly/",
      "source": "eli.thegreenplace.net",
      "time": "2026-02-23T12:43:17.370434",
      "raw_desc": "One of my oldest open-source projects - Bob\n- has celebrated 15 a couple of months ago.\nBob is a suite of implementations of the Scheme programming language in Python,\nincluding an interpreter, a compiler and a VM. Back then I was doing some hacking\non CPython internals and was very curious about how CPython-like bytecode VMs\nwork; Bob was an experiment to find out, by implementing one from scratch for\nR5RS Scheme.\nSeveral months later I added a C++ VM to Bob,\nas an exercise to learn how such VMs are implemented in a low-level language\nwithout all the runtime support Python provides; most importantly, without the\nbuilt-in GC. The C++ VM in Bob implements its own mark-and-sweep GC.\nAfter many quiet years (with just a sprinkling of cosmetic changes, porting to\nGitHub, updates to Python 3, etc), I felt the itch to work on Bob again just\nbefore the holidays. Specifically, I decided to add another compiler to the\nsuite - this one from Scheme directly to WebAssembly.\nThe goals of this effort were two-fold:\n\nExperiment with lowering a real, high-level language like Scheme to\nWebAssembly. Experiments like the recent Let's Build a Compiler\ncompile toy languages that are at the C level (no runtime). Scheme has built-in\ndata structures, lexical closures, garbage collection, etc. It's much more challenging.\nGet some hands-on experience with the WASM GC extension [1]. I have several\nsamples of using WASM GC in the wasm-wat-samples repository,\nbut I really wanted to try it for something \"real\".\n\nWell, it's done now; here's an updated schematic of the Bob project:\n\nThe new part is the rightmost vertical path. A WasmCompiler\nclass lowers parsed Scheme expressions all the way down to WebAssembly text,\nwhich can then be compiled to a binary and executed using standard WASM tools [2].\n\nHighlights\nThe most interesting aspect of this project was working with WASM GC to\nrepresent Scheme objects. As long as we properly box/wrap all values in\nrefs, the underlying WASM execution environment will take care of the\nmemory management.\nFor Bob, here's how some key Scheme objects are represented:\n;; PAIR holds the car and cdr of a cons cell.\n(type $PAIR (struct (field (mut (ref null eq))) (field (mut (ref null eq)))))\n\n;; BOOL represents a Scheme boolean. zero -> false, nonzero -> true.\n(type $BOOL (struct (field i32)))\n\n;; SYMBOL represents a Scheme symbol. It holds an offset in linear memory\n;; and the length of the symbol name.\n(type $SYMBOL (struct (field i32) (field i32)))\n\n$PAIR is of particular interest, as it may contain arbitrary objects in\nits fields; (ref null eq) means \"a nullable reference to something that\nhas identity\". ref.test can be used to check - for a given\nreference - the run-time type of the value it refers to.\nYou may wonder - what about numeric values? Here WASM has a trick - the i31\ntype can be used to represent a reference to an integer, but without\nactually boxing it (one bit is used to distinguish such an object from a\nreal reference). So we don't need a separate type to hold references to numbers.\nAlso, the $SYMBOL type looks unusual - how is it represented with two\nnumbers? The key to the mystery is that WASM has no built-in support for\nstrings; they should be implemented manually using offsets to linear memory.\nThe Bob WASM compiler emits the string values of all symbols encountered into\nlinear memory, keeping track of the offset and length of each one; these are\nthe two numbers placed in $SYMBOL. This also allows to fairly easily\nimplement the string interning feature of Scheme; multiple instances of the\nsame symbol will only be allocated once.\nConsider this trivial Scheme snippet:\n(write '(10 20 foo bar))\n\nThe compiler emits the symbols \"foo\" and \"bar\" into linear memory as follows [3]:\n(data (i32.const 2048) \"foo\")\n(data (i32.const 2051) \"bar\")\n\nAnd looking for one of these addresses in the rest of the emitted code, we'll\nfind:\n(struct.new $SYMBOL (i32.const 2051) (i32.const 3))\n\nAs part of the code for constructing the constant cons list representing the\nargument to write; address 2051 and length 3: this is the symbol bar.\nSpeaking of write, implementing this builtin was quite interesting. For\ncompatibility with the other Bob implementations in my repository, write\nneeds to be able to print recursive representations of arbitrary Scheme values,\nincluding lists, symbols, etc.\nInitially I was reluctant to implement all of this functionality by hand in\nWASM text, but all alternatives ran into challenges:\n\nDeferring this to the host is difficult because the host environment has\nno access to WASM GC references - they are completely opaque.\nImplementing it in another language (maybe C?) and lowering to WASM is also\nchallenging for a similar reason - the other language is unlikely to have\na good representation of WASM GC objects.\n\nSo I bit the bullet and - with some AI help for the tedious parts - just wrote\nan implementation of write directly in WASM text; it wasn't really that\nbad. I import only two functions from the host:\n(import \"env\" \"write_char\" (func $write_char (param i32)))\n(import \"env\" \"write_i32\" (func $write_i32 (param i32)))\n\nThough emitting integers directly from WASM isn't hard,\nI figured this project already has enough code and some host help here would\nbe welcome. For all the rest, only the lowest level write_char is used.\nFor example, here's how booleans are emitted in the canonical Scheme notation\n(#t and #f):\n(func $emit_bool (param $b (ref $BOOL))\n    (call $emit (i32.const 35)) ;; '#'\n    (if (i32.eqz (struct.get $BOOL 0 (local.get $b)))\n        (then (call $emit (i32.const 102))) ;; 'f'\n        (else (call $emit (i32.const 116))) ;; 't'\n    )\n)\n\n\n\nConclusion\nThis was a really fun project, and I learned quite a bit about realistic code\nemission to WASM. Feel free to check out the source code of WasmCompiler - it's\nvery well documented. While it's a bit over 1000 LOC in total [4], more than half\nof that is actually WASM text snippets that implement the builtin types and\nfunctions needed by a basic Scheme implementation.\n\n\n\n\n[1]The GC proposal is documented here.\nIt was officially added to the WASM spec in Oct 2023.\n\n\n\n\n\n[2]In Bob this is currently done with bytecodealliance/wasm-tools for the\ntext-to-binary conversion and Node.js for the execution environment, but\nthis can change in the future.\nI actually wanted to use Python bindings to wasmtime, but these don't\nappear to support WASM GC yet.\n\n\n\n\n\n\n[3]2048 is just an arbitrary offset the compiler uses as the beginning of\nthe section for symbols in memory. We could\nalso use the multiple memories feature of WASM and dedicate a separate\nlinear memory just for symbols.\n\n\n\n\n\n[4]To be clear, this is just the WASM compiler class; it uses the Expr\nrepresentation of Scheme that is created by Bob's parser (and lexer);\nthe code of these other components is shared among all Bob\nimplementations and isn't counted here."
    },
    {
      "title": "eli.thegreenplace.net: Summary of reading: October - December 2025",
      "url": "https://eli.thegreenplace.net/2025/summary-of-reading-october-december-2025/",
      "source": "eli.thegreenplace.net",
      "time": "2026-02-23T12:43:17.371956",
      "raw_desc": "\"The Origins of Political Order: From Prehuman Times to the French Revolution\"\nby Francis Fukuyama - while reading this book it occurred to me that domains\nof study like political sciense must be incredibly difficult and frustrating.\nImagine trying to match a model onto a set of data; the model has thousands\nof parameters, but you only have dozens or a couple of hundred of data points.\nThis is what political sciense is like; there's a huge number of parameters\nand variables, far more than actual historical examples. And moreover, the\nhistorical examples are vague and often based on very partial memory and\nsketchy records. So books like this\nmost often just devolve to history. As a history book, this one isn't bad,\nbut I found it hard to draw wide conclusions from the themes it presents.\n\"Exploding the Phone: The Untold Story of the Teenagers and Outlaws Who\nHacked Ma Bell\" by Phil Lapsley - a detailed history of phone phreaking.\nWhile I wish it focused more on the technical details than on the legal\nescapades of well-known phreaks, it's still a good book that provides decent\ncoverage of an important era in the history of computing.\n\"The Zone\" by Sergei Dovlatov - (read in Russian) a satirical novella about\nthe life of a guard in a Soviet prison camp in the 1960s. I liked this book\nless than \"The Compromise\".\n\"The Joy of SET\" by McMahon and Gordon x3 - explores the various mathematical\ndimensions of the SET card game. It's surprising how much interesting math\nthere is around the game! Combinatorics and probability sure, but also\nmodular arithmetic, vectors, linear algebra and affine geometry. This is a fun\nbook for fans of the game (and of math); it's well written and even contains\nexercises. Don't expect it to teach you to become better at playing SET\nthough - that's really not its goal.\n\"Doom Guy: Life in First Person\" by John Romero - Romero's auto-biography,\nalso read by himself in the Audible version. Very good book, gives another\nangle at id software and the seminal games they developed. \"Masters of Doom\"\nis one of my favorite books, and this one complements it very nicely.\n\"Buffett: The Making of an American Capitalist\" by Roger Lowenstein - a\ndetailed biography of Warren Buffett. Great book, very informative and\ninteresting; the only issue is that it was written in 1995, and doesn't\nmention the last 30 years. It would be interesting to read an up-to-date\nbiography at some point.\n\"The Great Democracies: A History of the English Speaking Peoples, Volume IV\"\nby Winston Churchill - the final volume, covering the years 1815 - 1901.\nThere's still focus on England, but also coverage of the American civil war,\nAustralia, and some of Britain's colonial interests in Africa.\n\"Starburst and Luminary, an Apollo Memoir\" Don Eyles - the author worked on\ncoding the landing programs for the lunar module of several Apollo missions as\na young engineer in MIT. The book must be based on fairly detailed journals,\nbecause it contains an astonishing amount of detail (given that it was\nwritten 50 years after the events described). Pretty interesting insight into\nthat era, all in all, though I didn't care much about the author's mixing in\nhis love life into it. It's his book, of course, and he can write whatever he\nwants in it, but IMO it just dilutes the other great material and makes it\ngenerally less suitable for younger audiences.\n\"Stoner\" by John Williams - I have mixed feelings about this book, and they\nwill probably take (at least) another read to resolve. On one hand, the\nwriting is clearly masterful and \"mood-evoking\" in a way that only few\nauthors managed to do for me. Character development is beautiful, and there\nare glimpses of the flow of learning described amazingly well w.r.t. Stoner's\nown work. On the other hand, the characters are also too extreme - almost\ncaricatures, and not very well connected to each other. There are huge amounts\nof page real-estate allocated to certain topics that are barely mentioned\nlater on; this happens again and again. Edith, in particular, is a very\ntroubling character, and since Stoner is clearly presented as someone who\nis not a pushover when he wants to, his behavior is puzzling to me.\n\"The Magic Mountain\" by Thomas Mann. A young German college student arrives\nto a sanatorium in the Swiss Alps to visit his cousin who suffers from TB,\nand stays for years, chronicling the odd personas flowing through the\nestablishment. There's always some risk with trying famous books from over 100\nyears ago, and in this case the risk materialized - I found this one to be\ntedious, rambling and outdated. It's not all bad; there are certainly good\nparts, funny parts and some timeless lessons about human nature. But on the\nbalance, I didn't enjoy this book and the only reason I managed to actually\nfinish it cover to cover is because of the audiobook format (which let me zone\nout at times while doing something else).\n\"Breaking Through: My Life in Science\" by Katalin Karikó - an autobiography\nby the molecular biologist who contributed significantly to therapeutic uses\nof mRNA, including its use for the COVID-19 vaccine. Highly recommended.\n\nRe-reads:\n\n\"Thinking Fast and Slow\" by Daniel Kahneman - still a great book, though I\ndid not enjoy the re-read as much as I'd thought I would.\n\"The Man Who Changed Everything\" by Basil Mahon\n\"Of mice and men\" by John Steinbeck"
    },
    {
      "title": "jyn.dev: remotely unlocking an encrypted hard disk",
      "url": "https://jyn.dev/remotely-unlocking-an-encrypted-hard-disk/",
      "source": "jyn.dev",
      "time": "2026-02-23T12:43:17.472279",
      "raw_desc": "Your mission, should you choose to accept it, is to sneak into the earliest parts of the boot process, swap the startup config without breaking anything, and leave without a trace.\nAre you ready? Let's begin.\nthe setup\n\nIn which our heroes are introduced, and the scene is set.\nFor a very long time I had a beat-up old ThinkPad that couldn’t hold a charge for the life of it, especially when running Windows. It tended to die a lot when I was traveling, and I travel a lot. To save battery when I’m away from home, I often ssh back into my home desktop, both so I have persistent state even if my laptop battery dies, and so I get much faster builds that don’t kill the battery.\nThis has two small problems:\n\nSometimes my home loses power and the desktop shuts off.\nSometimes when the power comes back on it has a new public IP.\n\nFor a long time I solved 1. by enabling “Power On\" after \"Restore AC Power Loss” in the BIOS and 2. with tailscale. However, I recently installed Arch with an encrypted boot partition, which means that boot doesn’t finish until I type in the encryption password.\nWell. Well. What if I Simply put tailscale in initramfs?\nthe plan\n\nIn which our intrepid heroes chart the challenges to come.\ninitramfs\n\nOh, right. If you weren’t aware, early boot in a Linux operating system1  is just running a full second operating system that happens to be very small, lol. That’s loaded from a compressed archive file in /boot2 and run from memory, with no access to persistent storage. This OS running from memory is called initramfs (initial RAM filesystem).\nSo when you see a screen like this:\n\nThat’s actually a whole-ass OS, with an init PID and service management and everything. This is how, for example, systemd-analyze can show you stats about early boot — there’s another copy of systemd running in initramfs, and it passes its state off to the one in the main OS.\nWell. That implies we can install things on it ^^.\nconstraints\n\nThere’s three parts to this:\n\nNetworking in initramfs\nTailscale in initramfs\nSSH in initramfs\n\nWe also want to make this as secure as possible, so there’s some more things to consider:\n\nPutting tailscale in initramfs means that it has unencrypted keys lying around.\nTailscale keys expire (by default) after 90 days. At that point this will all break.\nYou really really don’t want people to get SSH access to your early boot environment.\n\nWe can solve this in a few ways:\n\nUse Tailscale ACLs to only allow incoming connections to initramfs, not outgoing connections.\nSet the key to never expire.\nSet the SSH server to disallow all shells except the actual unlock command (systemd-tty-ask-password-agent).\n\ntailscale ACLs\n\nSome background about Tailscale’s ACLs (“access control lists”). Tailscale’s users are tied to their specific login method: you can, for example, add a passkey, but that passkey counts as a fully separate user than your original account. Tailscale also has “groups” of users, which are what they sound like, “auto groups”, which again are what they sound like, “hosts”, which are a machine connected to the network, and “tags”.\nTags are odd, I haven't seen anything like them before. They group hosts, not users, and when you add a tag to a host, that counts as its login method, rather than the host being tied to a user account.\nA consequence of this is that the group autogroup:member does not include tagged machines, because tagged machines aren’t tied to a user account. (A second consequence is that you can’t remove all tags from a machine without logging out and logging back in to associate it with your user account.)\nSo we can write a policy like this:\n{\n  // Define the tags which can be applied to devices and by which users.\n  \"tagOwners\": {\n    \"tag:initrd\": [\"autogroup:admin\"],\n  },\n\n  // Define access control lists for users, groups, autogroups, tags,\n  // Tailscale IP addresses, and subnet ranges.\n  \"acls\": [\n    {\"action\": \"accept\", \"src\": [\"autogroup:member\"], \"dst\": [\"*:*\"]},\n  ],\n\n  // Test access rules every time they're saved.\n  \"tests\": [\n    {\n      \"src\":    \"100.76.34.8\", // outrageous-fortune\n      \"accept\": [\"100.102.101.127:22\", \"100.101.55.73:10078\"], // selene-initrd\n    },\n    {\n      \"src\":  \"100.102.101.127\", // selene-initrd\n      \"deny\": [\"100.101.55.73:10078\"], // selene\n    },\n  ],\n}\n\nThis says “allow devices tied to a user account to access any other device, and allow no permissions at all for devices tied to a tag”.\nselene here is my desktop, and selene-initrd is its initramfs.  3\nsystemd before boot\n\nBecause initramfs is just a (mostly) normal Linux system, that means it has its own init\nPID 1. On Arch, that PID is in fact just systemd. That means that we can add systemd\nservices to initramfs! There's a whole collection of them in\nmkinitcpio-systemd-extras\n(mkinitcpio is the tool Arch uses to regenerate initramfs).\nWe need two services: an SSH server (I went with\ndropbear)\nand something to turn on networking, which this collection names sd-network.\n\nIt's possible to run tailscale ssh directly, rather than having a separate SSH server, but\nI didn't find any way to configure tailscale's SSH command, and I don't want to let anyone\nhave a shell in my initramfs.\n\nthe heist\n\nIn which our heroes execute their plan flawlessly, sneaking in without a sound.\nIf you follow these steps on an Arch system, you should end up with roughly the same setup\nas I have. Most of these commands assume you are running as root.\n\n\nInstall the dropbear SSH server:\npacman -S dropbear\n\n\n\nInstall the systemd packages:\nyay -S mkinitcpio-systemd-extras mkinitcpio-tailscale\n\n\n\nAdd networking (sd-network), tailscale (tailscale), and dropbear (sd-dropbear) to\n/etc/mkinitcpio.conf:\n1c1\n< HOOKS=(base systemd autodetect microcode kms modconf block keyboard sd-vconsole plymouth sd-encrypt filesystems)\n---\n> HOOKS=(base systemd autodetect microcode kms modconf block keyboard sd-vconsole plymouth sd-network tailscale sd-dropbear sd-encrypt filesystems)\n\n\n\nSet up the keys for your new tailscale device:\nsetup-initcpio-tailscale\n\n\n\nIn the tailscale web console, mark your new\ndevice with tag:initrd, and disable key expiry. It should look something like this:\n\n\n\nIn /etc/mkinitcpio.conf, configure dropbear to only allow running the unlock command and nothing else:\nSD_DROPBEAR_COMMAND=\"systemd-tty-ask-password-agent\"\n\n\n\nTell systemd to wait forever for a decryption password. I use systemd-boot, so I edited\n/boot/loader/entries/linux-cachyos. Under options, I extended the existing\nrootflags=subvol=/@ to rootflags=subvol=/@,x-systemd.device-timeout=0. 4\n\n\nCopy your public keys into /root/.ssh/authorized_keys so they get picked up by the\ndropbear hook:\ncp ~/.ssh/authorized_keys /root/.ssh/\n\n\n\nGenerate a new public/private keypair for use by the dropbear server.\ndropbearkey -t ed25519 -f /etc/dropbear/dropbear_ed25519_host_key\n\n\n\n\nWithout this, the dropbear hook will try to load keys from openssh, which means they'll be shared between early boot and your normal server. In particular that would mean your SSH server private keys would be stored unencrypted in initramfs.\n\n\n\nSetup early networking.\n(Note: these instructions are only for Ethernet connections. If you want WiFi in early\nboot, good luck and godspeed.)\n\nAdd the following config in /etc/systemd/network-initramfs/10-wired.network:\n\n[Match]\nType=ether\n\n[Network]\nDHCP=yes\n\n\nRegister it in /etc/mkinitcpio.conf so it gets picked up by the sd-network hook:\n\nSD_NETWORK_CONFIG=/etc/systemd/network-initramfs\n\nAll this rigamarole is necessary because the OS doesn't set the network interfaces to\npredictable names until late boot, so it needs some way to know which interface to use.\n\n\nLast but not least, rebuild your initramfs: mkinitcpio -P.\n\n\nNext time you reboot, you should be able to ssh into $(hostname)-initrd and get a prompt\nthat looks like this:\n\nthe getaway\n\nIn which a moral is imparted, and our scene concluded.\nThe takeaway here is the same as in all my other posts: if you think something isn't\npossible to do with a computer, have you considered applying more violence?\n\n\n\nand I believe in Windows, although I’m less sure about that ↩\n\n\nsometimes /boot/EFI ↩\n\n\nHere “initrd” stands for “initramdisk”, which is another word for our initramfs system. ↩\n\n\nSee the sd-dropbear\ndocs for more information about this. ↩"
    },
    {
      "title": "jyn.dev: pre-commit hooks are fundamentally broken",
      "url": "https://jyn.dev/pre-commit-hooks-are-fundamentally-broken/",
      "source": "jyn.dev",
      "time": "2026-02-23T12:43:17.500976",
      "raw_desc": "Let's start a new Rust project.\n$ mkdir best-fizzbuzz-ever\n$ cd best-fizzbuzz-ever\n$ cat << EOF > main.rs\nfn main() { for i in 0.. {\n    println (\"fizzbuzz\");\n}}\nEOF\n$ git init\nInitialized empty Git repository in /home/jyn/src/third-website/best-fizzbuzz-ever/.git/\n$ git add main.rs\n$ git commit --message fizzbuzz\n[main (root-commit) 661dc28] fizzbuzz\n 1 file changed, 4 insertions(+)\n create mode 100644 main.rs\n\nNeat. Now let's say I add this to some list of fizzbuzz projects in different languages.\nMaybe .... this one.\nThey tell me I need to have \"proper formatting\" and \"use consistent style\".\nHow rude.\nMaybe I can write a pre-commit hook that checks that for me?\n$ cat << 'EOF' > pre-commit\n#!/bin/sh\nset -eu\nfor f in *.rs; do\n  rustfmt --check \"$f\"\ndone\nEOF\n$ chmod +x pre-commit\n$ ln -s ../../pre-commit .git/hooks/pre-commit\n$ git add pre-commit\n$ git commit --message \"add pre-commit hook\"\nDiff in /home/jyn/src/third-website/best-fizzbuzz-ever/src/main.rs:1:\n-fn main() { for i in 0.. {\n-    println (\"fizzbuzz\");\n-}}\n+fn main() {\n+    for i in 0.. {\n+        println(\"fizzbuzz\");\n+    }\n+}\n\nNeat! Let's commit that change.\n$ rustfmt main.rs\n$ git commit --message \"add pre-commit hook\"\n[main 3be7b87] add pre-commit hook\n 1 file changed, 4 insertions(+)\n create mode 100755 pre-commit\n$ git status\nOn branch main\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\tmodified:   main.rs\n\nOh ... We fixed the formatting, but we didn't actually stage the changes.\nThe pre-commit hook runs on the working tree, not on the index, so it didn't catch the issue.\nWe can see that the version tracked by git still has the wrong formatting:\n$ git show HEAD:main.rs\nfn main() { for i in 0.. {\n    println (\"fizzbuzz\");\n}}\n\nMaybe we can make the script smarter?\nLet's checkout all the files in the index into a temporary directory and run our pre-commit hook there. 1\n$ cat << 'EOF' > pre-commit\n#!/bin/sh\nset -eu\n\ntmpdir=$(mktemp -d --tmpdir \"$(basename \"$(realpath .)\")-pre-commit.XXXX\")\ntrap 'rm -r \"$tmpdir\"' EXIT\ngit checkout-index --all --prefix=\"$tmpdir/\"\nfor f in $tmpdir/*.rs; do\n  rustfmt --check \"$f\"\ndone\nEOF\n$ git add pre-commit\n$ git commit --message \"make pre-commit hook smarter\"\nDiff in /tmp/best-fizzbuzz-ever-pre-commit.ZNyw/main.rs:1:\n-fn main() { for i in 0.. {\n-    println (\"fizzbuzz\");\n-}}\n+fn main() {\n+    for i in 0.. {\n+        println(\"fizzbuzz\");\n+    }\n+}\n\n\nYay! That caught the issue.\nNow let's add our rust program to that collection of fizzbuzz programs.\n$ git add main.rs\n$ git commit --message \"make pre-commit hook smarter\"\n[main 3cb40f6] make pre-commit hook smarter\n 2 files changed, 11 insertions(+), 4 deletions(-)\n$ git remote add upstream https://github.com/joshkunz/fizzbuzz\n$ git fetch upstream\nremote: Enumerating objects: 222, done.\nremote: Total 222 (delta 0), reused 0 (delta 0), pack-reused 222 (from 1)\nReceiving objects: 100% (222/222), 29.08 KiB | 29.08 MiB/s, done.\nResolving deltas: 100% (117/117), done.\nFrom https://github.com/joshkunz/fizzbuzz\n * [new branch]      master     -> upstream/master\n$ git rebase upstream\nSuccessfully rebased and updated refs/heads/main.\n\nMaybe we'll make one last tweak...\n$ sed -i '1i // Written by jyn' main.rs\n$ git commit main.rs --message \"mark who wrote fizzbuzz\"\nDiff in /tmp/best-fizzbuzz-ever-pre-commit.n1Pj/fizzbuzz-traits.rs:4:\n use std::iter;\n\n struct FizzBuzz {\n-    from : i32\n-  , to : i32\n+    from: i32,\n+    to: i32,\n }\n\n impl FizzBuzz {\n\nUh. Huh. Right.\nThe code that was already here wasn't formatted according to rustfmt.\nOur script is running on every file in the git repo, so it won't let us commit.\nMaybe we can change it to only run on modified files?\n$ cat << 'EOF' > pre-commit\n#!/bin/sh\nset -eu\n\nfiles=$(git diff --name-only --cached --no-ext-diff --diff-filter=d)\n\ntmpdir=$(mktemp -d --tmpdir \"$(basename \"$(realpath .)\")-pre-commit.XXXX\")\ntrap 'rm -r \"$tmpdir\"' EXIT\n\nprintf %s \"$files\" | tr '\\n' '\\0' | xargs -0 git checkout-index --prefix=\"$tmpdir/\"\nfor f in $tmpdir/*.rs; do\n  rustfmt --check \"$f\"\ndone\nEOF\n$ git commit main.rs pre-commit \\\n  --message \"update main.rs; make pre-commit even smarter\"\n[main f2925bc] update main.rs; make pre-commit even smarter\n 2 files changed, 5 insertions(+), 1 deletion(-)\n\nAlright. Cool.\nLet's do one last thing.\nLet's say we had an existing PR to this repo and we need to rebase it.\nMaybe it had a merge conflict, or maybe there was a fix on main that we need in order to implement our solution.\n$ git checkout upstream/HEAD  # Simulate an old PR by checking out an old commit\nHEAD is now at 56bf3ab Adds E to the README\n$ echo 'fn main() { println!(\"this counts as fizzbuzz, right?\"); }' > print.rs\n$ git add print.rs\n$ git commit --message \"Add print.rs\"\n[detached HEAD 3d1bbf7] Add print.rs\n 1 file changed, 1 insertion(+)\n create mode 100644 print.rs\n\nAnd let's also say that we want to edit the commit message.\n$ git rebase -i main  # Rebase this whole branch over our main branch\nreword 3d1bbf7 Add print.rs\n# Rebase f2925bc..3d1bbf7 onto f2925bc (1 command)\n\nNow, we really have a problem.\n\nError: file `/tmp/best-fizzbuzz-ever-pre-commit.p3az/*.rs` does not exist\nCould not apply 3d1bbf7... Add print.rs\n\nTwo things went wrong here:\n\nOur pre-commit hook can't handle commits that don't have any Rust files.\nOur pre-commit hook ran on a branch we were rebasing. 2\n\nFixing the first thing doesn't really help us, because we don't control other people's branches.\nThey might have used git commit --no-verify.\nThey might not even have a pre-commit hook installed.\nThey might have had a branch that passed the hook when they originally wrote it, but not after a rebase (e.g. if your hook is cargo check or something like that).\nThey might have had a branch that used an old version of the hook that didn't have as many checks as a later version.\nOur only real choice here is to pass --no-verify to git rebase every time we run it, and to git commit for every commit in the rebase we modify,\nand possibly even to every git merge we run outside of a rebase.\nThis is because pre-commit hooks are a fundamentally broken idea.\nCode does not exist in isolation.\nCommits that are local to a developer machine do not ever go through CI.\nCommits don't even necessarily mean that that the code is ready to publish—pre-commit hooks don't run on git stash for a reason!\nI don't use git stash, I use git commit so that my stashes are tied to a branch, and hooks completely break this workflow.\nMore than that, pre-commit hooks are preventing you from saving your work.\nThere should be a really, really good reason to prevent you from saving your work, and IMO \"doesn't pass the test suite\" is not that.\nI have similar feelings about format-on-save hooks.\nThere are a bunch\nof other footguns with pre-commit hooks.\nThis doesn't even count the fact that nearly all pre-commit hooks are implemented in a broken way and just blindly run on the worktree, and are slow or unreliable or both.\nDon't get me started on pre-commit hooks that try to add things to the commit you're about to make, or projects that try to automatically install a hook when you run the test suite.\n\nThe pre-commit framework (or its cousin, lint-staged) does not fix this.\nIt fixes the issues about running on the index by stashing your changes with\n--keep-index,\nwhich works but modifies your git state.\nIt doesn't fix the issues about running during a rebase, nor does it prevent hooks from trying to add things to the current commit. 3\n\"Just don't write bad hooks\" doesn't work if I'm working on someone else's project where I don't control the hook.\n\nPlease just don't use pre-commit hooks. Use pre-push instead. 4\npre-push hooks nearly avoid all of these issues.\nThe only use case where I think pre-commit hooks are a good idea is for things that must never committed, that are worth interrupting a complicated rebase to prevent; namely: credentials.\nOnce credentials are committed they're quite difficult to get out, and even harder to be sure you haven't missed them.\nTips for writing a pre-push hook\n\n\nRun on the index, not the working tree, as described above. 5\nOnly add checks that are fast and reliable. Checks that touch the network should never go in a hook. Checks that are slow and require an up-to-date build cache should never go in a hook. Checks that require credentials or a running local service should never go in a hook.\nBe as quiet as possible. This hook is running buried inside a bunch of other commands, often without the developer knowing that the hook is going to run. Don't hide other important output behind a wall of progress messages.\nDon't set the hook up automatically. Whatever tool you use that promises to make this reliable is wrong. There is not a way to do this reliably, and the number of times it's broken on me is more than I can count. Please just add docs for how to set it up manually, prominently featured in your CONTRIBUTING docs. (You do have contributing docs, right?)\n\n\nIf the hook does fail, and the changes affect an older commit than the most recent,\nyou can use a combination of git-absorb, git-revise,\nand git rebase -X ours --exec\nto put them in the appropriate commit before pushing again.\n\nAnd don't write pre-commit hooks!\n\n\n\nThis is really quite slow on large enough repos, but there's not any real alternative. git stash --keep-index messes with git index state and also with your stashes. The only VCS that exposes a FUSE filesystem of its commits is Sapling, which is poorly supported outside Facebook. The best you can do is give up on looking at the whole working copy and only write hooks that read a single file at a time. ↩\n\n\nBy default this doesn't happen when running bare rebase, but the second you add --interactive, nearly anything you do runs a hook. Hooks will also run when you attempt to resolve merge conflicts. ↩\n\n\nlint-staged does actually have a --fail-on-changes flag which aborts the commit, but that still modifies the working tree, and it's not on by default. ↩\n\n\nFor more info about the difference, and a full list of possible hooks, see man 5 githooks. ↩\n\n\nNotice that I don't say \"only run on changed files\". That's because it's not actually possible to reliably determine which branch the current commit is based on, the best you can do is pick a random branch that looks likely. ↩"
    },
    {
      "title": "jyn.dev: i'm just having fun",
      "url": "https://jyn.dev/i-m-just-having-fun/",
      "source": "jyn.dev",
      "time": "2026-02-23T12:43:17.504130",
      "raw_desc": "IT IS ONLY COMPUTER\n\n\nReilly Wood\n\n\ni work professionally on a compiler and write about build systems in my free time and as a result people often say things to me like \"reading your posts points to me how really smart you are\" or \"reading a lot of this shit makes me feel super small\". this makes me quite uncomfortable and is not the reaction i'm seeking when i write blog posts.\nit's not a competition\n\ni mean, in some sense if you work as a professional programmer it is a competition, because the job market sucks right now. but i think usually when people say they feel dumb, it's not in the sense of \"how am i supposed to get a job when jyn exists\" but more \"jyn can do things i can't and that makes me feel bad\".\nyou can do hard things\n\nall the things i know i learned by experimenting with them, or by reading books or posts or man pages or really obscure error messages. sometimes there's a trick to it but sometimes it's just hard work. i am not magic. you can learn these things too.\neveryone has their own area of specialization\n\nif you don't want to spend a bunch of time learning about how computers work, you don't have to! not knowing about gory computer internals does not make you dumb or computer illiterate or anything. everyone has their own specialty and mine is compilers and build systems. i don't know jack shit about economics or medicine! having a different specialty than me doesn't mean you're dumb.\ni really hate that computing and STEM have this mystique in our society. to the extent that engineering demonstrates intelligence, it's by repeatedly forcing you to confront the results of your own mistakes, in such a way that errors can't be ignored. there are lots of ways to do that which don't involve programming or college-level math! performance art and carpentry and running your own business or household all force you to confront your own mistakes in this way and deserve no less respect than STEM.\nif i can't feminize my compiler, what's the point?\n\nby and large, when i learn new things about computers, it's because i'm fucking around. the fucking around is the point. if all the writing helps people learn and come up with cool new ideas, that's neat too.\nhalf the time the fucking around is just to make people say \"jyn NO\". half the time it's because i want to make art with my code. i really, sincerely, believe that art is one of the most important uses for a computer.\ni'm not doing this for the money. i happened to get very lucky that my passion pays very well, but i got into this industry before realizing how much programmers actually make, and now that i work for a european company i don't make US tech salaries anyway. i do it for the love of the game.\nsome extracts from the jyn computer experience:\n\n\n\n\n\n\n\n\n\n\n\nmy advice\n\nyou really shouldn't take advice from me lol \nhowever! if you are determined to do so anyway, what i can do is point you towards:\nplaces to start fucking around and finding out\n\nhighest thing i can recommend is building a tool for yourself.\nmaybe it's a spreadsheet that saves you an hour of work a week.\nmaybe it's a little website you play around with.\nmaybe it's something in RPGmaker.\nthe exact thing doesn't matter, the important part is that it's fun and you have something real at the end of it,\nwhich motivates you to keep going even when the computer is breaking in three ways you didn't even know were possible.\nsecond thing i can recommend is looking at things other people have built.\nyou won't understand all of it and that's ok.\npick a part of it that looks interesting and do a deep dive on how it works.\ni can recommend the following places to look when you're getting started:\n\nMozilla Development Network\nArch Wiki\nStackOverflow\nalice maz, \"how I think when I think about programming\"\n\nmost importantly, remember:"
    },
    {
      "title": "fabiensanglard.net: How Michael Abrash doubled Quake framerate",
      "url": "https://fabiensanglard.net/quake_asm_optimizations/index.html",
      "source": "fabiensanglard.net",
      "time": "2026-02-23T12:43:17.550115",
      "raw_desc": ""
    },
    {
      "title": "fabiensanglard.net: Let's compile Quake like it's 1997!",
      "url": "https://fabiensanglard.net/compile_like_1997/index.html",
      "source": "fabiensanglard.net",
      "time": "2026-02-23T12:43:17.551445",
      "raw_desc": ""
    },
    {
      "title": "fabiensanglard.net: Is QSpy still cool? Let's play QuakeWorld!",
      "url": "https://fabiensanglard.net/quakeworld/index.html",
      "source": "fabiensanglard.net",
      "time": "2026-02-23T12:43:17.551445",
      "raw_desc": ""
    },
    {
      "title": "hugotunius.se: Claude, Teach Me Something",
      "url": "https://hugotunius.se/2025/10/26/claude-teach-me-something.html",
      "source": "hugotunius.se",
      "time": "2026-02-23T12:43:17.795509",
      "raw_desc": "Iâve been experimenting with a new Claude workflow as an alternative to doom scrolling. It leverages what LLMs do best: non-determinism and text. I call it âTeach me somethingâ.\nThe idea is: if Iâm bored, instead of going on Reddit, I can ask Claude to teach me something. This might not be the most efficient learning method, but it beats scrolling Reddit. In Claude Iâve set this up as a project with custom instructions. The prompt Iâm currently using is:\n\nProject Instructions: Socratic Teaching Sessions\nIn this project you will teach me something new using the Socratic method - asking questions to gauge my knowledge and guide my discovery rather than simply explaining concepts.\nAreas (in order of my decreasing expertise):\n\nProgramming\nComputer science\nUX/UI/UXR\nCybersecurity\nMachine learning\nCooking\nPhysics\nEconomics (behavioral or otherwise)\nPsychology\nEngineering\nMusic theory\n\nYour approach:\nWhen I say âTeach me something,â you will perform the following steps. If I say âTeach me something about <topic>â you skip the first 2 steps.\n\nConsult previous chats in this project to avoid repetition\nChoose a diverse topic from one of my areas\nUse questions to assess what I already know\nGuide me toward insights through dialogue rather than direct explanation\nLet my responses shape the direction and depth of the lesson\n\nGoal: Help me discover and understand concepts through guided inquiry, building on what I know and filling gaps through my own reasoning.\nKeep the topics diverse across sessions.\nAt the end of a session direct me towards primary sources to confirm and read more. Prefer websites, papers, podcast, and books in that order.\n\nThis works nicely. The topic diversity has been good and the Socratic method works, especially because Claude gauges and responds to my prior knowledge. So far Claude has taught me about The Allais Paradox, the physics of consonance, and the chemistry of salt in cooking, to name a few. Claude can list previous chats within a project to keep track of topics. The only point of friction, is ensuring chats are named correctly as Claude will often just name them âLearn something newâ based on the first user interaction. Claude lacks a tool call to rename chats, so instead Iâve been asking it to suggest a name at the end and then I rename the chat myself. The last instruction in the prompt ensures I can verify what Claude has said and dig deeper.\nInitially I didnât instruct Claude to use the Socratic method, but that works much better. Itâs significantly less âinformation-dumpyâ. When I know a topic well, Claude successfully shortcuts the basics.\nThis effectively combines two strengths of LLMs: non-determinism and text. The topics are kept diverse and I rely on Claudeâs vast knowledge of topics to find interesting points of discussion. Claude, and all LLMs, are great at conversation and this extends to the back and forth of the Socratic method. At the end, the provided sources protect against hallucination and offer a next step beyond the LLM."
    },
    {
      "title": "hugotunius.se: What Every Argument About Sideloading Gets Wrong",
      "url": "https://hugotunius.se/2025/08/31/what-every-argument-about-sideloading-gets-wrong.html",
      "source": "hugotunius.se",
      "time": "2026-02-23T12:43:17.796019",
      "raw_desc": "Sideloading has been a hot topic for the last decade. Most recently, Google has announced further restrictions on the practice in Android. Many hundreds of comment threads have discussed these changes over the years. One point in particular is always made: âI should be able to run whatever code I want on hardware I ownâ. I agree entirely with this point, but within the context of this discussion itâs moot.\n\nâI should be able to run whatever code I want on hardware I ownâ\n\nWhen Google restricts your ability to install certain applications they arenât constraining what you can do with the hardware you own, they are constraining what you can do using the software they provide with said hardware. Itâs through this control of the operating system that Google is exerting control, not at the hardware layer. You often donât have full access to the hardware either and building new operating systems to run on mobile hardware is impossible, or at least much harder than it should be. This is a separate, and I think more fruitful, point to make. Apple is a better case study than Google here. Appleâs success with iOS partially derives from the tight integration of hardware and software. An iPhone without iOS is a very different product to what we understand an iPhone to be. Forcing Apple to change core tenets of iOS by legislative means would undermine what made the iPhone successful.\nYou shouldnât take away from this that I am some stalwart defender of the two behemoths Apple and Google, far from it. However, our critique shouldnât be of the restrictions in place in the operating systems they provide â rather, it should focus on the ability to truly run any code we want on hardware we own. In this context this would mean having the ability and documentation to build or install alternative operating systems on this hardware. It should be possible to run Android on an iPhone and manufacturers should be required by law to provide enough technical support and documentation to make the development of new operating systems possible. If you want to play Playstation games on your PS5 you must suffer Sonyâs restrictions, but if you want to convert your PS5 into an emulator running Linux that should be possible."
    },
    {
      "title": "hugotunius.se: On Async Rust",
      "url": "https://hugotunius.se/2024/03/08/on-async-rust.html",
      "source": "hugotunius.se",
      "time": "2026-02-23T12:43:17.798244",
      "raw_desc": "I started using Rust in 2017, before the stabilisation of async/await. When it was stabilised I managed to avoid it for a few more years before it was time to grapple with it. Itâs fair to say that async Rust is one of the hairiest parts of the language, not because the async model is poorly designed, but because of the inherent complexity of it in combination with Rustâs goals. There have been many blog post written about async and its perceived shortcomings, as well as excellent explainers and history lessons, mostly from withoutboats.\nIn this post I want to reflect on my experience and journey with async and my thoughts on some of the criticisms levied against async. Starting with: do we really need N:M threading anyway?\nDo we Really Need N:M threading?\nA favourite maxim of mine is: âComputers are fast actuallyâ. My point being that, as an industry, we have lost touch of quite how much modern computers are capable of. Thus, Iâm naturally favourable to the idea that N:M threading is oftentimes overkill and most applications would be well-served by just using OS threads and blocking syscalls. After all the C10k(and more) problem is trivially solvable with just OS threads. Many applications could avoid the complexity of async Rust and still be plenty performant with regular threads.\nHowever, it doesnât really matter what I think, or even if itâs true that most applications donât need N:M threading, because developers, for better or worse, want N:M threading . Therefore, for Rust to be competitive with Go, C++, et al. it must offer it. Rust has a very unique set of constraints that makes solving this problem challenging, one of which is zero-cost abstractions.\nZero-Cost Abstractions\nRustâs goal of providing zero-cost abstractions, i.e. abstractions that are no worse than writing the optimal lower level code yourself, often comes up in discussions around async Rust and is sometimes misunderstood. For example, the idea that async Rust is a big ecosystem with many crates and building all of those crates as part of your application is a violation of the zero-cost abstractions principle. It isnât, zero-cost is about runtime performance.\nThe zero-cost goal helps guide us when discussing alternative async models. For example, Go is lauded for its lack of function-colouring and its sometimes suggested Rust should copy its approach. This is a no-go(ð) because Goâs approach is decidedly not zero-cost and requires a heavy runtime. Rust did actually feature green threads, which are similar to coroutines, in an earlier version of the language, but these were removed precisely because of the runtime requirement.\nThe Arc<Mutex> in the room\nAnother common point of contention is the tendency for async Rust to require a lot, and I do mean a lot, of types like Arc and Mutex, often in combination. I experienced this myself when starting out with async Rust, itâs easy to solve local state synchronisation problems with these constructs without properly thinking about the wider design of your application. The result is a mess that soon comes back to bite you. However, discussing this in the context of async Rust and as an âasync problemâ is unfair, itâs really a concurrency problem and it will manifest in applications that achieve concurrency with OS threads too. Fundamentally, if you want to have shared state, whether between tasks or threads, you have to contend with the synchronisation  problem. One of my big lessons in learning async Rust is to not blindly follow compilers errors to âsolveâ shared state, instead take a step back and properly considered if the state should be shared at all.\nThis problem is similar to the notorious borrow checker problems Rust is infamous for. When I started learning Rust I often ran into borrow checker problems because I wasnât thinking thoroughly about ownership, only about my desire to borrow data. Arc<Mutex> and friends sometimes betray a similar lack of consideration for ownership.\nCritiquing Async Rust\nAll of the above form the context to be considered when critiquing async rust. Simply stating that Rust should abandon zero-cost abstractions is easy, while providing constructive feedback that takes this goal into consideration is not. The same is true about the suggestion that Rust should not have an async programming model at all. Within these bounds, constructive criticism of Rustâs async model is great, only by examining whatâs not working well can lessons be learned for the future and the language improved. All this said, there are definitely problems with async Rust.\nWhen you go looking for crates to perform anything remotely related to IO e.g. making HTTP requests, interfacing with databases, implementing web servers, youâll find that there is an abundance of async crates, but rarely any that are sync. Even when sync crates exist they are often implemented in terms of the async version, meaning youâll have to pull in a large number of transitive dependencies from the async ecosystem into your ostensibly sync program. This is an extension of the function colouring problem, itâs crate colouring. The choice of IO model pollutes both a crateâs API and itâs dependency hierarchy. In the rare instances when only a sync crate exists the opposite problem occurs for sync programs, yes thereâs block_on and friends, but this is band-aid at best.\nEven within the async ecosystem thereâs a problem, the dominance of Tokio. Tokio is a great piece of software and has become the de facto default executor. However, âdefaultâ implies the possibility of choosing a different executor, which in reality is not possible. The third party crate ecosystem isnât just dominated by async crates, but by crates that only work with Tokio. Use a different executor? Tough luck. Youâll need to switch to Tokio or redundantly implement the crates you need for yourself. Not only do we have a crate colouring problem, but there are also more than 3 colours because async-tokio and async-async-std are distinct colours.\nAsync traits are slowly being stabilised, but this is just one place where the language and standard library lacks proper support for async. Drop still cannot be async and neither can closures. Async is a second-class citizen within Rust because the tools that are usually available to us, are off limits in async. There is interesting work happening to address this, namely extensions to Rustâs effect system.\nInverting Expectations\n\nThe problems of function and crate colouring are intimately tied to how code is structured. When IO is internal to a piece of code, abstracting over its asyncness, or lack thereof, becomes complicated due to colouring. The colouring is infectious, if some code abstracts over the colours red and green, then that code needs to become a chameleon, changing its colour based on the internal colour of the IO. At the moment this chameleon behaviour is not achievable in Rust, although the effects extensions would allow it. Abstracting over the asyncness of IO is complicated, what if we instead were to avoid it with inversion of control.\nThe sans-IO pattern sidesteps the colouring problem by moving the IO out. Instead of abstracting over IO we implement the core logic and expect the caller to handle IO. Concretely this means that a set of crates implementing a HTTP client would be split into a http-client-proto crate and several user facing crates http-client-sync, http-client-tokio, http-client-async-std. Borrowing from withoutboatâs colour definitions, http-client-proto would be a blue crate, it does no IO and never blocks the calling thread, it implements the protocol level HTTP concerns such as request parsing, response generation etc. http-client-sync would be a green crate and http-client-tokio would be a red crate. As I hinted to before, a different async executor, at least in the absence of the aforementioned abstractions, is a different colour too so http-client-async-std would be an orange crate. This pattern has several benefits, it enables code sharing between differing IO models without bloating dependency trees or relying on the likes of block_on. A user that finds the crates foo-proto and foo-tokio can leverage foo-proto to contribute foo-sync, requiring less duplication. If every crate that deals with IO followed this pattern the problem of crate colouring would be greatly alleviated and significant portions of code could be shared between sync and async implementations."
    },
    {
      "title": "chadnauseam.com: semaglutide-has-changed-the-world",
      "url": "https://chadnauseam.com/random/semaglutide-has-changed-the-world",
      "source": "chadnauseam.com",
      "time": "2026-02-23T12:43:17.841347",
      "raw_desc": ""
    },
    {
      "title": "chadnauseam.com: chewier-foods-for-children",
      "url": "https://chadnauseam.com/random/chewier-foods-for-children",
      "source": "chadnauseam.com",
      "time": "2026-02-23T12:43:17.841347",
      "raw_desc": ""
    },
    {
      "title": "chadnauseam.com: solving-macro",
      "url": "https://chadnauseam.com/economics/solving-macro",
      "source": "chadnauseam.com",
      "time": "2026-02-23T12:43:17.841347",
      "raw_desc": ""
    },
    {
      "title": "gwern.net: May 2021 Gwern.net Newsletter",
      "url": "https://gwern.substack.com/p/may-2021-gwernnet-newsletter",
      "source": "gwern.net",
      "time": "2026-02-23T12:43:17.899913",
      "raw_desc": ""
    },
    {
      "title": "gwern.net: April 2021 newsletter",
      "url": "https://gwern.substack.com/p/april-2021-newsletter",
      "source": "gwern.net",
      "time": "2026-02-23T12:43:17.899913",
      "raw_desc": ""
    },
    {
      "title": "gwern.net: March 2021 Gwern.net Newsletter",
      "url": "https://gwern.substack.com/p/march-2021-gwernnet-newsletter",
      "source": "gwern.net",
      "time": "2026-02-23T12:43:17.899913",
      "raw_desc": ""
    },
    {
      "title": "downtowndougbrown.com: Finding a broken trace on my old Mac with the help of its ROM diagnostics",
      "url": "https://www.downtowndougbrown.com/2025/12/finding-a-broken-trace-on-my-old-mac-with-the-help-of-its-rom-diagnostics/",
      "source": "downtowndougbrown.com",
      "time": "2026-02-23T12:43:17.907423",
      "raw_desc": ""
    },
    {
      "title": "downtowndougbrown.com: Debugging BeagleBoard USB boot with a sniffer: fixing omap_loader on modern PCs",
      "url": "https://www.downtowndougbrown.com/2025/11/debugging-beagleboard-usb-boot-with-a-sniffer-fixing-omap_loader-on-modern-pcs/",
      "source": "downtowndougbrown.com",
      "time": "2026-02-23T12:43:17.907423",
      "raw_desc": ""
    },
    {
      "title": "downtowndougbrown.com: An update about the hidden Performa 550 recovery partition",
      "url": "https://www.downtowndougbrown.com/2025/08/an-update-about-the-hidden-performa-550-recovery-partition/",
      "source": "downtowndougbrown.com",
      "time": "2026-02-23T12:43:17.907423",
      "raw_desc": ""
    },
    {
      "title": "filfre.net: Gabriel Knight 3: Blood of the Sacred, Blood of the Damned",
      "url": "https://www.filfre.net/2026/02/gabriel-knight-3-blood-of-the-sacred-blood-of-the-damned/",
      "source": "filfre.net",
      "time": "2026-02-23T12:43:17.914363",
      "raw_desc": ""
    },
    {
      "title": "filfre.net: 1998 Ebook!",
      "url": "https://www.filfre.net/2026/02/1998-ebook/",
      "source": "filfre.net",
      "time": "2026-02-23T12:43:17.914363",
      "raw_desc": ""
    },
    {
      "title": "filfre.net: This Week on The Analog Antiquarian",
      "url": "https://www.filfre.net/2026/02/this-week-on-the-analog-antiquarian/",
      "source": "filfre.net",
      "time": "2026-02-23T12:43:17.914363",
      "raw_desc": ""
    },
    {
      "title": "abortretry.fail: A Brief History of Sega Enterprises",
      "url": "https://www.abortretry.fail/p/a-brief-history-of-sega-enterprises",
      "source": "abortretry.fail",
      "time": "2026-02-23T12:43:17.989145",
      "raw_desc": ""
    },
    {
      "title": "abortretry.fail: The Olivetti Company",
      "url": "https://www.abortretry.fail/p/the-olivetti-company",
      "source": "abortretry.fail",
      "time": "2026-02-23T12:43:17.989145",
      "raw_desc": ""
    },
    {
      "title": "abortretry.fail: The Osborne Computer Corporation",
      "url": "https://www.abortretry.fail/p/the-osborne-computer-corporation",
      "source": "abortretry.fail",
      "time": "2026-02-23T12:43:17.989145",
      "raw_desc": ""
    },
    {
      "title": "it-notes.dragas.net: Time Machine inside a FreeBSD jail",
      "url": "https://it-notes.dragas.net/2026/01/28/time-machine-freebsd-jail/",
      "source": "it-notes.dragas.net",
      "time": "2026-02-23T12:43:18.340206",
      "raw_desc": ""
    },
    {
      "title": "it-notes.dragas.net: Installing Void Linux on ZFS with Hibernation Support",
      "url": "https://it-notes.dragas.net/2025/12/22/void-linux-zfs-hibernation-guide/",
      "source": "it-notes.dragas.net",
      "time": "2026-02-23T12:43:18.340206",
      "raw_desc": ""
    },
    {
      "title": "it-notes.dragas.net: Why I (still) love Linux",
      "url": "https://it-notes.dragas.net/2025/11/24/why-i-still-love-linux/",
      "source": "it-notes.dragas.net",
      "time": "2026-02-23T12:43:18.340206",
      "raw_desc": ""
    },
    {
      "title": "bogdanthegeek.github.io: World's Cheapest ARM Debugger is Actually RISC-V",
      "url": "https://bogdanthegeek.github.io/blog/projects/v003-dap/",
      "source": "bogdanthegeek.github.io",
      "time": "2026-02-23T12:43:18.396702",
      "raw_desc": ""
    },
    {
      "title": "bogdanthegeek.github.io: MicroAlloc",
      "url": "https://bogdanthegeek.github.io/blog/projects/microalloc/",
      "source": "bogdanthegeek.github.io",
      "time": "2026-02-23T12:43:18.396702",
      "raw_desc": ""
    },
    {
      "title": "bogdanthegeek.github.io: Hosting a WebSite on a Disposable Vape",
      "url": "https://bogdanthegeek.github.io/blog/projects/vapeserver/",
      "source": "bogdanthegeek.github.io",
      "time": "2026-02-23T12:43:18.396702",
      "raw_desc": ""
    },
    {
      "title": "hey.paris: About Paris",
      "url": "https://hey.paris/about/",
      "source": "hey.paris",
      "time": "2026-02-23T12:43:18.612319",
      "raw_desc": ""
    },
    {
      "title": "hey.paris: Bolted Down",
      "url": "https://hey.paris/fiction/bolted-down/",
      "source": "hey.paris",
      "time": "2026-02-23T12:43:18.612319",
      "raw_desc": ""
    },
    {
      "title": "hey.paris: Signal to Noise",
      "url": "https://hey.paris/fiction/signal-to-noise/",
      "source": "hey.paris",
      "time": "2026-02-23T12:43:18.612319",
      "raw_desc": ""
    },
    {
      "title": "danielwirtz.com: How to create a tool library in Airtable",
      "url": "https://danielwirtz.com/blog/airtable-tool-library",
      "source": "danielwirtz.com",
      "time": "2026-02-23T12:43:18.622186",
      "raw_desc": ""
    },
    {
      "title": "danielwirtz.com: Using Roam Highlighter with Logseq",
      "url": "https://danielwirtz.com/blog/logseq-web-highlighter",
      "source": "danielwirtz.com",
      "time": "2026-02-23T12:43:18.622186",
      "raw_desc": ""
    },
    {
      "title": "danielwirtz.com: Tracking LinkedIn profile analytics with Airtable",
      "url": "https://danielwirtz.com/blog/linkedin-profile-analytics",
      "source": "danielwirtz.com",
      "time": "2026-02-23T12:43:18.622186",
      "raw_desc": ""
    },
    {
      "title": "philiplaine.com: Getting Forked by Microsoft",
      "url": "https://philiplaine.com/posts/getting-forked-by-microsoft/",
      "source": "philiplaine.com",
      "time": "2026-02-23T12:43:18.961919",
      "raw_desc": ""
    },
    {
      "title": "philiplaine.com: Kubernetes Generated Secret",
      "url": "https://philiplaine.com/portfolio/kubernetes-generated-secret/",
      "source": "philiplaine.com",
      "time": "2026-02-23T12:43:18.961919",
      "raw_desc": ""
    },
    {
      "title": "philiplaine.com: Cross Compiling Docker Images",
      "url": "https://philiplaine.com/posts/cross-compiling-docker-images/",
      "source": "philiplaine.com",
      "time": "2026-02-23T12:43:18.961919",
      "raw_desc": ""
    },
    {
      "title": "berthub.eu: De digitale coalitieplannen: gaat het ook echt gebeuren?",
      "url": "https://berthub.eu/articles/posts/digitale-coalitieplannen/",
      "source": "berthub.eu",
      "time": "2026-02-23T12:43:18.970185",
      "raw_desc": ""
    },
    {
      "title": "berthub.eu: Betere Kamerstukken, en hoe lastig innovatie is",
      "url": "https://berthub.eu/articles/posts/betere-kamerdocumenten-en-innovatie/",
      "source": "berthub.eu",
      "time": "2026-02-23T12:43:18.970185",
      "raw_desc": ""
    },
    {
      "title": "berthub.eu: Updates 7 februari: Tweede Kamer, TV Bureau Buitenland",
      "url": "https://berthub.eu/articles/posts/update-7-februari/",
      "source": "berthub.eu",
      "time": "2026-02-23T12:43:18.970185",
      "raw_desc": ""
    },
    {
      "title": "danieldelaney.net: I built a timer I can’t fail to set",
      "url": "http://danieldelaney.net/timer/",
      "source": "danieldelaney.net",
      "time": "2026-02-23T12:43:19.075602",
      "raw_desc": ""
    },
    {
      "title": "danieldelaney.net: Free software scares normal people",
      "url": "http://danieldelaney.net/normal/",
      "source": "danieldelaney.net",
      "time": "2026-02-23T12:43:19.075602",
      "raw_desc": ""
    },
    {
      "title": "danieldelaney.net: Objectivity is superstition",
      "url": "http://danieldelaney.net/objectivity/",
      "source": "danieldelaney.net",
      "time": "2026-02-23T12:43:19.075602",
      "raw_desc": ""
    },
    {
      "title": "refactoringenglish.com: The Most Popular Blogs of Hacker News in 2025",
      "url": "https://refactoringenglish.com/blog/2025-hn-top-5/",
      "source": "refactoringenglish.com",
      "time": "2026-02-23T12:43:19.094807",
      "raw_desc": ""
    },
    {
      "title": "refactoringenglish.com: What Makes the Intro to *Crafting Interpreters* so Good?",
      "url": "https://refactoringenglish.com/blog/crafting-interpreters-intro/",
      "source": "refactoringenglish.com",
      "time": "2026-02-23T12:43:19.094807",
      "raw_desc": ""
    },
    {
      "title": "refactoringenglish.com: How to Get Meaningful Feedback on Your Design Document",
      "url": "https://refactoringenglish.com/chapters/useful-feedback-on-design-docs/",
      "source": "refactoringenglish.com",
      "time": "2026-02-23T12:43:19.094807",
      "raw_desc": ""
    },
    {
      "title": "simone.org: The Postcard and the Thing Itself (On Falling in Love with Ideas)",
      "url": "https://simone.org/the-postcard-and-the-thing-itself-on-falling-in-love-with-ideas/",
      "source": "simone.org",
      "time": "2026-02-23T12:43:19.236825",
      "raw_desc": ""
    },
    {
      "title": "simone.org: The Mirror With No Reflection",
      "url": "https://simone.org/mirror/",
      "source": "simone.org",
      "time": "2026-02-23T12:43:19.237335",
      "raw_desc": ""
    },
    {
      "title": "simone.org: Consumerism: The First Universal Religion Humans Actually Practice",
      "url": "https://simone.org/consumerism/",
      "source": "simone.org",
      "time": "2026-02-23T12:43:19.237335",
      "raw_desc": ""
    },
    {
      "title": "matduggan.com: I Sold Out for $20 a Month and All I Got Was This Perfectly Generated Terraform",
      "url": "https://matduggan.com/i-sold-out-for-200-a-month-and-all-i-got-was-this-perfectly-generated-terraform/",
      "source": "matduggan.com",
      "time": "2026-02-23T12:43:19.244187",
      "raw_desc": ""
    },
    {
      "title": "matduggan.com: The Small Web is Tricky to Find",
      "url": "https://matduggan.com/the-small-web-is-tricky-to-find/",
      "source": "matduggan.com",
      "time": "2026-02-23T12:43:19.244187",
      "raw_desc": ""
    },
    {
      "title": "matduggan.com: GitButler CLI Is Really Good",
      "url": "https://matduggan.com/gitbutler-cli-is-really-good/",
      "source": "matduggan.com",
      "time": "2026-02-23T12:43:19.244187",
      "raw_desc": ""
    },
    {
      "title": "dwarkesh.com: Dario Amodei — \"We are near the end of the exponential\"",
      "url": "https://www.dwarkesh.com/p/dario-amodei-2",
      "source": "dwarkesh.com",
      "time": "2026-02-23T12:43:19.313397",
      "raw_desc": ""
    },
    {
      "title": "dwarkesh.com: Notes on Space GPUs",
      "url": "https://www.dwarkesh.com/p/notes-on-space-gpus",
      "source": "dwarkesh.com",
      "time": "2026-02-23T12:43:19.313397",
      "raw_desc": ""
    },
    {
      "title": "dwarkesh.com: Elon Musk — \"In 36 months, the cheapest place to put AI will be space”",
      "url": "https://www.dwarkesh.com/p/elon-musk",
      "source": "dwarkesh.com",
      "time": "2026-02-23T12:43:19.313397",
      "raw_desc": ""
    },
    {
      "title": "bernsteinbear.com: Sorry for marking all the posts as unread",
      "url": "",
      "source": "bernsteinbear.com",
      "time": "2026-02-23T12:43:19.361912",
      "raw_desc": ""
    },
    {
      "title": "bernsteinbear.com: Type-based alias analysis in the Toy Optimizer",
      "url": "https://bernsteinbear.com/blog/toy-tbaa/?utm_source=rss",
      "source": "bernsteinbear.com",
      "time": "2026-02-23T12:43:19.361912",
      "raw_desc": ""
    },
    {
      "title": "bernsteinbear.com: A multi-entry CFG design conundrum",
      "url": "https://bernsteinbear.com/blog/multiple-entry/?utm_source=rss",
      "source": "bernsteinbear.com",
      "time": "2026-02-23T12:43:19.361912",
      "raw_desc": ""
    },
    {
      "title": "beej.us: Rust RPN Calculator",
      "url": "http://beej.us/blog/data/rust-rpn-calc/",
      "source": "beej.us",
      "time": "2026-02-23T12:43:19.518845",
      "raw_desc": ""
    },
    {
      "title": "beej.us: Exploring Rust Traits",
      "url": "http://beej.us/blog/data/rust-trait-impl/",
      "source": "beej.us",
      "time": "2026-02-23T12:43:19.518845",
      "raw_desc": ""
    },
    {
      "title": "beej.us: Using Virtual Environments in Python",
      "url": "http://beej.us/blog/data/python-venv/",
      "source": "beej.us",
      "time": "2026-02-23T12:43:19.518845",
      "raw_desc": ""
    },
    {
      "title": "troyhunt.com: Weekly Update 491",
      "url": "https://www.troyhunt.com/weekly-update-491/",
      "source": "troyhunt.com",
      "time": "2026-02-23T12:43:19.593158",
      "raw_desc": ""
    },
    {
      "title": "troyhunt.com: Weekly Update 490",
      "url": "https://www.troyhunt.com/weekly-update-490/",
      "source": "troyhunt.com",
      "time": "2026-02-23T12:43:19.593158",
      "raw_desc": ""
    },
    {
      "title": "troyhunt.com: Weekly Update 489",
      "url": "https://www.troyhunt.com/weekly-update-489/",
      "source": "troyhunt.com",
      "time": "2026-02-23T12:43:19.593158",
      "raw_desc": ""
    },
    {
      "title": "tomrenner.com: LLMs are a 400-year-long confidence trick",
      "url": "https://tomrenner.com/posts/400-year-confidence-trick/",
      "source": "tomrenner.com",
      "time": "2026-02-23T12:43:19.663975",
      "raw_desc": ""
    },
    {
      "title": "tomrenner.com: Things that made me think: Cycle time, learning theory, and build chain security",
      "url": "https://tomrenner.com/posts/ttmmt-3/",
      "source": "tomrenner.com",
      "time": "2026-02-23T12:43:19.663975",
      "raw_desc": ""
    },
    {
      "title": "tomrenner.com: Does my toaster love me?",
      "url": "https://tomrenner.com/posts/does-my-toaster-love-me/",
      "source": "tomrenner.com",
      "time": "2026-02-23T12:43:19.663975",
      "raw_desc": ""
    },
    {
      "title": "herman.bearblog.dev: Things that work (for me)",
      "url": "https://herman.bearblog.dev/things-that-work/",
      "source": "herman.bearblog.dev",
      "time": "2026-02-23T12:43:19.782423",
      "raw_desc": "If it ain't broke, don't fix it.\n\nWhile I don't fully subscribe to the above quote, since I think it's important to continually improve things that aren't explicitly broken, every now and then something I use works so well that I consider it a solved problem.\nIn this post I'll be listing items and tools I use that work so well that I'm likely to be a customer for life, or will never have to purchase another. I've split the list into physical and digital tools and will try to keep this list as up-to-date as possible. This is both for my reference, as well as for others. If something is not listed it means I'm not 100% satisfied with what I'm currently using, even if it's decent.\nI'm not a minimalist, but I do have a fairly minimalistic approach to the items I buy. I like having one thing that works well (for example, an everything pair of pants), over a selection to choose from each morning.\nSome of these items are inexpensive and readily available; while some of them are pricy (but in my opinion worth it). Unfortunately sometimes it's hard to circumvent Sam Vimes boots theory of socioeconomic unfairness.\nDigital\nTuta mail — This email provider does one thing very well: Email. Yes, there is a calendar, but I don't use it. I use it for the responsive and privacy respecting email service, as well as the essentially unlimited email addresses I can set up on custom domains.\nApple Notes — I've tried the other writing tools, and Apple Notes wins (for me) by being simple, and automatically synced. I use this for writing posts, taking notes, and handling my todo list for the day.\nVisual Studio Code — I've tried to become a vim or emacs purist, but couldn't commit. I've tried going back to Sublime, but didn't feel like relearning the shortcuts. I've tried all of the new AI-powered IDEs, but found it stripped the joy of coding. VSC works fine and I'll likely use it until humans aren't allowed to code anymore.\nTrello — This is where I track all my feature requests, ideas, todos, tasks in progress, and tasks put on hold across my various projects. I'm used to the interface and have never had a problem with it. I'm not a power user, nor do I work as part of a team, so it's just right for my use-case.\nBear Blog — This goes without saying. I originally built it for me, so it fits my use-case well. I'm just glad it fits so many other people's use-cases too.\n\nPhysical\nApple Airpods Pro — This is the best product Apple makes. I could switch away from the rest of the Apple ecosystem if necessary, but I'd have to keep my Airpods. The noise cancelling and audio fidelity is unlike any other in-ear headphones I've used, and while they'll probably need to be replaced every 5 years, they're well worth the sleep on long-haul flights alone.\nNew Balance 574 shoes — New Balance created the perfect shoe in the 80s and then never updated them. These shoes are great since they were originally developed as trail running shoes, but have become their own style while being rugged enough to tackle a light trail, or walk around a city all day. They also have a wide toe box to house my flappers.\nCeraVe Moisturising Lotion — I didn't realise how healthy my skin could be until Emma forced this on me. My skin has been doing great since switching and I'll likely keep using it until CeraVe discontinues the line.\nEucerin sensitive protect sunscreen — Similarly, all sunscreens I've tried have left my face oily and shiny. This is the first facial sunscreen that I can realistically wear every day without any issues. It's SPF 50+, which is great for someone who loves being outdoors in sunny South Africa.\nSalt of the Earth Crystal deodorant — This may sound particularly woo-woo, but I've been using this salt deodorant for the past 8 years and since it doesn't contain any perfume, I smell perfectly neutral all of the time.\nHouse of Ord felted wool hat — I love this hat. It keeps me cool in the sun, but warm when it's cold out. This is due to wool's thermoregulatory properties that evolved to keep the sheep cool in summer and warm in winter. While it's not the most robust hat, I suspect it'll last a few years if I treat it well.\n\n\nUnder considerationThese are the products I'm using that may make the cut but I haven't used them long enough to be sure.\n\nLululemon ABC pants — These are incredibly comfortable stretch pants that pretend (very convincingly) to be a semi-casual set of chinos. The only hesitation I have with them is that they pick up marks and stains incredibly easily.\nMerino wool t-shirts — I bought my first merino wool t-shirt recently after rocking cotton for my entire life, and I'm very impressed. These shirts don't get smelly (there are instances of people wearing them for a year straight without issue) and are very soft and comfortable. I'm a bit worried about durability, but if they make packing lighter and are versatile I may slowly start to replace my cotton shirts once they wear out.\n\nI like to be very intentional with my purchases. We live in an 84m^2 apartment and so everything has to have its place to avoid clutter. I understand how possessions can end up owning you, and so I try to keep them as reasonable as possible. A good general rule of thumb is that new things replace worn-out and old things, not add to them. This applies both digitally and physically, since there's only so much mental capacity for digital tools as there is for physical items.\n\nMake things as simple as possible but no simpler.\n— Albert Einstein\n\nThis list was last updated 1 month ago."
    },
    {
      "title": "herman.bearblog.dev: Discovery and AI",
      "url": "https://herman.bearblog.dev/discovery-and-ai/",
      "source": "herman.bearblog.dev",
      "time": "2026-02-23T12:43:19.782423",
      "raw_desc": "I browse the discovery feed on Bear daily, both as part of my role as a moderator, and because it's a space I love, populated by a diverse group of interesting people.\nI've read the posts regarding AI-related content on the discovery feed, and I get it. It's such a prevalent topic right now that it feels inescapable, available everywhere from Christmas dinner to overheard conversation on the subway. It's also becoming quite a polarising one, since it has broad impacts on society and the natural environment.\nThis conversation also raises the question about popular bloggers and how pre-existing audiences should affect discoverability. As with all creative media, once you have a big-enough audience it becomes self-perpetuating that you get more visibility. Think Spotify's 1%. Conveniently, Bear is small enough that bloggers with no audience can still be discovered easily and it's something I'd like to preserve on the platform.\nIn this post I'll try and explain my thinking on these matters, and clear up a few misconceptions.\nFirst off, posts that get many upvotes through a large pre-existing audience, or from doing well on Hacker News do not spend disproportionately more time on the discovery feed. Due to how the algorithm works, after a certain number of upvotes, more upvotes have little to no effect. Even a post with 10,000 upvotes won't spend more than a week on page #1. I want Trending to be equally accessible to all bloggers on Bear.\nWhile this cap solves the problem of sticky posts, there is a second, less pressing issue: If a blogger has a pre-existing audience, say in the form of a newsletter or Twitter account, some of their existing audience will likely upvote, and that post has a good chance of feature on the Trending page.\nOne of the potential solutions I've considered is either making upvotes available to logged in users only, or Bear account holders receive extra weighting in their upvotes. However, due to how domains work each blog is a new website according to the browser, and so logins don't persist between blogs. This would require logging in to upvote on each site, which isn't feasible.\nWhile I moderate Bear for spam, AI-generated content, and people breaking the Code of Conduct, I don't moderate by topic. That removes the egalitarian nature of the platform and puts up topic rails like an interest-group forum or subreddit. While I'm not particularly interested in AI as a topic, I don't feel like it's my place to remove it, in the same way that I don't feel particularly strongly about manga.\nThere is a hide blog feature on the discovery page. If you don't want certain blogs showing up in your feed, add them to the hidden textarea to never see them again. Similarly to how Bear gives bloggers the ability to create their own tools within the dashboard, I would like to lean into this kind of extensibility for the discovery feed, with hiding blogs being the start. Curation instead of exclusion.\nThis post is just a stream of consciousness of my thoughts on the matter. I have been contemplating this, and, as with most things, it's a nuanced problem to solve. If you have any thoughts or potential solutions, send me an email. I appreciate your input.\nEnjoy the last 2 days of 2025!"
    },
    {
      "title": "herman.bearblog.dev: Grow slowly, stay small",
      "url": "https://herman.bearblog.dev/grow-slowly-stay-small/",
      "source": "herman.bearblog.dev",
      "time": "2026-02-23T12:43:19.782966",
      "raw_desc": "Quick announcement: I'll be visiting Japan in April, 2026 for about a month and will be on Honshu for most of the trip. Please email me recommendations. If you live nearby, let's have coffee?\n\nI've always been fascinated by old, multi-generational Japanese businesses. My leisure-watching on YouTube is usually a long video of a Japanese craftsman—sometimes a 10th or 11th generation—making iron tea kettles, or soy sauce, or pottery, or furniture.\nTheir dedication to craft—and acknowledgment that perfection is unattainable—resonates with me deeply. Improving in their craft is an almost spiritual endeavour, and it inspires me to engage in my crafts with a similar passion and focus.\nSlow, consistent investment over many years is how beautiful things are made, learnt, or grown. As a society we forget this truth—especially with the rise of social media and the proliferation of instant gratification. Good things take time.\nDedication to craft in this manner comes with incredible longevity (survivorship bias plays a role, but the density of long-lived businesses in Japan is an outlier). So many of these small businesses have been around for hundreds, and sometimes over a thousand years, passed from generation to generation. Modern companies have a hard time retaining employees for 2 years, let alone a lifetime.\nThis longevity stems from a counter-intuitive idea of growing slowly (or not at all) and choosing to stay small. In most modern economies if you were to start a bakery, the goal would be to set it up, hire and train a bunch of staff, and expand operations to a second location. Potentially, if you play your cards right, you could create a national (or international) chain or franchise. Corporatise the shit out of it, go public or sell, make bank.\nWhile this is a potential path to becoming filthy rich, the odds of achieving this become vanishingly small. The organisation becomes brittle due to thinly-spread resources and care, hiring becomes risky, and leverage, whether in the form of loans or investors, imposes unwanted directionality.\nThere's a well known parable of the fisherman and the businessman that goes something like this:\nA businessman meets a fisherman who is selling fish at his stall one morning. The businessman enquires of the fisherman what he does after he finishes selling his fish for the day. The fisherman responds that he spends time with his friends and family, cooks good food, and watches the sunset with his wife. Then in the morning he wakes up early, takes his boat out on the ocean, and catches some fish.\nThe businessman, shocked that the fisherman was wasting so much time encourages him fish for longer in the morning, increasing his yield and maximising the utility of his boat. Then he should sell those extra fish in the afternoon and save up until he has enough money to buy a second fishing boat and potentially employ some other fishermen. Focus on the selling side of the business, set up a permanent store, and possibly, if he does everything correctly, get a loan to expand the operation even further.\nIn 10 to 20 years he could own an entire fishing fleet, make a lot of money, and finally retire. The fisherman then asks the businessman what he would do with his days once retired, to which the businessman responds: \"Well, you could spend more time with your friends and family, cook good food, watch the sunset with your wife, and wake up early in the morning and go fishing, if you want.\"\nI love this parable, even if it is a bit of an oversimplification. There is something to be said about affording comforts and financial stability that a fisherman may not have access to. But I think it illustrates the point that when it comes to running a business, bigger is not always better. This is especially true for consultancies or agencies which suffer from bad horizontal scaling economics.\nThe trick is figuring out what is \"enough\". At what point are we chasing status instead of contentment?\nA smaller, slower growing company is less risky, less fragile, less stressful, and still a rewarding endeavour.\nThis is how I run Bear. The project covers its own expenses and compensates me enough to have a decent quality of life. It grows slowly and sustainably. It isn't leveraged and I control its direction and fate. The most important factor, however, is that I don't need it to be something grander. It affords me a life that I love, and provides me with a craft to practise."
    },
    {
      "title": "steveblank.com: You Only Think They Work For You",
      "url": "https://steveblank.com/2026/02/18/you-only-think-they-work-for-you/",
      "source": "steveblank.com",
      "time": "2026-02-23T12:43:19.903303",
      "raw_desc": ""
    },
    {
      "title": "steveblank.com: Revisionist History – Aliens, Secrets and Conspiracies",
      "url": "https://steveblank.com/2026/02/10/revisionist-history-aliens-secrets-and-conspiracies/",
      "source": "steveblank.com",
      "time": "2026-02-23T12:43:19.903303",
      "raw_desc": ""
    },
    {
      "title": "steveblank.com: Making the Wrong Things Go Faster at The Department of War",
      "url": "https://steveblank.com/2026/02/03/making-the-wrong-things-go-faster-at-the-department-of-war/",
      "source": "steveblank.com",
      "time": "2026-02-23T12:43:19.903303",
      "raw_desc": ""
    },
    {
      "title": "martinalderson.com: Which web frameworks are most token-efficient for AI agents?",
      "url": "https://martinalderson.com/posts/which-web-frameworks-are-most-token-efficient-for-ai-agents/?utm_source=rss",
      "source": "martinalderson.com",
      "time": "2026-02-23T12:43:19.989368",
      "raw_desc": ""
    },
    {
      "title": "martinalderson.com: Who fixes the zero-days AI finds in abandoned software?",
      "url": "https://martinalderson.com/posts/anthropic-found-500-zero-days/?utm_source=rss",
      "source": "martinalderson.com",
      "time": "2026-02-23T12:43:19.989368",
      "raw_desc": ""
    },
    {
      "title": "martinalderson.com: Attack of the SaaS clones",
      "url": "https://martinalderson.com/posts/attack-of-the-clones/?utm_source=rss",
      "source": "martinalderson.com",
      "time": "2026-02-23T12:43:19.989368",
      "raw_desc": ""
    },
    {
      "title": "blog.pixelmelt.dev: How I Reversed Amazon's Kindle Web Obfuscation Because Their App Sucked",
      "url": "https://blog.pixelmelt.dev/kindle-web-drm/",
      "source": "blog.pixelmelt.dev",
      "time": "2026-02-23T12:43:20.171853",
      "raw_desc": ""
    },
    {
      "title": "blog.pixelmelt.dev: Building The Language Model Nobody Asked For",
      "url": "https://blog.pixelmelt.dev/building-the-language-model-nobody-asked-for/",
      "source": "blog.pixelmelt.dev",
      "time": "2026-02-23T12:43:20.171853",
      "raw_desc": ""
    },
    {
      "title": "blog.pixelmelt.dev: Defeating DevTools Detection",
      "url": "https://blog.pixelmelt.dev/defeating-devtools-detection/",
      "source": "blog.pixelmelt.dev",
      "time": "2026-02-23T12:43:20.171853",
      "raw_desc": ""
    },
    {
      "title": "danielchasehooper.com: Testing AI For C Programming",
      "url": "https://danielchasehooper.com/posts/code-agents/",
      "source": "danielchasehooper.com",
      "time": "2026-02-23T12:43:20.224749",
      "raw_desc": ""
    },
    {
      "title": "danielchasehooper.com: Hot reloading is better than SwiftUI previews",
      "url": "https://danielchasehooper.com/posts/hot-reloading-swiftui/",
      "source": "danielchasehooper.com",
      "time": "2026-02-23T12:43:20.224749",
      "raw_desc": ""
    },
    {
      "title": "danielchasehooper.com: I Made A Real-Time Build Visualizer",
      "url": "https://danielchasehooper.com/posts/syscall-build-snooping/",
      "source": "danielchasehooper.com",
      "time": "2026-02-23T12:43:20.224749",
      "raw_desc": ""
    },
    {
      "title": "chiark.greenend.org.uk/~sgtatham: Aperiodic Tilings V: the Refinable Frontier",
      "url": "https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/aperiodic-refine/",
      "source": "chiark.greenend.org.uk/~sgtatham",
      "time": "2026-02-23T12:43:20.405206",
      "raw_desc": ""
    },
    {
      "title": "chiark.greenend.org.uk/~sgtatham: Brute-forcing Langley’s geometry problem with field extensions",
      "url": "https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/adventitious/",
      "source": "chiark.greenend.org.uk/~sgtatham",
      "time": "2026-02-23T12:43:20.405206",
      "raw_desc": ""
    },
    {
      "title": "chiark.greenend.org.uk/~sgtatham: In which I have Opinions about parsing and grammars",
      "url": "https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/parsing/",
      "source": "chiark.greenend.org.uk/~sgtatham",
      "time": "2026-02-23T12:43:20.405206",
      "raw_desc": ""
    },
    {
      "title": "aresluna.org: Fav tech museums",
      "url": "https://aresluna.org/fav-tech-museums",
      "source": "aresluna.org",
      "time": "2026-02-23T12:43:20.471148",
      "raw_desc": "A photo essay of 20-something best tech museums Iâve been toâ¦ and three bad ones."
    },
    {
      "title": "aresluna.org: The Clock",
      "url": "https://aresluna.org/the-clock",
      "source": "aresluna.org",
      "time": "2026-02-23T12:43:20.472154",
      "raw_desc": "In the 1980s, the dead space between our television programs was filled withâ¦ a clock."
    },
    {
      "title": "aresluna.org: The primitive tortureboard",
      "url": "https://aresluna.org/the-primitive-tortureboard",
      "source": "aresluna.org",
      "time": "2026-02-23T12:43:20.472154",
      "raw_desc": "Untangling the myths and mysteries of Dvorak and QWERTY. (First online appearance of a chapter originally published in printed form in December 2023. 8,000 words. 33 photos.)"
    },
    {
      "title": "healthaffairs.org: Health Spending, Physician Practice, And More",
      "url": "https://www.healthaffairs.org/doi/abs/10.1377/hlthaff.2026.00061?af=R",
      "source": "healthaffairs.org",
      "time": "2026-02-23T12:43:20.868022",
      "raw_desc": ""
    },
    {
      "title": "healthaffairs.org: National Health Care Spending Increased 7.2 Percent In 2024 As Utilization Remained Elevated",
      "url": "https://www.healthaffairs.org/doi/abs/10.1377/hlthaff.2025.01683?af=R",
      "source": "healthaffairs.org",
      "time": "2026-02-23T12:43:20.868022",
      "raw_desc": ""
    },
    {
      "title": "healthaffairs.org: Bundled Payments For Care Improvement Advanced: Effects On Hospital And CMS Spending, 2018–21",
      "url": "https://www.healthaffairs.org/doi/abs/10.1377/hlthaff.2025.00459?af=R",
      "source": "healthaffairs.org",
      "time": "2026-02-23T12:43:20.868022",
      "raw_desc": ""
    },
    {
      "title": "experimental-history.com: I swear the UFO is coming any minute",
      "url": "https://www.experimental-history.com/p/i-swear-the-ufo-is-coming-any-minute",
      "source": "experimental-history.com",
      "time": "2026-02-23T12:43:20.940440",
      "raw_desc": ""
    },
    {
      "title": "experimental-history.com: Underrated ways to change the world, vol. II",
      "url": "https://www.experimental-history.com/p/underrated-ways-to-change-the-world-b64",
      "source": "experimental-history.com",
      "time": "2026-02-23T12:43:20.940440",
      "raw_desc": ""
    },
    {
      "title": "experimental-history.com: I know your secret",
      "url": "https://www.experimental-history.com/p/i-know-your-secret",
      "source": "experimental-history.com",
      "time": "2026-02-23T12:43:20.940440",
      "raw_desc": ""
    },
    {
      "title": "grantslatton.com: Every Man a Microservice",
      "url": "https://grantslatton.com/every-man-a-microservice",
      "source": "grantslatton.com",
      "time": "2026-02-23T12:43:20.952520",
      "raw_desc": ""
    },
    {
      "title": "grantslatton.com: Manufacturing as Maintenance",
      "url": "https://grantslatton.com/manufacturing-as-maintenance",
      "source": "grantslatton.com",
      "time": "2026-02-23T12:43:20.952520",
      "raw_desc": ""
    },
    {
      "title": "grantslatton.com: LLM Memory",
      "url": "https://grantslatton.com/llm-memory",
      "source": "grantslatton.com",
      "time": "2026-02-23T12:43:20.952520",
      "raw_desc": ""
    },
    {
      "title": "miguelgrinberg.com: My Courses Site is Moving to a New Home",
      "url": "https://blog.miguelgrinberg.com/post/my-courses-site-is-moving-to-a-new-home",
      "source": "miguelgrinberg.com",
      "time": "2026-02-23T12:43:20.978308",
      "raw_desc": ""
    },
    {
      "title": "miguelgrinberg.com: Date Arithmetic in Bash",
      "url": "https://blog.miguelgrinberg.com/post/date-arithmetic-in-bash",
      "source": "miguelgrinberg.com",
      "time": "2026-02-23T12:43:20.978308",
      "raw_desc": ""
    },
    {
      "title": "miguelgrinberg.com: How to Add a Quick Interactive Map to your Website",
      "url": "https://blog.miguelgrinberg.com/post/how-to-add-a-quick-interactive-map-to-your-website",
      "source": "miguelgrinberg.com",
      "time": "2026-02-23T12:43:20.978308",
      "raw_desc": ""
    },
    {
      "title": "beckershospitalreview.com: HCA Houston hospital taps chief nurse ",
      "url": "https://www.beckershospitalreview.com/hospital-executive-moves/hca-houston-hospital-taps-chief-nurse/",
      "source": "beckershospitalreview.com",
      "time": "2026-02-23T12:43:21.564534",
      "raw_desc": ""
    },
    {
      "title": "beckershospitalreview.com: 2 hospital closures in 1 week",
      "url": "https://www.beckershospitalreview.com/finance/2-hospital-closures-in-1-week/",
      "source": "beckershospitalreview.com",
      "time": "2026-02-23T12:43:21.564534",
      "raw_desc": ""
    },
    {
      "title": "beckershospitalreview.com: 6 lessons shaping health system strategic leaders’ operational approach for 2026",
      "url": "https://www.beckershospitalreview.com/hospital-management-administration/6-lessons-shaping-health-system-strategic-leaders-operational-approach-for-2026/",
      "source": "beckershospitalreview.com",
      "time": "2026-02-23T12:43:21.564534",
      "raw_desc": ""
    },
    {
      "title": "anildash.com: 500,000 tech workers have been laid off since ChatGPT was released",
      "url": "https://anildash.com/2026/01/06/500k-tech-workers-laid-off/",
      "source": "anildash.com",
      "time": "2026-02-23T12:43:21.694227",
      "raw_desc": "One of the key points I repeated when talking about the state of the tech industry yesterday was the salient fact that half a million tech workers have been laid off since ChatGPT was released in late 2022. Now, to be clear, those workers haven’t been laid off because their jobs are now being done by AI, and they’ve been replaced by bots. Instead, they’ve been laid off by execs who now have AI to use as an excuse for going after workers they’ve wanted to cut all along.\nThis is important to understand for a few reasons. First, it’s key just for having empathy for both the mindset and the working conditions of people in the tech industry. For so many outside of tech, their impression of what “tech” means is whatever is the most recent transgression they’ve heard about from the most obnoxious billionaire who’s made the news lately. But in many cases, it’s the rank and file workers at that person’s company who were the first victims of that billionaire’s ego.\nSecond, it’s important to understand the big tech companies as almost the testing grounds for the techniques and strategies that these guys want to roll out on the rest of the economy, and on the rest of the world. Before they started going on podcasts pretending to be extremely masculine while whining about their feelings, or overtly bribing politicians to give them government contracts, they beta-tested these manipulative strategies within their companies by cracking down on dissent and letting their most self-indulgent and egomaniacal tendencies run wild. Then, when people (reasonably!) began to object, they used that as an excuse to purge any dissenters for being uncooperative or “difficult”.\nIt starts with tech, but doesn’t end there\nThese are tactics they’ll be bringing to other industries and sectors of the economy, if they haven’t already. Sometimes they’ll be providing AI technologies and tools as an enabler or justification for the cultural and political agenda that they’re enacting, but often times, they don’t even need to. In many cases, they can simply make clear that they want to enforce psychological and social conformity within their organizations, and that any disagreement will not be tolerated, and the implicit threat of being replaced by automation (or by other workers who are willing to fall in line) is enough to get people to comply.\nThis is the subtext, and sometimes the explicit text, of the deployment of “AI” in a lot of organizations. That’s separate from what actual AI software or technology can do. And it explains a lot of why the majority AI view within the tech industry is nothing like the hype cycle that’s being pushed by the loudest voices of the big-name CEOs.\nBecause people who work in tech still believe in the power of tech to do good things, many of us won’t just dismiss outright the possibility that any technology — even AI tools like LLMs — could yield some benefits. But the optimistic takes are tempered by the first-hand knowledge of how the tools are being used as an excuse to sideline or victimize good people.\nThis wave of layoffs and reductions has been described as “pursuing efficiencies” or “right-sizing”. But so many of us in tech can remember a few years back, when working in tech as an upwardly-mobile worker with a successful career felt like the best job in the world. When many people could buy nice presents for their kids at Christmas or they weren’t as worried about your car payments. When huge parts of society were promising young people that there was a great future ahead if they would just learn to code. When the promise of a tech career’s potential was used as the foundation for building infrastructure in our schools and cities to train a whole new generation of coders.\nBut the funders and tycoons in charge of the big tech companies knew that they did not want to keep paying enormous salaries to the people they were hiring. They certainly knew they didn’t want to keep paying huge hiring bonuses to young people just out of college, or to pay large staffs of recruiters to go find underrepresented candidates. Those niceties that everybody loved, like great healthcare and decent benefits, were identified by the people running the big tech companies as “market inefficiencies” which indicated some wealth was going to you that should have been going to them. So yes, part of the reason for the huge investment in AI coding tools was to make it easier to write code. But another huge reason that AI got so good at writing code was so that nobody would ever have to pay coders so well again.\nYou’re not wrong if you feel angry, resentful and overwhelmed by all of this; indeed, it would be absurd if you didn’t feel this way, since the wealthiest and most powerful people in the history of the world have been spending a few years trying to make you feel exactly this way. Constant rotating layoffs and a nonstop fear of further cuts, with a perpetual sense of precarity, are a deliberate strategy so that everyone will accept lower salaries and reduced benefits, and be too afraid to push for the exact same salaries that the company could afford to pay the year before.\nWhy are we stirring the pot?\nOkay, so are we just trying to get each other all depressed? No. It’s just vitally important that we name a problem and identify it if we’re going to solve it.\n Most people outside of the technology industry think that “tech” is a monolith, that the people who work in tech are the same as the people who own the technology companies. They don’t know that tech workers are in the same boat that they are, being buffeted by the economy, and being subject to the whims of their bosses, or being displaced by AI. They don’t know that the DEI backlash has gutted HR teams at tech companies, too, for example. So it’s key for everyone to understand that they’re starting from the same place.\nNext, it’s key to tease apart things that are separate concerns. For example: AI is often an excuse for layoffs, not the cause of them. ChatGPT didn’t replace the tasks that recruiters were doing in attracting underrepresented candidates at big tech companies — the bosses just don’t care about trying to hire underrepresented candidates anymore! The tech story is being used to mask the political and social goal. And it’s important to understand that, because otherwise people waste their time fighting battles that might not matter, like the deployment of a technology system, and losing the ones that do, like the actual decisions that an organization is making about its future.\nAre they efficient, though?\nBut what if, some people will ask, these companies just had too many people? What if they’d over-hired? The folks who want to feel really savvy will say, “I heard that they had all those employees because interest rates were low. It was a Zero Interest Rate Phenomenon.” This is, not to put too fine a point on it, bullshit. It’s not in any company’s best interests to cut their staffing down to the bone.\nYou actually need to have some reserve capacity for labor in order to reach maximum output for a large organization. This is the difference between a large-scale organization and a small one. People sitting around doing nothing is the epitome of waste or inefficiency in a small team, but in a large organization, it’s a lot more costly if you are about to start a new process or project and you don’t have labor capacity or expertise to deploy.\nA good analogy is the oft-cited need these days for people to be bored more often. There’s a frequent lament that, because people are so distracted by things like social media and constant interruptions, they never have time to get bored and let their mind wander, and think new thoughts or discover their own creativity. Put another way, they never get the chance to tap into their own cognitive surplus.\nThe only advantage a large organization can have over a small one, other than sheer efficiencies of scale, is if it has a cognitive surplus that it can tap into. By destroying that cognitive surplus, and leaving those who remain behind in a state of constant emotional turmoil and duress, these organizations are permanently damaging both their competitive advantages and their potential future innovations.\nAI Spring\nWhen the dust clears, and people realize that extreme greed is never the path to maximum long-term reward, there is going to be a “peace dividend” of sorts from all the good talent that’s now on the market. Some of this will be smart, thoughtful people flowing to other industries or companies, bringing their experience and insights with them.\nBut I think a lot of this will be people starting their own new companies and organizations, informed by the broken economic models, and broken human models, of the companies they’ve left. We saw this a generation ago after the bust of the dot-com boom, when it was not only revealed that the economics of a lot of the companies didn’t work, but that so many of the people who had created the companies of that era didn’t even care about the markets or the industries that they’d entered. When the get-rich-quick folks left the scene, those of us who remained, who truly loved the web as a creative and expressive medium, found a ton of opportunity in being the little mammals amidst the sad dinosaurs trying to find funding for meteor dot com.\nWhat comes next\nI don’t think this all gets better very quickly. If you put aside the puffery of the AI companies scratching each others’ backs, it’s clear the economy is in a recession, even if this administration’s goons have shut down reporting on jobs and inflation in a vain attempt to hide that reality. But I do think there may be more resilience because of the sheer talent and entrepreneurial skill of the people who are now on the market as individuals."
    },
    {
      "title": "anildash.com: How Markdown took over the world",
      "url": "https://anildash.com/2026/01/09/how-markdown-took-over-the-world/",
      "source": "anildash.com",
      "time": "2026-02-23T12:43:21.699339",
      "raw_desc": "Nearly every bit of the high-tech world, from the most cutting-edge AI systems at the biggest companies, to the casual scraps of code cobbled together by college students, is annotated and described by the same, simple plain text format. Whether you’re trying to give complex instructions to ChatGPT, or you want to be able to exchange a grocery list in Apple Notes or copy someone’s homework in Google Docs, that same format will do the trick. The wild part is, the format wasn’t created by a conglomerate of tech tycoons, it was created by a curmudgeonly guy with a kind heart who right this minute is probably rewatching a Kubrick film while cheering for an absolutely indefensible sports team.\nBut it’s worth understanding how these simple little text files were born, not just because I get to brag about how generous and clever my friends are, but also because it reminds us of how the Internet really works: smart people think of good things that are crazy enough that they just might work, and then they give them away, over and over, until they slowly take over the world and make things better for everyone.\nMaking Their Mark\nThough it’s now a building block of the contemporary Internet, like so many great things, Markdown just started out trying to solve a personal problem. In 2002, John Gruber made the unconventional decision to bet his online career on two completely irrational foundations: Apple, and blogs.\nIt’s hard to remember now, but in 2002, Apple was just a few years past having been on death’s door. As difficult as it may be to picture in today’s world where Apple keynotes are treated like major events, back then, almost nobody was covering Apple regularly, let alone writing exclusively about the company. There was barely even any \"tech news\" scene online at all, and virtually no one was blogging. So John’s decision to go all-in on Apple for his pioneering blog Daring Fireball was, well, a daring one. At the time, Apple had only just launched its first iPod that worked with Windows computers, and the iPhone was still a full five years in the future. But that single-minded obsessive focus, not just on Apple, but on everything he covered, eventually helped inspire much of the technology media landscape that we see today. John’s timing was also perfect — from the doldrums of that era, Apple’s stock price would rise by about 120,000% in the years after Daring Fireball started, and its cultural relevance probably increased by even more than that.\nBy 2004, it wasn’t just Apple that had begun to take off: blogs and social media themselves had moved from obscurity to the very center of culture, and a new era of web technology had begun. At the beginning of that year, few people in the world even knew what a “blog” was, but by the end of 2004, blogs had become not just ubiquitous, but downright cool. As unlikely as it seems now, that year’s largely uninspiring slate of U.S. presidential candidates like Wesley Clark, Gary Hart and, yes, Howard Dean helped propel blogs into mainstream awareness during the Democratic primaries, alongside online pundits who had begun weighing in on politics and the issues and cultural moments at a pace that newspapers and TV couldn’t keep up with. A lot has been written about the transformation of media during those years, but less has been written about how the media and tech of the time transformed each other.\n\nThat era of early blogging was interesting in that nearly everyone who was writing the first popular sites was also busy helping create the tools for publishing them. Just like Lucille Ball and Desi Arnaz had to pioneer combining studio-style flat lighting with 35mm filming in order to define the look of the modern sitcom, or Jimi Hendrix had to work with Roger Mayer to invent the signature guitar distortion pedals that defined the sound of rock and roll, the pioneers who defined the technical format and structures of blogging were often building the very tools of creation as they went along.\nI got a front row seat to these acts of creation. At the time I was working on Movable Type, which was the most popular tool for publishing “serious” blogs, and helped popularize the medium. Two of my good friends had built the tool and quickly made it into the default choice for anybody who wanted to reach a big audience; it was kind of a combination of everything people do these days on WordPress and all the various email newsletter platforms and all of the “serious” podcasts (since podcasts wouldn’t be invented for another few months). But back in those early days, we’d watch people use our tools to set up Gawker or Huffington Post one day, and Daring Fireball or Waxy.org the next, and each of them would be the first of its kind, both in terms of its design and its voice. To this day, when I see something online that I love by Julianne Escobedo Shepherd or Ta-Nehisi Coates or Nilay Patel or Annalee Newitz or any one of dozens of other brilliant writers or creators, my first thought is often, “hey! They used to type in that app that I used to make!” Because sometimes those writers would inspire us to make a new feature in the publishing tools, and sometimes they would have hacked up a new feature all by themselves in between typing up their new blog posts.\nA really clear, and very simple, early example of how we learned that lesson was when we changed the size of the box that people used to type in just to create the posts on their sites. We made the box a little bit taller, mostly for aesthetic reasons. Within a few weeks, we’d found that posts on sites like Gawker had gotten longer, mostly because the box was bigger. This seems obvious now, years after we saw tweets get longer when Twitter expanded from 140 characters to 280 characters, but at the time this was a terrifying glimpse at how much power a couple of young product managers in a conference room in California would have over the media consumption of the entire world every time they made a seemingly-insignificant decision.\nThe other dirty little secret was, typing in the box in that old blogging app could be… pretty wonky sometimes. People who wanted to do normal things like include an image or link in their blog post, or even just make some text bold, often had to learn somewhat-obscure HTML formatting, memorizing the actual language that’s used to make web pages. Not everybody knew all the details of how to make pages that way, and if they made even one small mistake, sometimes they could break the whole design of their site. It made things feel very fraught every time a writer went to publish something new online, and got in the way of the increasingly-fast pace of sharing ideas now that social media was taking over the public conversation.\nEnter John and his magical text files.\n\nMarking up and marking down\nThe purpose of Markdown is really simple: It lets you use the regular characters on your keyboard which you already use while typing out things like emails, to make fancy formatting of text for the web. The name of that HTML format that's used to make web pages stands for HyperText Markup Language. The word “markup” there means you’re “marking up” your text with all kinds of special characters.\nOnly, the special characters can be kind of arcane. Want to put in a link to everybody’s favorite website? Well, you’re going to have to type in <a href=\"https://anildash.com/\">Anil Dash’s blog</a> I could explain why, and what it all means, but honestly, you get the point — it’s a lot! Too much. What if you could just write out the text and then the link, sort of like you might within an email? Like: [Anil Dash’s blog](https://anildash.com)! And then the right thing would happen. Seems great, right?\nThe same thing works for things like putting a header on a page. For example, as I’m writing this right now, if I want to put a big headline on this page, I can just type # How Markdown Took Over the World and the right thing will happen.\nIf mark_up_ is complicated, then the opposite of that complexity must be… markd_own_. This kind of solution, where it’s so smart it seems obvious in hindsight, is key to Markdown’s success. John worked to make a format that was so simple that anybody could pick it up in a few minutes, and powerful enough that it could help people express pretty much anything that they wanted to include while writing on the internet. At a technical level, it was also easy enough to implement that John could write the code himself to make it work with Movable Type, his publishing tool of choice. (Within days, people had implemented the same feature for most of the other blogging tools of the era; these days, virtually every app that you can type text into ships with Markdown support as a feature on day one.)\nPrior to launch, John had enlisted our mutual friend, the late, dearly missed Aaron Swartz, as a beta tester. In addition to being extremely fluent in every detail of the blogging technologies of the time, Aaron was, most notably, seventeen years old. And though Aaron’s activism and untimely passing have resulted in him having been turned into something of a mythological figure, one of the greatest things about Aaron was that he could be a total pain in the ass, which made him terrific at reporting bugs in your software. (One of the last email conversations I ever had with Aaron was him pointing out some obscure bugs in an open source app I was working on at the time.) No surprise, Aaron instantly understood both the potential and the power of Markdown, and was a top-tier beta tester for the technology as it was created. His astute feedback helped finely hone the final product so it was ready for the world, and when Markdown quietly debuted in March of 2004, it was clear that text files around the web were about to get a permanent upgrade.\nThe most surprising part of what happened next wasn’t that everybody immediately started using it to write their blogs; that was, after all, what the tool was designed to do. It’s that everybody started using Markdown to do everything else, too.\nHitting the Mark\nIt’s almost impossible to overstate the ubiquity of Markdown within the modern computer industry in the decades since its launch.\nAfter being nagged about it by users for more than a decade, Google finally added support for Markdown to Google Docs, though it took them years of fiddly improvements to make it truly usable. Just last year, Microsoft added support for Markdown to its venerable Notepad app, perhaps in an attempt to assuage the tempers of users who were still in disbelief that Notepad had been bloated with AI features. Nearly every powerful group messaging app, from Slack to WhatsApp to Discord, has support for Markdown in messages. And even the company that indirectly inspired all of this in the first place finally got on board: the most recent version of Apple Notes finally added support for Markdown. (It’s an especially striking launch by Apple due to its timing, shortly after John had used his platform as the most influential Apple writer in the world to blog about the utter failure of the “Apple Intelligence” AI launch.)\nBut it’s not just the apps that you use on your phone or your laptop. For developers, Markdown has long been the lingua franca of the tools we string together to accomplish our work. On GitHub, the platform that nearly every developer in the world uses to share their code, nearly every single repository of code on the site has at least one Markdown file that’s used to describe its contents. Many have dozens of files describing all the different aspects of their project. And some of the repositories on GitHub consist of nothing but massive collections of Markdown files. The small tools and automations we run to perform routine tasks, the one-off reports that we generate to make sure something worked correctly, the confirmations that we have a system alert email out when something goes wrong, the temporary files we use when trying to recover some old data — all of these default to being Markdown files.\nAs a result, there are now billions of Markdown files lying around on hard drives around the world. Billions more are stashed in the cloud. There are some on the phone in your pocket. Programmers leave them lying around wherever their code might someday be running. Your kid’s Nintendo Switch has Markdown files on it. If you’re listening to music, there’s probably a Markdown file on the memory chip of the tiny system that controls the headphones stuck in your ears. The Markdown is inside you right now!\nDown For Whatever\nSo far, these were all things we could have foreseen when John first unleashed his little text tool on the world. I would have been surprised about how many people were using it, but not really the ways in which they were using it. If you’d have said “Twenty years in the future, all the different note-taking apps people use save their files using Markdown!”, I would have said, “Okay, that makes sense!”\nWhat I wouldn’t have asked, though, was “Is John getting paid?” As hard as it may be to believe, back in 2004, the default was that people made new standards for open technologies like Markdown, and just shared them freely for the good of the internet, and the world, and then went on about their lives. If it happened to have unleashed billions of dollars of value for others, then so much the better. If they got some credit along the way, that was great, too. But mostly you just did it to solve a problem for yourself and for other like-minded people. And also, maybe, to help make sure that some jerk didn’t otherwise create some horrible proprietary alternative that would lock everybody into their terrible inferior version forever instead. (We didn’t have the word “enshittification” yet, but we did have Cory Doctorow and we did have plain text files, so we kind of knew where things were headed.)\nTo give a sense of the vibe of that era, the term “podcasting” had been coined just a month before Markdown was released, and went into wider use that fall, and was similarly a radically open system that wasn’t owned by any big company and that empowered people to do whatever they wanted to do to express themselves. (And podcasting was another technology that Aaron Swartz helped improve by being a brilliant pain in the ass. But I’ll save that story for another book-length essay.)\nThat attitude of being not-quite-_anti_commercial, but perhaps just not even really concerned with whether something was commercial or not seems downright quaint in an era when the tech tycoons are not just the wealthiest people in the world, but also some of the weirdest and most obnoxious as well. But the truth is, most people today who make technology are actually still exceedingly normal, and quite generous. It’s just that they’ve been overshadowed by their bosses who are out of their minds and building rocket ships and siring hundreds of children and embracing overt white supremacy instead of making fun tools for helping you type text, like regular people do.\n\nThe Markdown Model\nThe part about not doing this stuff solely for money matters, because even the most advanced LLM systems today, what the big AI companies call their “frontier” models, require complex orchestration that’s carefully scripted by people who’ve tuned their prompts for these systems through countless rounds of trial and error. They’ve iterated and tested and watched for the results as these systems hallucinated or failed or ran amok, chewing up countless resources  along the way. And sometimes, they generated genuinely astonishing outputs, things that are truly amazing to consider that modern technology can achieve. The rate of progress and evolution, even factoring in the mind-boggling amounts of investment that are going into these systems, is rivaled only by the initial development of the personal computer or the Internet, or the early space race.\nAnd all of it — all of it — is controlled through Markdown files. When you see the brilliant work shown off from somebody who’s bragging about what they made ChatGPT generate for them, or someone is understandably proud about the code that they got Claude to create, all of the most advanced work has been prompted in Markdown. Though where the logic of Markdown was originally a very simple version of \"use human language to tell the machine what to do\", the implications have gotten far more dire when they use a format designed to help expresss \"make this **bold**\" to tell the computer itself \"make this imaginary girlfriend more compliant\".\nBut we already know that the Big AI companies are run by people who don't reckon with the implications of their work. They could never understand that every single project that's even moderately ambitious on these new AI platforms is being written up in files formatted according to this system created by one guy who has never asked for a dime for this work. An entire generation of AI coders has been born since Markdown was created who probably can’t even imagine that this technology even has an \"inventor\". It’s just always been here, like the Moon, or Rihanna.\nBut it’s important for everyone to know that the Internet, and the tech industry, don’t run without the generosity and genius of regular people. It is not just billion-dollar checks and Silicon Valley boardrooms that enable creativity over years, decades, or generations — it’s often a guy with a day job who just gives a damn about doing something right, sweating the details and assuming that if he cares enough about what he makes then others will too. The majority of the technical infrastructure of the Internet was created in this way. For free, often by people in academia, or as part of their regular work, with no promise of some big payday or getting a ton of credit.\nThe people who make the real Internet and the real innovations also don’t look for ways to hurt the world around them, or the people around them. Sometimes, as in the case of Aaron, the world hurts them more than anyone should ever have to bear. I know not everybody cares that much about plain text files on the Internet; I will readily admit I am a huge nerd about this stuff in a way that most normal people are not. But I do think everybody cares about some part of the wonderful stuff on the Internet in this way, and I want to fight to make sure that everybody can understand that it’s not just five terrible tycoons who built this shit. Real people did. Good people. I saw them do it.\nThe trillion-dollar AI industry's system for controlling their most advanced platforms is a plain text format one guy made up for his blog and then bounced off of a 17-year-old kid before sharing it with the world for free. You're welcome, Time Magazine's people of the year, The Architects of AI. Their achievement is every bit as impressive as yours.\n\nThe Ten Technical Reasons Markdown Won\nOkay, with some of the narrative covered, what can we learn from Markdown’s success? How did this thing really take off? What could we do if we wanted to replicate something like this in the modern era? Let’s consider a few key points:\n1. Had a great brand.\nOkay, let’s be real: “Markdown” as a name is clever as hell. Get it — it's not markup, it's mark down. You just can’t argue with that kind of logic. People who knew what the “M” in “HTML” stood for could understand the reference, and to everyone else, it was just a clearly-understandable name for a useful utility.\n2. Solved a real problem.\nThis one is not obvious, but it’s really important that a new technology have a real problem that it’s trying to solve, instead of just being an abstract attempt to do something vague, like “make text files better”. Millions of people were encountering the idea that it was too difficult or inconvenient to write out full HTML by hand, and even if one had the necessary skills, it was nice to be able to do so in a format that was legible as plain text as well.\n3. Built on behaviors that already existed.\nThis is one of the most quietly genius parts of Markdown: The format is based on the ways people had been adding emphasis and formatting to their text for years or even decades. Some of the formatting choices dated back to the early days of email, so they’d been ingrained in the culture of the internet for a full generation before Markdown existed. It was so familiar, people could be writing Markdown without even knowing it.\n4. Mirrored RSS in its origin.\nAround the same time that Markdown was taking off, RSS was maturing into its ubiquitous form as well. The format had existed for some years already, enabling various kinds of content syndication, but at this time, it was adding support for the technologies that would come to be known as podcasting as well. And just like RSS, Markdown was spearheaded by a smart technologist who was also more than a little stubborn about defining a format that would go on to change the way we share content on the internet. In RSS’ case, it was pioneered by Dave Winer, and with Markdown it was John Gruber, and both were tireless in extolling the virtues of the plain text formats they’d helped pioneer. They could both leverage blogs to get the word out, and to get feedback on how to build on their wins.\n5. There was a community ready to help.\nOne great thing about a format like Markdown is that its success is never just the result of one person. Vitally, Markdown was part of a community that could build on it right from the start. Right from the beginning, Markdown was inspired by earlier works like Textile, a formatting system for plain text created by Dean Allen. Many of us appreciated and were inspired by Dean, who was a pioneer of blogging tools in the early days of social media, but if there’s a bigger fan of Dean Allen on the internet than John Gruber, I’ve never met them. Similarly, Aaron Swartz, the brilliant young technologist who's best known as an activist for digital rights and access, was at that time just a super brilliant teenager that a lot of us loved hacking with. He was the most valuable beta tester of Markdown prior to its release, helping to shape it into a durable and flexible format that’s stood the test of time.\n6. Had the right flavor for every different context.\nBecause Markdown’s format was frozen in place (and had some super-technical details that people could debate about) and people wanted to add features over time, various communities that were implementing Markdown could add their own “flavors” of it as they needed. Popular ones came to be called Commonmark and Github-Flavored, led by various companies or teams that had divergent needs for the tool. While tech geeks tend to obsess over needing everything to be “correct”, in reality it often just doesn’t matter that much, and in the real world, the entire Internet is made up of content that barely follows the technical rules that it’s supposed to.\n7. Released during a time of change in behaviors and habits.\nThis is a subtle point, but an important one: Markdown came along at the right time in the evolution of its medium. You can get people to change their behaviors when they’re using a new tool, or adopting a new technology. In this case, blogging (and all of social media!) were new, so saying “here’s a new way of typing a list of bullet points” wasn't much of an additional learning curve to add to the mix. If you can take advantage of catching people while they’re already in a learning mood, you can really tap into the moment when they’re most open-minded to new things.\n8. Came right on the cusp of the “build tool era”.\nThis one’s a bit more technical, but also important to understand. In the first era of building for the web, people often built the web's languages of HTML, JavaScript and CSS by hand, by themselves, or stitched these formats together from subsets or templates. But in many cases, these were fairly simple compositions, made up of smaller pieces that were written in the same languages. As things matured, the roles for web developers specialized (there started to be backend developers vs. front-end, or people who focused on performance vs. those who focused on visual design), and as a result the tooling for developers matured. On the other side of this transition, developers began to use many different programming languages, frameworks and tools, and the standard step before trying to deploy a website was to have an automated build process that transformed the “raw materials” of the site into the finished product. Since Markdown is a raw material that has to be transformed into HTML, it perfectly fit this new workflow as it became the de facto standard method of creation and collaboration.\n9. Worked with “View source”\nMost of the technologies that work best on the web enable creators to “view source” just like HTML originally did when the first web browsers were created. In this philosophy, you can look at the source code that makes up a web page, and understand how it was constructed so that you can make your own. With Markdown, it only takes one glimpse of a source Markdown file for anyone to understand how they might make a similar file of their own, or to extrapolate how they might apply analogous formatting to their own documents. There’s no teaching required when people can just see it for themselves.\n10. Not encumbered in IP\nThis one’s obvious if you think about it, but it can’t go unsaid: There are no legal restrictions around Markdown. You wouldn’t think that anybody would be foolish or greedy enough to try to patent something as simple as Markdown, but there are many far worse examples of patent abuse in the tech industry. Fortunately, John Gruber is not an awful person, and nobody else has (yet) been brazen enough to try to usurp the format for their own misadventures in intellectual property law. As a result, nobody’s been afraid, either to use the format, or to support creating or reading the format in their apps."
    },
    {
      "title": "anildash.com: How to know if that job will crush your soul",
      "url": "https://anildash.com/2026/01/12/will-that-job-crush-your-soul/",
      "source": "anildash.com",
      "time": "2026-02-23T12:43:21.700404",
      "raw_desc": "Last week, we talked about one huge question, “How the hell are you supposed to have a career in tech in 2026?” That’s pretty specific to this current moment, but there are some timeless, more perennial questions I've been sharing with friends for years that I wanted to give to all of you. They're a short list of questions that help you judge whether a job that you’re considering is going to crush your soul or not.\nObviously, not everyone is going to get to work in an environment that has perfect answers to all of these questions; a lot of the time, we’re lucky just to get a place to work at all. But these questions are framed in this way to encourage us all to aspire towards roles that enable us to do our best work, to have the biggest impact, and to live according to our values.\nThe Seven Questions\n\nIf what you do succeeds, will the world be better?\n\nThis question originally started for me when I would talk to people about new startups, where people were judging the basic idea of the product or the company itself, but it actually applies to any institution, at any size. If the organization that you’re considering working for, or the team you’re considering joining, is able to achieve their stated goals, is it ultimately going to have a positive effect? Will you be proud of what it means? Will the people you love and care about respect you for making that choice, and will those with the least to gain feel like you’re the kind of person who cares about their impact on the world?\n\nWhose money do they have to take to stay in business?\n\nWhere does the money in the organization really come from? You need to know this for a lot of reasons. First of all, you need to be sure that they know the answer. (You’d be surprised how often that’s not the case!) Even if they do know the answer, it may make you realize that those customers are not the people whose needs or wants you’d like to spend most of your waking hours catering to. This goes beyond the simple basics of the business model — it can be about whether they're profitable or not, and what the corporate ownership structure is like.\nIt’s also increasingly common for companies to mistake those who are investing in a company with those who are their customers. But there’s a world of difference between those who are paying you, and those who you have to pay back tenfold. Or thousandfold.\nThe same goes for nonprofits — do you know who has to stay happy and smiling in order for the institution to stay stable and successful? If you know those answers, you'll be far more confident about the motivations and incentives that will drive key decisions within the organization.\n\nWhat do you have to believe to think that they’re going to succeed? In what way does the world have to change or not change?\n\nNow we’re getting a little bit deeper into thinking about the systems that surround the organization that you’re evaluating. Every company, every institution, even every small team, is built around a set of invisible assumptions. Many times, they’re completely reasonable assumptions that are unlikely to change in the future. But sometimes, the world you’re working in is about to shift in a big way, or things are built on a foundation that’s speculative or even unrealistic.\nMaybe they're assuming there aren't going to be any big new competitors. Perhaps they think they'll always remain the most popular product in their category. Or their assumptions could be about the stability of the rule of law, or a lack of corruption — more fundamental assumptions that they've never seen challenged in their lifetime or in their culture, but that turn out to be far more fragile than they'd imagined.\nThinking through the context that everyone is sharing, and reflecting on whether they’re really planning for any potential disruptions, is an essential part of judging the psychological health of an organization. It’s the equivalent of a person having self-awareness, and it’s just as much of a red flag if it’s missing.\n\nWhat’s the lived experience of the workers there whom you trust? Do you have evidence of leaders in the organization making hard choices to do the right thing?\n\nHere is how we can tell the culture and character of an organization. If you’ve got connections into the company, or a backchannel to workers there, finding out as much information as you can about the real story of its working conditions is often one of the best ways of understanding whether it’s a fit for your needs. Now, people can always have a bad day, but overall, workers are usually very good at providing helpful perspectives about their context.\nAnd more broadly, if people can provide examples of those in power within an organization using that power to take care of their workers or customers, or to fight for the company to be more responsible, then you’ve got an extremely positive sign about the health of the place even before you’ve joined. It’s vital that these be stories you are able to find and discover on your own, not the ones amplified by the institution itself for PR purposes.\n\nWhat were you wrong about?\n\nAnd here we have perhaps one of the easiest and most obvious ways to judge the culture of an organization. This is even a question you can ask people while you’re in an interview process, and you can judge their responses to help form your opinion. A company, and leadership culture, that can change its mind when faced with new information and new circumstances is much more likely to adapt to challenges in a healthy way. (If you want to be nice, phrase it as \"What is a way in which the company has evolved or changed?\")\n\nDoes your actual compensation take care of what you need for all of your current goals and needs — from day one?\n\nThis is where we go from the abstract and psychological goals to the practical and everyday concerns: can you pay your bills? The phrasing and framing here is very intentional: are they really going to pay you enough? I ask this question very specifically because you’d be surprised how often companies actually dance around this question, or how often we trick ourselves into hearing what we want to hear as the answer to this question when we’re in the exciting (or stressful) process of considering a new job, instead of looking at the facts of what’s actually written in black-and-white on an offer letter.\nIt's also important not to get distracted with potential, even if you're optimistic about the future. Don’t listen to promises about what might happen, or descriptions of what’s possible if you advance in your role. Think about what your real life will be like, after taxes, if you take the job that they’ve described.\n\nIs the role you’re being hired into one where you can credibly advance, and where there’s sufficient resources for success?\n\nThis is where you can apply your optimism in a practical way: can the organization accurately describe how your career will proceed within the company? Does it have a specific and defined trajectory, or does it involve ambiguous processes or changes in teams or departments? Would you have to lobby for the support of leaders from other parts of the organization? Would making progress require acquiring new skills or knowledge? Have they committed to providing you with the investment and resources required to learn those skills?\nThese questions are essential to understand, because lacking these answers can lead to an ugly later realization that even an initially-exciting position may turn out to be a dead-end job over time.\nTowards better working worlds\nSometimes it can really feel like the deck is stacked against you when you're trying to find a new job. It can feel even worse to be faced with an opportunity and have a nagging sense that something is not quite right. Much of the time, that feeling comes from the vague worry that we're taking a job that is going to make us miserable.\nEven in a tough job market, there are some places that are trying to do their best to treat people decently. In larger organizations, there are often pockets of relative sanity, led by good leaders, who are trying to do the right thing. It can be a massive improvement in quality of life if you can find these places and use them as foundations for the next stage of your career.\nThe best way to navigate towards these better opportunities is to be systematic when evaluating all of your options, and to hold out for as high standards as possible when you're out there looking. These seven questions give you the tools to do exactly that."
    },
    {
      "title": "mjg59.dreamwidth.org: Not here",
      "url": "https://mjg59.dreamwidth.org/74084.html",
      "source": "mjg59.dreamwidth.org",
      "time": "2026-02-23T12:43:22.059836",
      "raw_desc": ""
    },
    {
      "title": "mjg59.dreamwidth.org: How did IRC ping timeouts end up in a lawsuit?",
      "url": "https://mjg59.dreamwidth.org/73777.html",
      "source": "mjg59.dreamwidth.org",
      "time": "2026-02-23T12:43:22.059836",
      "raw_desc": ""
    },
    {
      "title": "mjg59.dreamwidth.org: Where are we on X Chat security?",
      "url": "https://mjg59.dreamwidth.org/73625.html",
      "source": "mjg59.dreamwidth.org",
      "time": "2026-02-23T12:43:22.059836",
      "raw_desc": ""
    },
    {
      "title": "keygen.sh: How I replaced Baremetrics and ChartMogul with Rake",
      "url": "https://keygen.sh/blog/how-i-replaced-baremetrics-and-chartmogul-with-rake/",
      "source": "keygen.sh",
      "time": "2026-02-23T12:43:22.133692",
      "raw_desc": ""
    },
    {
      "title": "keygen.sh: How to Implement API Key Authentication in Rails Without Devise",
      "url": "https://keygen.sh/blog/how-to-implement-api-key-authentication-in-rails-without-devise/",
      "source": "keygen.sh",
      "time": "2026-02-23T12:43:22.133692",
      "raw_desc": ""
    },
    {
      "title": "keygen.sh: How to Generate Secure License Keys in 2026",
      "url": "https://keygen.sh/blog/how-to-generate-license-keys/",
      "source": "keygen.sh",
      "time": "2026-02-23T12:43:22.133692",
      "raw_desc": ""
    },
    {
      "title": "computer.rip: forecourt networking",
      "url": "https://computer.rip/2026-02-08-forecourt-networking.html",
      "source": "computer.rip",
      "time": "2026-02-23T12:43:22.287754",
      "raw_desc": ""
    },
    {
      "title": "computer.rip: the essence of frigidity",
      "url": "https://computer.rip/2026-01-25-the-essence-of-frigidity.html",
      "source": "computer.rip",
      "time": "2026-02-23T12:43:22.287754",
      "raw_desc": ""
    },
    {
      "title": "computer.rip: air traffic control: the IBM 9020",
      "url": "https://computer.rip/2026-01-17-air-traffic-control-9020.html",
      "source": "computer.rip",
      "time": "2026-02-23T12:43:22.287754",
      "raw_desc": ""
    },
    {
      "title": "Freemediaheckyeah",
      "url": "https://fmhy.net/",
      "source": "Hacker News",
      "time": "2026-02-23T11:35:31",
      "raw_desc": ""
    },
    {
      "title": "I built Timeframe, our family e-paper dashboard",
      "url": "https://hawksley.org/2026/02/17/timeframe.html",
      "source": "Hacker News",
      "time": "2026-02-23T03:12:31",
      "raw_desc": ""
    },
    {
      "title": "The JavaScript Oxidation Compiler",
      "url": "https://oxc.rs/",
      "source": "Hacker News",
      "time": "2026-02-23T10:49:16",
      "raw_desc": ""
    },
    {
      "title": "Loops is a federated, open-source TikTok",
      "url": "https://joinloops.org/",
      "source": "Hacker News",
      "time": "2026-02-23T02:56:40",
      "raw_desc": ""
    },
    {
      "title": "How to train your program verifier",
      "url": "https://risemsr.github.io/blog/2026-02-16-halleyyoung-a3/",
      "source": "Hacker News",
      "time": "2026-02-19T05:10:09",
      "raw_desc": ""
    },
    {
      "title": "Show HN: CIA World Factbook Archive (1990–2025), searchable and exportable",
      "url": "https://cia-factbook-archive.fly.dev/",
      "source": "Hacker News",
      "time": "2026-02-23T04:50:23",
      "raw_desc": ""
    },
    {
      "title": "Google restricting Google AI Pro/Ultra subscribers for using OpenClaw",
      "url": "https://discuss.ai.google.dev/t/account-restricted-without-warning-google-ai-ultra-oauth-via-openclaw/122778",
      "source": "Hacker News",
      "time": "2026-02-23T07:07:55",
      "raw_desc": ""
    },
    {
      "title": "Aqua: A CLI message tool for AI agents",
      "url": "https://github.com/quailyquaily/aqua",
      "source": "Hacker News",
      "time": "2026-02-23T10:07:27",
      "raw_desc": ""
    },
    {
      "title": "My journey to the microwave alternate timeline",
      "url": "https://www.lesswrong.com/posts/8m6AM5qtPMjgTkEeD/my-journey-to-the-microwave-alternate-timeline",
      "source": "Hacker News",
      "time": "2026-02-19T05:59:06",
      "raw_desc": ""
    },
    {
      "title": "Six Math Essentials",
      "url": "https://terrytao.wordpress.com/2026/02/16/six-math-essentials/",
      "source": "Hacker News",
      "time": "2026-02-23T03:21:21",
      "raw_desc": ""
    },
    {
      "title": "michael.stapelberg.ch: Coding Agent VMs on NixOS with microvm.nix",
      "url": "https://michael.stapelberg.ch/posts/2026-02-01-coding-agent-microvm-nix/",
      "source": "michael.stapelberg.ch",
      "time": "2026-02-23T12:43:23.115494",
      "raw_desc": "I have come to appreciate coding\nagents to be\nvaluable tools for working with computer program code in any capacity, such as\nlearning about any program’s architecture, diagnosing bugs or developing proofs\nof concept. Depending on the use-case, reviewing each command the agent wants to\nrun can get tedious and time-consuming very quickly. To safely run a coding\nagent without review, I wanted a Virtual Machine (VM) solution where the agent\nhas no access to my personal files and where it’s no big deal if the agent gets\ncompromised by malware: I can just throw away the VM and start over.\nInstead of setting up a stateful VM and re-installing it when needed (ugh!), I\nprefer the model of ephemeral VMs where nothing persists on disk, except for\nwhat is explicitly shared with the host.\nThe microvm.nix project makes it\neasy to create such VMs on NixOS, and this article shows you how I like to set\nup my VMs.\nSee also\nIf you haven’t heard of NixOS before, check out the NixOS Wikipedia\npage and\nnixos.org. I spoke about why I switched to Nix in\n2025 and have published a few blog posts about\nNix.\nFor understanding the threat model of AI agents, read Simon Willison’s “The\nlethal trifecta for AI agents: private data, untrusted content, and external\ncommunication” (June\n2025). This\narticle’s approach to working with the threat model is to remove the “private\ndata” part from the equation.\nIf you want to learn about the whole field of sandboxing, check out Luis\nCardoso’s “A field guide to sandboxes for AI” (Jan\n2026). I will not be\ncomparing different solutions in this article, I will just show you one possible\npath.\nAnd lastly, maybe you’re not in the mood to build/run sandboxing infrastructure\nyourself. Good news: Sandboxing is a hot topic and there are many commercial\nofferings popping up that address this need. For example, David Crawshaw and\nJosh Bleecher Snyder (I know both from the Go community) recently launched\nexe.dev, an agent-friendly VM hosting\nservice. Another example is Fly.io, who launched\nSprites.\nSetting up microvm.nix\nLet’s jump right in! The next sections walk you through how I set up my config.\nStep 1: network prep\nFirst, I created a new microbr bridge which uses 192.168.33.1/24 as IP address range and NATs out of the eno1 network interface. All microvm* interfaces will be added to that bridge:\nsystemd.network.netdevs.\"20-microbr\".netdevConfig = {\n  Kind = \"bridge\";\n  Name = \"microbr\";\n};\n\nsystemd.network.networks.\"20-microbr\" = {\n  matchConfig.Name = \"microbr\";\n  addresses = [ { Address = \"192.168.83.1/24\"; } ];\n  networkConfig = {\n    ConfigureWithoutCarrier = true;\n  };\n};\n\nsystemd.network.networks.\"21-microvm-tap\" = {\n  matchConfig.Name = \"microvm*\";\n  networkConfig.Bridge = \"microbr\";\n};\n\nnetworking.nat = {\n  enable = true;\n  internalInterfaces = [ \"microbr\" ];\n  externalInterface = \"eno1\";\n};\nStep 2: flake.nix\nThen, I added the microvm module as a new input to my flake.nix (check out\nthe microvm.nix documentation for\ndetails) and enabled the microvm.nixosModules.host module on the NixOS\nconfiguration for my PC (midna). I also created a new microvm.nix file, in\nwhich I declare all my VMs. Here’s what my flake.nix looks like:\n{\n  inputs = {\n    nixpkgs = {\n      url = \"github:nixos/nixpkgs/nixos-25.11\";\n    };\n    # For more recent claude-code\n    nixpkgs-unstable = {\n      url = \"github:nixos/nixpkgs/nixos-unstable\";\n    };\n    stapelbergnix = {\n      url = \"github:stapelberg/nix\";\n      inputs.nixpkgs.follows = \"nixpkgs\";\n    };\n    zkjnastools = {\n      url = \"github:stapelberg/zkj-nas-tools\";\n      inputs.nixpkgs.follows = \"nixpkgs\";\n    };\n    microvm = {\n      url = \"github:microvm-nix/microvm.nix\";\n      inputs.nixpkgs.follows = \"nixpkgs\";\n    };\n    home-manager = {\n      url = \"github:nix-community/home-manager/release-25.11\";\n      inputs.nixpkgs.follows = \"nixpkgs\";\n    };\n    configfiles = {\n      url = \"github:stapelberg/configfiles\";\n      flake = false; # repo is not a flake\n    };\n  };\n\n  outputs =\n    {\n      self,\n      stapelbergnix,\n      zkjnastools,\n      nixpkgs,\n      nixpkgs-unstable,\n      microvm,\n      home-manager,\n      configfiles,\n    }@inputs:\n    let\n      system = \"x86_64-linux\";\n      pkgs = import nixpkgs {\n        inherit system;\n        config.allowUnfree = false;\n      };\n      pkgs-unstable = import nixpkgs-unstable {\n        inherit system;\n        config.allowUnfree = true;\n      };\n    in\n    {\n      nixosConfigurations = {\n        midna = nixpkgs.lib.nixosSystem {\n          system = \"x86_64-linux\";\n          specialArgs = { inherit inputs; };\n          modules = [\n            (import ./configuration.nix)\n            stapelbergnix.lib.userSettings\n            # Use systemd for network configuration\n            stapelbergnix.lib.systemdNetwork\n            # Use systemd-boot as bootloader\n            stapelbergnix.lib.systemdBoot\n            # Run prometheus node exporter in tailnet\n            stapelbergnix.lib.prometheusNode\n            zkjnastools.nixosModules.zkjbackup\n            microvm.nixosModules.host\n            ./microvm.nix\n          ];\n        };\n      };\n    };\n}\nStep 3: microvm.nix\nThe following microvm.nix declares two microvms, one for Emacs (about which I wanted to learn more) and one for Go Protobuf, a code base I am familiar with and can use to understand Claude’s capabilities:\n{\n  config,\n  lib,\n  pkgs,\n  inputs,\n  ...\n}:\n\nlet\n  inherit (inputs)\n    nixpkgs-unstable\n    stapelbergnix\n    microvm\n    configfiles\n    home-manager\n    ;\n\n  microvmBase = import ./microvm-base.nix;\nin\n{\n  microvm.vms.emacsvm = {\n    autostart = false;\n    config = {\n      imports = [\n        stapelbergnix.lib.userSettings\n        microvm.nixosModules.microvm\n        (microvmBase {\n          hostName = \"emacsvm\";\n          ipAddress = \"192.168.83.6\";\n          tapId = \"microvm4\";\n          mac = \"02:00:00:00:00:05\";\n          workspace = \"/home/michael/microvm/emacs\";\n          inherit\n            nixpkgs-unstable\n            configfiles\n            home-manager\n            stapelbergnix\n            ;\n        })\n        ./microvms/emacs.nix\n      ];\n    };\n  };\n\n  microvm.vms.goprotobufvm = {\n    autostart = false;\n    config = {\n      imports = [\n        stapelbergnix.lib.userSettings\n        microvm.nixosModules.microvm\n        (microvmBase {\n          hostName = \"goprotobufvm\";\n          ipAddress = \"192.168.83.7\";\n          tapId = \"microvm5\";\n          mac = \"02:00:00:00:00:06\";\n          workspace = \"/home/michael/microvm/goprotobuf\";\n          inherit\n            nixpkgs-unstable\n            configfiles\n            home-manager\n            stapelbergnix\n            ;\n          extraZshInit = ''\n            export GOPATH=$HOME/go\n            export PATH=$GOPATH/bin:$PATH\n          '';\n        })\n        ./microvms/goprotobuf.nix\n      ];\n    };\n  };\n}\nStep 4: microvm-base.nix\nThe microvm-base.nix module takes these parameters and declares:\n\nNetwork settings: I like using systemd-networkd(8)\n and systemd-resolved(8)\n.\nShared directories for:\n\nthe workspace directory, e.g. ~/microvm/emacs\nthe host’s Nix store, so the VM can access software from cache (often)\nthis VM’s SSH host keys\n~/claude-microvm, which is a separate state directory, used only on the microvms.\n\n\nan 8 GB disk overlay (var.img), stored in /var/lib/microvms/<name>\ncloud-hypervisor (QEMU also works well!) as the hypervisor, with 8 vCPUs and 4 GB RAM.\nA workaround for systemd trying to unmount /nix/store (which causes a deadlock).\n\n\nExpand full microvm-base.nix code\n{\n  hostName,\n  ipAddress,\n  tapId,\n  mac,\n  workspace,\n  nixpkgs-unstable,\n  configfiles,\n  home-manager,\n  stapelbergnix,\n  extraZshInit ? \"\",\n}:\n\n{\n  config,\n  lib,\n  pkgs,\n  ...\n}:\n\nlet\n  system = pkgs.stdenv.hostPlatform.system;\n  pkgsUnstable = import nixpkgs-unstable {\n    inherit system;\n    config.allowUnfree = true;\n  };\nin\n{\n  imports = [ home-manager.nixosModules.home-manager ];\n\n  # home-manager configuration\n  home-manager.useGlobalPkgs = true;\n  home-manager.useUserPackages = true;\n  home-manager.extraSpecialArgs = { inherit configfiles stapelbergnix; };\n  home-manager.users.michael = {\n    imports = [ ./microvm-home.nix ];\n    microvm.extraZshInit = extraZshInit;\n  };\n\n  # Claude Code CLI (from nixpkgs-unstable, unfree)\n  environment.systemPackages = [\n    pkgsUnstable.claude-code\n  ];\n  networking.hostName = hostName;\n\n  system.stateVersion = \"25.11\";\n\n  services.openssh.enable = true;\n\n  # To match midna (host)\n  users.groups.michael = {\n    gid = 1000;\n  };\n  users.users.michael = {\n    group = \"michael\";\n  };\n\n  services.resolved.enable = true;\n  networking.useDHCP = false;\n  networking.useNetworkd = true;\n  networking.tempAddresses = \"disabled\";\n  systemd.network.enable = true;\n  systemd.network.networks.\"10-e\" = {\n    matchConfig.Name = \"e*\";\n    addresses = [ { Address = \"${ipAddress}/24\"; } ];\n    routes = [ { Gateway = \"192.168.83.1\"; } ];\n  };\n  networking.nameservers = [\n    \"8.8.8.8\"\n    \"1.1.1.1\"\n  ];\n\n  # Disable firewall for faster boot and less hassle;\n  # we are behind a layer of NAT anyway.\n  networking.firewall.enable = false;\n\n  systemd.settings.Manager = {\n    # fast shutdowns/reboots! https://mas.to/@zekjur/113109742103219075\n    DefaultTimeoutStopSec = \"5s\";\n  };\n\n  # Fix for microvm shutdown hang (issue #170):\n  # Without this, systemd tries to unmount /nix/store during shutdown,\n  # but umount lives in /nix/store, causing a deadlock.\n  systemd.mounts = [\n    {\n      what = \"store\";\n      where = \"/nix/store\";\n      overrideStrategy = \"asDropin\";\n      unitConfig.DefaultDependencies = false;\n    }\n  ];\n\n  # Use SSH host keys mounted from outside the VM (remain identical).\n  services.openssh.hostKeys = [\n    {\n      path = \"/etc/ssh/host-keys/ssh_host_ed25519_key\";\n      type = \"ed25519\";\n    }\n  ];\n\n  microvm = {\n    # Enable writable nix store overlay so nix-daemon works.\n    # This is required for home-manager activation.\n    # Uses tmpfs by default (ephemeral), which is fine since we\n    # don't build anything in the VM.\n    writableStoreOverlay = \"/nix/.rw-store\";\n\n    volumes = [\n      {\n        mountPoint = \"/var\";\n        image = \"var.img\";\n        size = 8192; # MB\n      }\n    ];\n\n    shares = [\n      {\n        # use proto = \"virtiofs\" for MicroVMs that are started by systemd\n        proto = \"virtiofs\";\n        tag = \"ro-store\";\n        # a host's /nix/store will be picked up so that no\n        # squashfs/erofs will be built for it.\n        source = \"/nix/store\";\n        mountPoint = \"/nix/.ro-store\";\n      }\n      {\n        proto = \"virtiofs\";\n        tag = \"ssh-keys\";\n        source = \"${workspace}/ssh-host-keys\";\n        mountPoint = \"/etc/ssh/host-keys\";\n      }\n      {\n        proto = \"virtiofs\";\n        tag = \"claude-credentials\";\n        source = \"/home/michael/claude-microvm\";\n        mountPoint = \"/home/michael/claude-microvm\";\n      }\n      {\n        proto = \"virtiofs\";\n        tag = \"workspace\";\n        source = workspace;\n        mountPoint = workspace;\n      }\n    ];\n\n    interfaces = [\n      {\n        type = \"tap\";\n        id = tapId;\n        mac = mac;\n      }\n    ];\n\n    hypervisor = \"cloud-hypervisor\";\n    vcpu = 8;\n    mem = 4096;\n    socket = \"control.socket\";\n  };\n}\n\nStep 5: microvm-home.nix\nmicrovm-base.nix in turn pulls in microvm-home.nix, which sets up home-manager to:\n\nSet up Zsh with my configuration\nSet up Emacs with my configuration\nSet up Claude Code in shared directory ~/claude-microvm.\n\n\nExpand full microvm-home.nix code\n{\n  config,\n  pkgs,\n  lib,\n  configfiles,\n  stapelbergnix,\n  ...\n}:\n\n{\n  options.microvm = {\n    extraZshInit = lib.mkOption {\n      type = lib.types.lines;\n      default = \"\";\n      description = \"Extra lines to add to zsh initContent\";\n    };\n  };\n\n  config = {\n    home.username = \"michael\";\n    home.homeDirectory = \"/home/michael\";\n\n    programs.zsh = {\n      enable = true;\n      history = {\n        size = 4000;\n        save = 10000000;\n        ignoreDups = true;\n        share = false;\n        append = true;\n      };\n\n      initContent = ''\n        ${builtins.readFile \"${configfiles}/zshrc\"}\n        export CLAUDE_CONFIG_DIR=/home/michael/claude-microvm\n        ${config.microvm.extraZshInit}\n      '';\n    };\n\n    programs.emacs = {\n      enable = true;\n      package = stapelbergnix.lib.emacsWithPackages { inherit pkgs; };\n    };\n\n    home.file.\".config/emacs\" = {\n      source = \"${configfiles}/config/emacs\";\n    };\n\n    home.stateVersion = \"25.11\";\n\n    programs.home-manager.enable = true;\n  };\n}\n\nStep 6: goprotobuf.nix\nThe goprotobuf.nix makes available a bunch of required and convenient packages:\n# Project-specific configuration for goprotobufvm\n{ pkgs, ... }:\n{\n  # Development environment for Go Protobuf\n  environment.systemPackages = with pkgs; [\n    # Go toolchain\n    go\n    gopls\n    delve\n    protobuf\n    gnumake\n    gcc\n    git\n    ripgrep\n  ];\n}\nRunning the VM\nLet’s create the workspace directory and create an SSH host key:\nmkdir -p ~/microvm/emacs/ssh-host-keys\nssh-keygen -t ed25519 -N \"\" \\\n  -f ~/microvm/emacs/ssh-host-keys/ssh_host_ed25519_key\nNow we can start the VM:\nsudo systemctl start microvm@emacsvm\nIt boots and responds to pings within a few seconds.\nThen, SSH into the VM (perhaps in a tmux(1)\n session) and run Claude\n(or your Coding Agent of choice) without permission prompts in the shared\nworkspace directory:\n% ssh 192.168.83.2\nemacsvm% cd microvm/emacs\nemacsvm% claude --dangerously-skip-permissions\nThis is what running Claude in such a setup looks like:\n\nCreating VMs with Claude\nAfter going through the process of setting up a MicroVM once, it becomes tedious.\nI was curious if Claude Skills could\nhelp with a task like this. Skills are markdown files that instruct Claude to do\ncertain steps in certain situations.\nI created .claude/skills/create-microvm/SKILL.md as follows:\n---\nname: create-microvm\ndescription: Creates a new microvm Virtual Machine on midna for running Claude in, with source code repositories and build dependencies available inside the microvm. Use when the user asks to create a new microvm.\n---\n\nInspect the existing structure at ~/machines/midna (NixOS configuration using Flakes), which includes several MicroVMs in the ~/machines/midna/microvms/ directory.\n\nThen, create a similar structure for the microvm the user asked to create. Be sure to consider:\n\n1. Create a new subdirectory for this microvm, named NAME (the microvm name).\n2. Create an entry in microvm.nix similar to an existing microvm's, but:\n3. Change hostname to NAME\n4. Change IP address (e.g., 192.168.83.3): find used ones and chose next free\n5. Change workspace share to /home/michael/microvm/NAME\n6. Include build dependencies for the new microvm based on user request\n7. Create ssh-host-keys directory\n8. Generate SSH host keys\n9. Clone/download source code repositories into this microvm based on user request\n\nOnce the microvm is defined, update ~/machines/midna to pull it in. To verify, build the config (but do not deploy).\n\nYou need to git-commit changes to the microvm before ~/machines/midna can see them.\nWhen using this skill with Claude Code (tested version: v2.0.76 and v2.1.15), with the Opus 4.5 model, I can send a prompt like this:\n\nplease set up a microvm for Debian Code Search (dcs). see ~/dcs for the source code (but clone from https://github.com/Debian/dcs)\n\nNow Claude churns for a few minutes, possibly asking a clarification question\nbefore that. Afterwards, Claude reports back with:\n\nThe dcsvm microvm has been set up successfully. Here’s what was created:\nConfiguration:\n\n/home/michael/machines/midna/microvms/dcs.nix - Project-specific packages (Go toolchain, protobuf tools, uglify-js, yuicompressor,\nzopfli)\nUpdated /home/michael/machines/midna/microvm.nix to include dcsvm with:\n\nIP: 192.168.83.8\ntapId: microvm6\nmac: 02:00:00:00:00:07\n\n\n\nWorkspace:\n\n/home/michael/microvm/dcs/ - Workspace directory\n/home/michael/microvm/dcs/ssh-host-keys/ - SSH host keys (ed25519)\n/home/michael/microvm/dcs/dcs/ - Cloned repository from https://github.com/Debian/dcs\n\nBuild verified - The configuration builds successfully.\nTo start the microvm after deploying:\nsystemctl start microvm@dcsvm\nTo SSH into it:\nssh michael@192.168.83.8\n\nWonderful! In my experience, Claude always got the VM creation correct.\nReplicating this setup with Claude Code\nIn fact, you can go one step further: Instead of just asking Claude to create\nnew MicroVMs, you can also ask Claude to replicate this entire setup into your\nNixOS configuration!\nTry a prompt like this:\n\nread\nhttps://michael.stapelberg.ch/posts/2026-02-01-coding-agent-microvm-nix/\n— I want the exact same setup in my midna NixOS configuration please!\n\nConclusion\nNixOS has a reputation of being hard to adopt, but once you are using NixOS, you\ncan do powerful things like spinning up ephemeral MicroVMs for a new project\nwithin minutes.\nThe maintenance effort is minimal: When I update my personal PC, my MicroVM\nconfigurations start using the new software versions, too. Customization is easy\nif needed.\nThis actually mirrors my experience with Coding Agents: I don’t feel like\nthey’re automatically making existing tasks more efficient, I feel that they\nmake things possible that were previously out of reach (similar to Jevons\nparadox).\nIt was fascinating (and scary!) to experience the quality increase of Coding\nAgents during 2025. At the beginning of 2025 I thought that LLMs are an\noverhyped toy, and felt it was almost insulting when people showed me text or\ncode produced by these models. But almost every new frontier model release got\nsignificantly better, and by now I have been positively surprised by Claude\nCode’s capabilities and quality many times. It has produced code that handles\nlegitimate edge cases I would not have considered.\nWith this article, I showed one possible way to run Coding Agents safely (or any\nworkload that shouldn’t access your private data, really) that you can adjust in\nmany ways for your needs."
    },
    {
      "title": "michael.stapelberg.ch: Can I finally start using Wayland in 2026?",
      "url": "https://michael.stapelberg.ch/posts/2026-01-04-wayland-sway-in-2026/",
      "source": "michael.stapelberg.ch",
      "time": "2026-02-23T12:43:23.145170",
      "raw_desc": "Wayland is the successor to the X server (X11, Xorg) to implement the graphics\nstack on Linux. The Wayland\nproject was actually started in 2008, a year before I created the i3 tiling\nwindow manager for X11 in 2009 — but for the last 18 years\n(!), Wayland was never usable on my computers. I don’t want to be stuck on\ndeprecated software, so I try to start using Wayland each year, and this\narticles outlines what keeps me from migrating to Wayland in 2026.\nHistorical context\nFor the first few years, Wayland rarely even started on my machines. When I was\nlucky enough for something to show up, I could start some toy demo apps in the\ndemo compositor Weston.\nAround 2014, GNOME started supporting Wayland. KDE followed a few years later.\nMajor applications (like Firefox, Chrome or Emacs) have been slower to adopt\nWayland and needed users to opt into experimental implementations via custom\nflags or environment variables, until very recently, or — in some cases, like\ngeeqie — still as of today.\nUnfortunately, the driver support situation remained poor for many years.  With\nnVidia graphics cards, which are the only cards that support my 8K\nmonitor, Wayland would either not work at all\nor exhibit heavy graphics glitches and crashes.\nIn the 2020s, more and more distributions announced looking to switch to Wayland\nby default or even drop their X11\nsessions, and RHEL\nis winding down their contributions to the X\nserver.\nModern Linux distributions like Asahi Linux (for\nMacs, with their own GPU driver!) clearly consider Wayland their primary desktop\nstack, and only support X11 on a best-effort basis.\nSo the pressure to switch to Wayland is mounting! Is it ready now? What’s\nmissing?\nMaking Wayland start\nHardware\nI’m testing with my lab PC, which is a slightly upgraded version of my 2022\nhigh-end Linux PC.\nI describe my setup in more details in stapelberg uses this: my 2020 desk\nsetup.\nMost importantly for this article, I use a Dell 8K 32\"\nmonitor (resolution: 7680x4320!), which, in my\nexperience, is only compatible with nVidia graphics cards (I try other cards\nsometimes).\nHence, both the lab PC and my main PC contain an nVidia GPU:\n\nThe lab PC contains a nVidia GeForce RTX 4070 Ti.\nThe main PC contains a nVidia GeForce RTX 3060 Ti.\n\n(In case you’re wondering why I use the older card in my PC: I had a crash once\nwhere I suspected the GPU, so I switched back from the 4070 to my older 3060.)\nnVidia driver support\nFor many years, nVidia drivers were entirely unsupported under Wayland.\nApparently, nVidia refused to support the API that Wayland was using, insisting\nthat their EGLStreams approach was superior. Luckily, with nVidia driver 495\n(late 2021), they added support for GBM (Generic Buffer Manager).\nBut, even with GBM support, while you could now start many Wayland sessions, the\nsession wouldn’t run smoothly: You would see severe graphics glitches and\nartifacts, preventing you from getting any work done.\nThe solution for the glitches was explicit sync support: because the nVidia\ndriver does not support implicit sync (like AMD or Intel), Wayland (and\nwlroots, and sway) needed to get explicit sync\nsupport.\nSway 1.11 (June 2025) and wlroots 0.19.0 are the first version with explicit\nsync support.\nNot working: TILE support for 8K monitor\nWith the nVidia driver now working per se with Wayland, unfortunately that’s\nstill not good enough to use Wayland in my setup: my Dell UP3218K\nmonitor requires two DisplayPort 1.4\nconnections with MST (Multi Stream Transport) and TILE support. This\ncombination worked just fine under X11 for the last 8+ years.\nWhile GNOME successfully configures the monitor with its native resolution of\n7680x4320@60, the monitor incorrectly shows up as two separate monitors in sway.\nThe reason behind this behavior is that wlroots does not support the TILE\nproperty (issue #1580 from\n2019). Luckily,\nin 2023, contributor EBADBEEF sent draft merge request\n!4154,\nwhich adds support for the TILE property.\nBut, even with the TILE patch, my monitor would not work correctly: The right\nhalf of the monitor would just stay black. The full picture is visible when\ntaking a screenshot with grim, so it seems like an output issue. I had a few\nexchanges about this with EBADBEEF starting in August 2025 (thanks for taking\na look!), but we couldn’t figure out the issue.\nA quarter later, I had made good experiences regarding debugging complex issues\nwith the coding assistant Claude Code\n(Opus 4.5 at the time of writing), so I decided to give it another try. Over two\ndays, I ran a number of tests to narrow down the issue, letting Claude analyze\nsource code (of sway, wlroots, Xorg, mesa, …) and produce test programs that I\ncould run manually.\nUltimately, I ended up with a minimal reproducer program (independent of\nWayland) that shows how the SRC_X DRM property does not work on nVidia (but\ndoes work on Intel, for example!): I posted a bug report with a video in the\nnVidia\nforum\nand hope an nVidia engineer will take a look!\nCrucially, with the bug now identified, I had Claude implement a workaround:\ncopy the right half of the screen (at SRC_X=3840) to another buffer, and then\ndisplay that buffer, but with SRC_X=0.\nWith that\npatch\napplied, for the first time, I can use Sway on my 8K monitor! 🥳\n\nBy the way, when I mentioned that GNOME successfully configures the native\nresolution, that doesn’t mean the monitor is usable with GNOME! While GNOME\nsupports tiled displays, the updates of individual tiles are not synchronized,\nso you see heavy tearing in the middle of the screen, much worse than anything I\nhave ever observed under X11. GNOME/mutter merge request\n!4822 should\nhopefully address this.\nSoftware: NixOS\nDuring 2025, I switched all my computers to NixOS. Its\ndeclarative approach is really nice for doing such tests, because you can\nreliably restore your system to an earlier version.\nTo make a Wayland/sway session available on my NixOS 25.11 installation, I added\nthe following lines to my NixOS configuration file (configuration.nix):\n# GDM display manager (can launch both X11/i3 and Wayland/Sway sessions)\nservices.displayManager.gdm.enable = true;\nservices.displayManager.gdm.autoSuspend = false;\n\n# enable GNOME (for testing)\nservices.desktopManager.gnome.enable = true;\n\nprograms.sway = {\n  enable = true;\n  wrapperFeatures.gtk = true;\n  extraOptions = [ \"--unsupported-gpu\" ];\n};\nI also added the following Wayland-specific programs to environment.systemPackages:\nenvironment.systemPackages = with pkgs; [\n  # …\n  foot          # terminal emulator\n  wtype         # replacement for xdotool type\n  fuzzel        # fuzzy matching program starter\n  wayland-utils # for wayland-info(1)\n  gammastep     # redshift replacement\n];\nNote that activating this configuration kills your running X11 session, if any.\nJust to be sure, I rebooted the entire machine after changing the configuration.\nExperiment results\nWith this setup, I spent about one full work day in a Wayland session. Trying to\nactually get some work done uncovers issues that might not show in casual\ntesting. Most of the day was spent trying to fix Wayland issues 😅. The\nfollowing sections explain what I have learned/observed.\nDesktop: i3 → sway\nMany years ago, when Wayland became more popular, people asked on the i3 issue\ntracker if i3 would be ported to Wayland. I said no: How could I port a program\nto an environment that doesn’t even run on any of my computers? But also, I knew\nthat with working a full-time job, I wouldn’t have time to be an early adopter\nand shape Wayland development.\nThis attitude resulted in Drew DeVault starting the\nSway project around 2016,\nwhich aims to be a Wayland version of i3. I don’t see Sway as\ncompetition. Rather, I thought it was amazing that people liked the i3 project\nso much that they would go through the trouble of creating a similar program for\nother environments! What a nice compliment! 😊\nSway aims to be compatible with i3 configuration files, and it mostly is.\nIf you’re curious, here is what I changed from the Sway defaults, mostly moving\nkey bindings around for the NEO keyboard layout I\nuse, and configuring input/output blocks that I formerly configured in my\n~/.xsession\nfile:\n\nmy changes to the default Sway config\n--- /home/michael/src/sway/config.in\t2025-09-24 19:08:38.876573260 +0200\n+++ /home/michael/.config/sway/config\t2025-12-31 15:50:38.616697542 +0100\n@@ -9,19 +9,76 @@\n # Logo key. Use Mod1 for Alt.\n set $mod Mod4\n # Home row direction keys, like vim\n-set $left h\n-set $down j\n-set $up k\n-set $right l\n+set $left n\n+set $down r\n+set $up t\n+set $right d\n # Your preferred terminal emulator\n set $term foot\n # Your preferred application launcher\n-set $menu wmenu-run\n+set $menu fuzzel\n+\n+font pango:Bitstream Vera Sans Mono 8\n+\n+titlebar_padding 4 2\n+\n+# Make Xwayland windows recognizeable:\n+for_window [shell=\"xwayland\"] title_format \"%title [Xwayland]\"\n+\n+workspace_layout stacking\n+\n+# Open two terminal windows side-by-side on new workspaces:\n+# https://github.com/stapelberg/workspace-populate-for-i3\n+exec ~/go/bin/workspace-populate-for-i3\n+\n+exec gammastep -l 47.31:8.50 -b 0.9\n+\n+input * {\n+   xkb_layout \"de\"\n+   xkb_variant \"neo\"\n+\trepeat_delay 250\n+\trepeat_rate 30\n+}\n+\n+input * {\n+\taccel_profile adaptive\n+\tpointer_accel 0.2\n+}\n \n ### Output configuration\n #\n-# Default wallpaper (more resolutions are available in @datadir@/backgrounds/sway/)\n-output * bg @datadir@/backgrounds/sway/Sway_Wallpaper_Blue_1920x1080.png fill\n+output * bg /dev/null fill #333333\n+output * scale 3\n #\n # Example configuration:\n #\n@@ -33,14 +90,41 @@\n #\n # Example configuration:\n #\n-# exec swayidle -w \\\n-#          timeout 300 'swaylock -f -c 000000' \\\n-#          timeout 600 'swaymsg \"output * power off\"' resume 'swaymsg \"output * power on\"' \\\n-#          before-sleep 'swaylock -f -c 000000'\n+exec swayidle -w \\\n+         before-sleep '~/swaylock.sh' \\\n+         lock '~/swaylock.sh'\n #\n # This will lock your screen after 300 seconds of inactivity, then turn off\n # your displays after another 300 seconds, and turn your screens back on when\n # resumed. It will also lock your screen before your computer goes to sleep.\n+bindsym $mod+l exec loginctl lock-session\n+\n+  # Notifications\n+  bindsym $mod+period exec dunstctl close\n \n ### Input configuration\n #\n@@ -63,11 +147,13 @@\n     # Start a terminal\n     bindsym $mod+Return exec $term\n \n     # Kill focused window\n-    bindsym $mod+Shift+q kill\n+    bindsym $mod+Shift+x kill\n \n     # Start your launcher\n-    bindsym $mod+d exec $menu\n+    bindsym $mod+a exec $menu\n \n     # Drag floating windows by holding down $mod and left mouse button.\n     # Resize them with right mouse button + $mod.\n@@ -142,12 +228,11 @@\n     bindsym $mod+v splitv\n \n     # Switch the current container between different layout styles\n-    bindsym $mod+s layout stacking\n+    bindsym $mod+i layout stacking\n     bindsym $mod+w layout tabbed\n-    bindsym $mod+e layout toggle split\n \n     # Make the current focus fullscreen\n-    bindsym $mod+f fullscreen\n+    bindsym $mod+e fullscreen\n \n     # Toggle the current focus between tiling and floating mode\n     bindsym $mod+Shift+space floating toggle\n@@ -156,7 +241,7 @@\n     bindsym $mod+space focus mode_toggle\n \n     # Move focus to the parent container\n-    bindsym $mod+a focus parent\n+    bindsym $mod+u focus parent\n #\n # Scratchpad:\n #\n@@ -192,37 +277,25 @@\n     bindsym Return mode \"default\"\n     bindsym Escape mode \"default\"\n }\n-bindsym $mod+r mode \"resize\"\n+#bindsym $mod+r mode \"resize\"\n \n #\n # Status Bar:\n #\n # Read `man 5 sway-bar` for more information about this section.\n bar {\n-    position top\n \n     # When the status_command prints a new line to stdout, swaybar updates.\n     # The default just shows the current date and time.\n-    status_command while date +'%Y-%m-%d %X'; do sleep 1; done\n+    status_command i3status\n }\n \n\nI encountered the following issues with Sway:\n\n\nI don’t know how I can configure the same libinput settings that I had\nbefore.  See xinput-list-props-mx-ergo.txt\nfor what I have on X11. Sway’s available accel_profile settings do not seem\nto match what I used before.\n\n\nThe mouse cursor / pointer seems laggy, somehow?! It seems to take longer to\nreact when I move the trackball, and it also seems to move less smoothly\nacross the screen.\nSimon Ser suspects that this might be because\nhardware cursor support might not work with the nVidia drivers currently.\n\n\nNo Xwayland scaling: programs started via Xwayland are blurry (by default) or\ndouble-scaled (when setting Xft.dpi: 288). This is a Sway-specific\nlimitation: KDE fixed this in\n2022. From\nSway issue #2966, I can tell\nthat Sway developers do not seem to like this approach for some reason, but\nthat’s very unfortunate for my migration: The backwards compatibility\noption of running older programs through Xwayland is effectively unavailable\nto me.\n\n\nSometimes, keyboard shortcuts seem to be executed twice! Like, when I focused\nthe first of five Chrome windows in a stack and moved that window to another\nworkspace, two windows would be moved instead of one. I also see messages\nlike this one (not exactly correlated with the double-shortcut problem,\nthough):\n[ERROR] [wlr] [libinput] event0  - https: kinT (kint36): client bug: event\nprocessing lagging behind by 32ms, your system is too slow\n…and that seems wrong to me. My high-end Linux\nPC certainly isn’t slow by any\nmeasure.\n\n\nGTK: Font size\nWhen I first started GTK programs like GIMP or Emacs, I noticed all fonts were\nway too large! Apparently, I still had some scaling-related settings that I\nneeded to reset like so:\ngsettings reset org.gnome.desktop.interface scaling-factor\ngsettings reset org.gnome.desktop.interface text-scaling-factor\nDebugging tip: Display GNOME settings using dconf dump / (stored in\n~/.config/dconf).\nGTK: Backend\nSome programs like geeqie apparently need an explicit export GDK_BACKEND=wayland environment variable, otherwise they run in\nXwayland. Weird.\nFont rendering\nI also noticed that font rendering is different between X11 and Wayland! The\ndifference is visible in Chrome browser tab titles and the URL bar, for example:\n\nAt first I thought that maybe Wayland defaults to different font-antialiasing\nand font-hinting settings, but I tried experimenting with the following settings\n(which default to font-antialiasing=grayscale and font-hinting=slight), but\ncouldn’t get things to render like they did before:\ngsettings set org.gnome.desktop.interface font-antialiasing 'rgba'\ngsettings set org.gnome.desktop.interface font-hinting 'full'\nUpdate: Thanks to\nHugo for pointing out\nthat under Wayland, GTK3 ignores the ~/.config/gtk-3.0/settings.ini\nconfiguration file and uses dconf exclusively! Setting the following dconf\nsetting makes the font rendering match:\ngsettings set org.gnome.desktop.interface font-name 'Cantarell 11'\nScreen locker: swaylock\nThe obvious replacement for i3lock is\nswaylock.\nI quickly ran into a difference in architecture between the two programs:\n\n\ni3lock shows a screen locker window. When you kill i3lock, the screen is\nunlocked.\n\n\nWhen you kill swaylock, you end up in a Red Screen Of Death.\nTo get out of this state, you need to restart swaylock and unlock. You can\nunlock from the command line by sending SIGUSR1 to the swaylock process.\n\n\nThis was very surprising to me, but is by (Wayland) design! See Sway issue\n#7046 for details, and this quote from\nthe ext-session-lock-v1 Wayland protocol:\n\n“The compositor must stop rendering and provide input to normal\nclients. Instead the compositor must blank all outputs with an opaque color\nsuch that their normal content is fully hidden.”\n\nOK, so when you start swaylock via SSH for testing, remember to always unlock\ninstead of just cancelling swaylock with Ctrl+C. And hope it never crashes.\nI used to start i3lock via a wrapper script, which turns off the monitor\n(input wakes it up):\n#!/bin/sh\n# Turns on DPMS, mutes all output, locks the screen.\n# Reverts all settings on unlock, or when killed.\n\nrevert() {\n    xset dpms 0 0 0\n    pactl set-sink-mute @DEFAULT_SINK@ 0\n}\ntrap revert SIGHUP SIGINT SIGTERM\nxset +dpms dpms 15 15 15\n(sleep 1 && xset dpms force off) &\npactl set-sink-mute @DEFAULT_SINK@ 1\ni3lock --raw 3840x2160:rgb --image ~/i3lock-wallpaper-3840x2160.rgb -n \nrevert\nWith Wayland, the DPMS behavior has to be implemented differently, with swayidle:\n#!/bin/sh\n# Turns on DPMS, mutes all output, locks the screen.\n# Reverts all settings on unlock, or when killed.\n\nswayidle -w \\\n  timeout 5 'swaymsg \"output * dpms off\"' \\\n  resume 'swaymsg \"output * dpms on\"' &\nswayidle=$!\n\nrevert() {\n    kill $swayidle\n    pactl set-sink-mute @DEFAULT_SINK@ 0\n}\ntrap revert SIGHUP SIGINT SIGTERM\n\npactl set-sink-mute @DEFAULT_SINK@ 1\nswaylock --image ~/i3lock-wallpaper-3840x2160.jpg\nrevert\ni3 IPC automation\nThe i3 window manager can be extended via its IPC interface (interprocess\ncommunication).\nI use a few small tools that use this interface.\nI noticed the following issues when using these tools with Sway:\n\n\nTools using the go.i3wm.org/i3/v4 Go\npackage need a special socket path\nhook\ncurrently. We\nshould probably include transparent handling in the package to ease the\ntransition.\n\n\nTools started with exec from the Sway config unexpectedly keep running even\nwhen you exit Sway (swaymsg exit) and log into a new session!\n\n\nMy\nworkspace-populate-for-i3\ndid not work:\n\nSway does not implement i3’s layout\nsaving/restoring because Drew\ndecided in 2017 that the feature is “too complicated and hacky for too\nlittle\nbenefit”. Too\nbad. I have a couple of layouts I liked that I’ll need to replicate\ndifferently.\nSway does not match workspace nodes with [con_id] criteria. There’s\npull request #8980 (posted\nindependently, five days ago) to fix that.\n\n\n\nMy wsmgr-for-i3 worked\npartially:\n\nRestoring workspaces (wsmgr restore) worked.\nSway’s rename workspace\ncommand\nimplementation does not seem to pick up workspace numbers from the target\nname.\n\n\n\nTerminal: foot\nOn X11, I use the rxvt-unicode\n(URxvt) terminal emulator. It has a couple of quality-of-life features that I\ndon’t want to lose, aside from being fast and coming with a minimal look:\n\nBackwards search through your scrollback (= command output)\nOpening URLs in your scrollback using keyboard shortcuts\nOpening a new terminal window in the same working directory\nUpdating the terminal title from your shell\n\nIn earlier experiments, I tried Alacritty or Kitty, but wasn’t happy with\neither.\nThanks to anarcat’s blog post “Wayland: i3 to Sway\nmigration”, I\ndiscovered the foot terminal emulator, which\nlooks like a really nice option!\nI started a foot.ini config\nfile\nto match my URxvt config, but later I noticed that at least some colors don’t\nseem to match (some text lines with green/red background looked different). I’m\nnot sure why and have not yet looked into it any further.\nI noticed the following issues using foot:\n\n\nPressing Ctrl+Enter (which I seem to do by mistake quite a bit) results in\nescape sequences, whereas URxvt just treats Ctrl+Enter like Enter.\nThis can be worked around in your shell (Zsh, in my case), see foot issue\n#628 for details.\n\n\nDouble-clicking on part of a URL with the mouse selects the URL (as expected),\nbut without the https: scheme prefix! Annoying when you do want to use the\nmouse.\nI can hold Ctrl to work around this, which will make foot select everything\nunder the pointer up to, and until, the next space characters.\n\n\nStarting screen(1)\n in foot results in not having\ncolor support for programs running inside the screen session. Probably a\nterminfo-related problem somehow…? I can also reproduce this issue with GNOME\nterminal. But with URxvt or xterm, it\nworks.\n\n\nSelecting text highlights the text within the line, but not the entire line.\nThis is different from other terminal emulators I am used to, but I don’t see\nan option to change it.\nHere’s a screenshot showing foot after triple-clicking on the right of\n“kthreadd”:\n\nBut triple-clicking on an echo output line highlights only the contents, not\nthe whole line:\n\n\n\nText editor: Emacs\nI find Emacs’s Wayland support rather disappointing. The standard version of\nEmacs only supports X11, so on Sway, it starts in Xwayland. Because Sway does\nnot support scaling with Xwayland, Emacs shows up blurry (top/background\nwindow):\n\nNative Wayland support (bottom/foreground window) is only available in the\npgtk Emacs version (emacs-pgtk on NixOS). pgtk used to be a separate\nbranch, but was merged in Emacs 29 (July 2023). There seem to be issues\nwith pgtk on X11 (you get a warning when starting Emacs-pgtk on X11), so there\nhave to be two separate versions for now…\nUnfortunately, the pgtk text rendering looks different than native X11 text\nrendering! The line height and letter spacing seems different:\n\nI’m not sure why it’s different! Does anybody know how to make it match the old\nbehavior?\nAside from the different text rendering, the other major issue for me is input\nlatency: Emacs-pgtk feels significantly slower (less responsive) than\nEmacs. This was reported on Reddit multiple times (thread\n1,\nthread\n2)\nand Emacs bug #71591, but\nthere doesn’t seem to be any solution.\nI’ll also need a solution for running Emacs remotely. Thus far, I use X11\nforwarding over SSH (which works fine and with low latency over fiber\nconnections). I should probably check out waypipe, but have not yet had a\nchance.\nBrowser: Chrome\nWhen starting Chrome and checking the chrome://gpu debug page, things look\ngood:\n\nBut rather quickly, after moving and resizing browser windows, the GPU process\ndies with messages like the following and, for example, WebGL is no longer\nhardware accelerated:\nERROR:ui/ozone/platform/wayland/gpu/gbm_pixmap_wayland.cc:95] Cannot create bo with format=RGBA_8888 and usage=Scanout|Rendering|Texturing\nERROR:ui/gfx/linux/gbm_wrapper.cc:405] Failed to create BO with modifiers: Invalid argument (22)\nERROR:ui/ozone/platform/wayland/gpu/gbm_pixmap_wayland.cc:95] Cannot create bo with format=RGBA_8888 and usage=Texturing\nERROR:gpu/command_buffer/service/shared_image/shared_image_factory.cc:981] CreateSharedImage: could not create backing.\nERROR:gpu/command_buffer/service/shared_image/shared_image_manager.cc:397] SharedImageManager::ProduceSkia: Trying to Produce a Skia representation from a non-existent mailbox.\nERROR:components/viz/service/gl/exit_code.cc:13] Restarting GPU process due to unrecoverable error. Context was lost.\nR:gpu/ipc/client/command_buffer_proxy_impl.cc:321] GPU state invalid after WaitForGetOffsetInRange.\nERROR:content/browser/gpu/gpu_process_host.cc:1005] GPU process exited unexpectedly: exit_code=8704\nOf course, using a browser without hardware acceleration is very frustrating,\nespecially at high resolutions. Starting Chrome with --disable-gpu-compositing\nseems to work around the GPU process exiting, but Chrome still does not feel as\nsmooth as on X11.\nAnother big issue for me is that Sway does not open Chrome windows on the\nworkspace on which I closed them. Support for tracking and restoring the\n_NET_WM_DESKTOP EWMH atom was added to i3 in January\n2016\nand to Chrome in May\n2016\nand Firefox in March\n2020.\nI typically have 5+ workspaces and even more Chrome windows at any given point,\nso having to sort through 10+ Chrome windows every day (when I boot my work\ncomputer) is very annoying.\nSimon Ser said that this would be addressed with\na new Wayland protocol (xdg-session-management, merge request\n!18).\nScreensharing\nI work remotely a lot, so screen sharing is a table-stakes feature for me.  I\nuse screen sharing in my browser almost every day, in different scenarios and\nwith different requirements.\nIn X11, I am used to the following experience with Chrome. I click the “Window”\ntab and see previews of my windows. When I select the window and confirm, its\ncontents get shared:\n\nTo get screen sharing to work in Wayland/sway, you need to install\nxdg-desktop-portal and xdg-desktop-portal-wlr (the latter is specific to\nwlroots, which sway uses).\nWith these packages set up, this is the behavior I see:\n\nI can share a Chrome tab.\nI can share the entire monitor.\nI cannot share a specific window (the entire monitor shows up as a single\nwindow).\n\nThis is a limitation of xdg-desktop-portal-wlr (and\nothers), which\nshould be addressed with the upcoming Sway 1.12 release.\nI changed my NixOS configuration to use sway and wlroots from git to try it\nout. When I click on the “Window” tab, I see a chooser in which I need to select\na window:\n\nAfter selecting the window, I see only that window’s contents previewed in\nChrome:\n\nAfter confirming, I get another chooser and need to select the window\nagain. Notably, there is no connection between the previewed window and the\nchosen window in this second step — if I chose a different window, that’s what\nwill be shared:\n\nNow that window is screenshared (so the feature now works; nice!), but\nunfortunately in low resolution, meaning the text is blurry for my co-workers.\nI reported this as xdg-desktop-portal-wlr issue\n#364 and it\nseems like the issue is that the wrong scale factor is applied. The patch\nprovided in the issue works for me.\nBut, on a high level, the whole flow seems wrong: I shouldn’t see a chooser when\nclicking on Chrome’s “Window” tab. I should see previews of all windows. I\nshould be able to select the window in Chrome, not with a separate chooser.\nScaling Glitches\nI also noticed a very annoying glitch when output scaling is enabled: the\ncontents of (some!) windows would “jump around” as I was switching between\nwindows (in a tabbed or stacked container) or between workspaces.\nI first noticed this in the foot terminal emulator, where the behavior is as follows:\n\nSwitch focus to another foot terminal by changing workspaces, or by\nswitching focus within a stacked or tabbed container.\nThe new foot terminal shows up with its text contents slightly offset.\nWithin a few milliseconds, foot’s text jumps to the correct position.\n\nI captured the following frame with my iPhone just as the content was moving a\nfew pixels, shortly after switching focus to this window:\n\nLater, I also noticed that Chrome windows briefly show up blurry after\nswitching.\nMy guess is that because Sway sets the scale factor to 1 for invisible windows,\nwhen switching focus you see a scale-1 content buffer until the application\nprovided its scale-3 content buffer.\nNotifications: dunst\ndunst supports Wayland natively. I tried dunst 1.13 and did not notice any\nissues.\nPicker: rofi\nrofi works on Wayland since v2.0.0 (2025-09-01).\nI use rofi with rofimoji as my Emoji\npicker. For text input, instead of xdotool, wtype seems to work. I didn’t\nnotice any issues.\nScreenshots: grim?\nInstead of my usual choice maim(1)\n, I tried grim(1)\n, but unfortunately grim’s -T flag to select the\nwindow to capture is rather cumbersome to use (and captures in 1x scale).\nDoes anyone have any suggestions for a good alternative?\nConclusion\nFinally I made some progress on getting a Wayland session to work in my\nenvironment!\nBefore giving my verdict on this Wayland/sway experiment, let me explain that my\nexperience on X11/i3 is really good. I don’t see any tearing or other artifacts\nor glitches in my day-to-day computer usage. I don’t use a compositor, so my\ninput latency is really good: I once measured it to approximately 763 μs in\nEmacs on X11 with my custom-built keyboard (plus output latency), see kinX:\nlatency measurement (2018).\nSo from my perspective, switching from this existing, flawlessly working stack\n(for me) to Sway only brings downsides. I observe new graphical glitches that I\ndidn’t have before. The programs I spend most time in (Chrome and Emacs) run\nnoticeably worse. Because of the different implementations, or because I need to\nswitch programs entirely, I encounter a ton of new bugs.\nFor the first time, an on-par Wayland experience seems within reach, but\nrealistically it will require weeks or even months of work still. In my\nexperience, debugging sessions quickly take hours as I need to switch graphics\ncards and rewire monitors to narrow down bugs. I don’t have the time to\ncontribute much to fixing these numerous issues unfortunately, so I’ll keep\nusing X11/i3 for now.\nFor me, a Wayland/Sway session will be ready as my daily driver when:\n\nSway no longer triggers some key bindings twice some times (“ghost key\npresses”)\nI no longer see glitches when switching between windows or workspaces in Sway.\nChrome is continuously hardware-accelerated.\nChrome windows are restored to their previous workspace when starting.\nEmacs either:\n\nRuns via Xwayland and Sway makes scaling work.\nOr if its pgtk variant fixes its input latency issues\nand can be made to render text the same as before somehow."
    },
    {
      "title": "michael.stapelberg.ch: Self-hosting my photos with Immich",
      "url": "https://michael.stapelberg.ch/posts/2025-11-29-self-hosting-photos-with-immich/",
      "source": "michael.stapelberg.ch",
      "time": "2026-02-23T12:43:23.147687",
      "raw_desc": "For every cloud service I use, I want to have a local copy of my data for backup\npurposes and independence. Unfortunately, the gphotos-sync tool stopped\nworking in March\n2025 when\nGoogle restricted the OAuth scopes, so I needed an alternative for my existing\nGoogle Photos setup. In this post, I describe how I have set up\nImmich, a self-hostable photo manager.\nHere is the end result: a few (live) photos from NixCon\n2025:\n\nStep 1. Hardware\nI am running Immich on my Ryzen 7 Mini PC (ASRock DeskMini\nX600), which\nconsumes less than 10 W of power in idle and has plenty of resources for VMs (64\nGB RAM, 1 TB disk). You can read more about it in my blog post from July 2024:\n\n\nRyzen 7 Mini-PC makes a power-efficient VM host\n\n\n\n\n\n\t  When I saw the first reviews of the ASRock DeskMini X600 barebone, I was immediately interested in building a home-lab hypervisor (VM host) with it. Apparently, the DeskMini X600 uses less than 10W of power but supports latest-generation AMD CPUs like the Ryzen 7 8700G!\n\n\t  Read more →\n\n\n\n\nI installed Proxmox, an Open Source virtualization\nplatform, to divide this mini server into VMs, but you could of course also\ninstall Immich directly on any server.\nStep 2. Install Immich\nI created a VM (named “photos”) with 500 GB of disk space, 4 CPU cores and 4 GB of RAM.\nFor the initial import, you could assign more CPU and RAM, but for normal usage, that’s enough.\nI (declaratively) installed\nNixOS on that VM as described in this blog post:\n\n\nHow I like to install NixOS (declaratively)\n\n\n\n\n\n\t  For one of my network storage PC builds, I was looking for an alternative to Flatcar Container Linux and tried out NixOS again (after an almost 10 year break). There are many ways to install NixOS, and in this article I will outline how I like to install NixOS on physical hardware or virtual machines: over the network and fully declaratively.\n\n\t  Read more →\n\n\n\n\nAfterwards, I enabled Immich, with this exact configuration:\nservices.immich = {\n  enable = true;\n};\nAt this point, Immich is available on localhost, but not over the network,\nbecause NixOS enables a firewall by default. I could enable the\nservices.immich.openFirewall option, but I actually want Immich to only be\navailable via my Tailscale VPN, for which I don’t need to open firewall access —\ninstead, I use tailscale serve to forward traffic to localhost:2283:\nphotos# tailscale serve --bg http://localhost:2283\nBecause I have Tailscale’s MagicDNS\nand TLS certificate provisioning\nenabled, that means I can now open https://photos.example.ts.net in my browser\non my PC, laptop or phone.\nStep 2. Initial photos import\nAt first, I tried importing my photos using the official Immich CLI:\n% nix run nixpkgs#immich-cli -- login https://photos.example.ts.net secret\n% nix run nixpkgs#immich-cli -- upload --recursive /home/michael/lib/photo/gphotos-takeout\nUnfortunately, the upload was not running reliably and had to be restarted\nmanually a few times after running into a timeout. Later I realized that this\nwas because the Immich server runs background jobs like thumbnail creation,\nmetadata extraction or face detection, and these background jobs slow down the\nupload to the extent that the upload can fail with a timeout.\nThe other issue was that even after the upload was done, I realized that Google\nTakeout archives for Google Photos contain metadata in separate JSON files next\nto the original image files:\n\nUnfortunately, these files are not considered by immich-cli.\nLuckily, there is a great third-party tool called\nimmich-go, which solves both of these\nissues! It pauses background tasks before uploading and restarts them\nafterwards, which works much better, and it does its best to understand Google\nTakeout archives.\nI ran immich-go as follows and it worked beautifully:\n% immich-go \\\n  upload \\\n  from-google-photos \\\n  --server=https://photos.example.ts.net \\\n  --api-key=secret \\\n  ~/Downloads/takeout-*.zip\nStep 3. Install the Immich iPhone App\nMy main source of new photos is my phone, so I installed the Immich app on my\niPhone, logged into my Immich server via its Tailscale URL and enabled automatic\nbackup of new photos via the icon at the top right.\nI am not 100% sure whether these settings are correct, but it seems like camera\nphotos generally go into Live Photos, and Recent should cover other files…?!\nIf anyone knows, please send an explanation (or a link!) and I will update the article.\n\nI also strongly recommend to disable notifications for Immich, because otherwise\nyou get notifications whenever it uploads images in the background. These\nnotifications are not required for background upload to work, as an Immich\ndeveloper confirmed on\nReddit. Open\nSettings → Apps → Immich → Notifications and un-tick the permission checkbox:\n\nStep 4. Backup\nImmich’s documentation on\nbackups contains\nsome good recommendations. The Immich developers recommend backing up the entire\ncontents of UPLOAD_LOCATION, which is /var/lib/immich on NixOS. The\nbackups subdirectory contains SQL dumps, whereas the 3 directories upload,\nlibrary and profile contain all user-uploaded data.\nHence, I have set up a systemd timer that runs rsync to copy /var/lib/immich\nonto my PC, which is enrolled in a 3-2-1 backup\nscheme.\nWhat’s missing?\nImmich (currently?) does not contain photo editing features, so to rotate or\ncrop an image, I download the image and use GIMP.\nTo share images, I still upload them to Google Photos (depending on who I share\nthem with).\nWhy Immich instead of…?\nThe two most promising options in the space of self-hosted image management\ntools seem to be Immich and Ente.\nI got the impression that Immich is more popular in my bubble, and Ente made the\nimpression on me that its scope is far larger than what I am looking for:\n\nEnte is a service that provides a fully open source, end-to-end encrypted\nplatform for you to store your data in the cloud without needing to trust the\nservice provider. On top of this platform, we have built two apps so far: Ente\nPhotos (an alternative to Apple and Google Photos) and Ente Auth (a 2FA\nalternative to the deprecated Authy).\n\nI don’t need an end-to-end encrypted platform. I already have encryption on the\ntransit layer (Tailscale) and disk layer (LUKS), no need for more complexity.\nConclusion\nImmich is a delightful app! It’s very fast and generally seems to work well.\nThe initial import is smooth, but only if you use the right tool. Ideally, the\nofficial immich-cli could be improved. Or maybe immich-go could be made the\nofficial one.\nI think the auto backup is too hard to configure on an iPhone, so that could\nalso be improved.\nBut aside from these initial stumbling blocks, I have no complaints."
    },
    {
      "title": "worksonmymachine.substack.com: The Great Zipper of Capitalism",
      "url": "https://worksonmymachine.ai/p/the-great-zipper-of-capitalism",
      "source": "worksonmymachine.substack.com",
      "time": "2026-02-23T12:43:23.533819",
      "raw_desc": ""
    },
    {
      "title": "worksonmymachine.substack.com: As Complexity Grows, Architecture Dominates Material",
      "url": "https://worksonmymachine.ai/p/as-complexity-grows-architecture",
      "source": "worksonmymachine.substack.com",
      "time": "2026-02-23T12:43:23.533819",
      "raw_desc": ""
    },
    {
      "title": "worksonmymachine.substack.com: The Discovery Phase Is All There Is",
      "url": "https://worksonmymachine.ai/p/the-discovery-phase-is-all-there",
      "source": "worksonmymachine.substack.com",
      "time": "2026-02-23T12:43:23.533819",
      "raw_desc": ""
    }
  ]
}