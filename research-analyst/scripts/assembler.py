"""
<!-- Input: Project Path, Output Filename, Report Title, Strict Mode Toggle -->
<!-- Output: Merged Report Path, Quality Audit Report -->
<!-- Pos: scripts/assembler.py. The "Blacksmith" that forges the final report. V6.2 -->

!!! Maintenance Protocol: This script MUST verify character counts and enforce "De-molding" logic.
!!! ANY metadata leakage or illegal formatting (bolding) in Production mode results in failure.
"""

import argparse
import os
import glob
import sys
import re

def clean_content(content):
    """The 'De-molding' logic: removes noise while preserving substance."""
    # 1. Remove GEB-Flow Metadata blocks (Triple quotes with comments)
    content = re.sub(r'"""[\s\S]*?"""', '', content)

    # 2. Remove Bold (Double Asterisks) - Forbidden in Consulting Narrative
    content = re.sub(r'\*\*(.*?)\*\*', r'\1', content)
    
    # 3. Trim whitespace
    return content.strip()

def assemble_report(project_path, output_filename="final_report.md", title="Strategic Deep Dive Report", min_words=800):
    # 1. Locate Chapters (Recursive and Multi-pattern)
    patterns = [
        os.path.join(project_path, "chapter*.md"),
        os.path.join(project_path, "[0-9]*.md"),
        os.path.join(project_path, "chapters", "chapter*.md"),
        os.path.join(project_path, "chapters", "[0-9]*.md")
    ]
    
    files = []
    for p in patterns:
        files.extend(glob.glob(p))
    
    # Remove duplicates and sort
    files = list(set(files))
    try:
        files.sort(key=lambda x: int(re.search(r'\d+', os.path.basename(x)).group()) if re.search(r'\d+', os.path.basename(x)) else 999)
    except:
        files.sort()

    if not files:
        return {"status": "error", "message": f"No chapter files found in {project_path}."}

    # 2. Forge Final Text
    merged_content = []
    merged_content.append(f"# {title}\n> Generated by Research Analyst V6.2\n\n")
    
    audit_results = []
    total_source_bytes = 0

    for f_path in files:
        total_source_bytes += os.path.getsize(f_path)
        with open(f_path, 'r', encoding='utf-8') as f:
            raw_text = f.read()
            # Word count check: CJK characters + English words
            cjk_count = len(re.findall(r'[\u4e00-\u9fff]', raw_text))
            en_word_count = len(re.findall(r'\b[a-zA-Z0-9]+\b', raw_text))
            word_count = cjk_count + en_word_count
            
            clean_text = clean_content(raw_text)
            
            merged_content.append(clean_text)
            merged_content.append("\n\n---\n\n")
            
            audit_results.append({
                "file": os.path.basename(f_path),
                "words": word_count,
                "passed_depth": word_count >= min_words
            })
    
    final_text = "".join(merged_content)
    
    # 3. Save
    if output_filename.startswith("..") or os.path.isabs(output_filename):
        output_path = os.path.abspath(os.path.join(project_path, output_filename))
    else:
        output_path = os.path.join(project_path, output_filename)
        
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(final_text)
    
    # 4. Density Guard Check
    final_bytes = os.path.getsize(output_path)
    
    status = "success"
    failed_chapters = [a["file"] for a in audit_results if not a["passed_depth"]]
    if failed_chapters:
        status = "warning_depth_insufficient"
    
    return {
        "status": status,
        "path": output_path,
        "chapters_merged": len(files),
        "audit": audit_results,
        "failed_depth_list": failed_chapters,
        "final_bytes": final_bytes
    }

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--path", required=True)
    parser.add_argument("--output", default="final_report.md")
    parser.add_argument("--title", default="Strategic Deep Dive Report")
    parser.add_argument("--min_words", type=int, default=800)
    args = parser.parse_args()
    
    result = assemble_report(args.path, args.output, args.title, args.min_words)
    import json
    print(json.dumps(result, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()
