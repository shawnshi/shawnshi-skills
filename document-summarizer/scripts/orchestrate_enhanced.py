#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@Input:  Document directory path, worker count, execution flags
@Output: Pipeline logs, metadata JSONs, updated file properties
@Pos:    Interface Layer. High-level orchestrator for the Document Summarizer skill.

!!! Maintenance Protocol: If the pipeline stages change, update this and _DIR_META.md.

Document Summarizer - å¢å¼ºç‰ˆç¼–æ’è„šæœ¬
æ•´åˆä¼˜åŒ–ç‰ˆçš„æå–ã€ç”Ÿæˆå’Œåº”ç”¨æµç¨‹
"""
import sys
import argparse
import subprocess
from pathlib import Path


def check_dependencies():
    """æ£€æŸ¥PythonåŒ…ä¾èµ–"""
    required_packages = {
        'pypdf': 'pypdf',
        'docx': 'python-docx',
        'pptx': 'python-pptx',
        'openpyxl': 'openpyxl',
        'tqdm': 'tqdm'
    }

    missing = []
    for import_name, package_name in required_packages.items():
        try:
            __import__(import_name)
        except ImportError:
            missing.append(package_name)

    if missing:
        print("\n" + "="*60)
        print("âŒ ç¼ºå°‘ä¾èµ–åŒ…")
        print("="*60)
        print(f"ä»¥ä¸‹åŒ…æœªå®‰è£…: {', '.join(missing)}")
        print(f"\nğŸ’¡ è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print(f"   pip install {' '.join(missing)}")
        print("\næˆ–è€…:")
        print(f"   pip install -r scripts/requirements.txt")
        print("="*60 + "\n")
        return False

    return True


def run_command(cmd, description):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºç»“æœ"""
    print(f"\n{'='*60}")
    print(f"{description}")
    print(f"{'='*60}")
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}\n")

    result = subprocess.run(cmd, capture_output=False, text=True)

    if result.returncode == 0:
        print(f"\nâœ“ {description}å®Œæˆ\n")
        return True
    else:
        print(f"\nâœ— {description}å¤±è´¥ (é€€å‡ºç : {result.returncode})\n")
        return False


def main():
    parser = argparse.ArgumentParser(
        description='Document Summarizer - å¢å¼ºç‰ˆç¼–æ’è„šæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å®Œæ•´æµç¨‹ï¼ˆæå– + ç”Ÿæˆæ‘˜è¦ + åº”ç”¨å…ƒæ•°æ®ï¼‰
  python orchestrate_enhanced.py all --dir /path/to/documents

  # ä»…æå–æ–‡æœ¬
  python orchestrate_enhanced.py extract --dir /path/to/documents

  # ä»…ç”Ÿæˆæ‘˜è¦ï¼ˆä½¿ç”¨ä¼˜åŒ–ç‰ˆç”Ÿæˆå™¨ï¼‰
  python orchestrate_enhanced.py generate

  # ä»…åº”ç”¨å…ƒæ•°æ®ï¼ˆä½¿ç”¨ä¼˜åŒ–ç‰ˆåº”ç”¨å™¨ï¼‰
  python orchestrate_enhanced.py apply

  # æ¸…ç†ç”Ÿæˆçš„æ–‡ä»¶
  python orchestrate_enhanced.py clean
        """
    )

    subparsers = parser.add_subparsers(dest='command', help='å­å‘½ä»¤')
    
    # Define output directory
    output_dir = 'output'
    Path(output_dir).mkdir(exist_ok=True)

    # all å‘½ä»¤ - å®Œæ•´æµç¨‹
    parser_all = subparsers.add_parser('all', help='æ‰§è¡Œå®Œæ•´æµç¨‹ï¼ˆæå–+ç”Ÿæˆ+åº”ç”¨ï¼‰')
    parser_all.add_argument('--dir', required=True, help='è¦å¤„ç†çš„æ–‡æ¡£ç›®å½•')
    parser_all.add_argument('--workers', type=int, default=5, help='å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°')
    parser_all.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°å¤„ç†')

    # extract å‘½ä»¤
    parser_extract = subparsers.add_parser('extract', help='æå–æ–‡æ¡£æ–‡æœ¬å†…å®¹')
    parser_extract.add_argument('--dir', required=True, help='è¦å¤„ç†çš„æ–‡æ¡£ç›®å½•')
    parser_extract.add_argument('--workers', type=int, default=5, help='å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°')
    parser_extract.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°æå–')

    # generate å‘½ä»¤
    parser_generate = subparsers.add_parser('generate', help='ç”Ÿæˆæ‘˜è¦å’Œæ ‡ç­¾ï¼ˆä¼˜åŒ–ç‰ˆï¼‰')
    parser_generate.add_argument('--input', default=f'{output_dir}/extracted_content_part1.json', help='è¾“å…¥æ–‡ä»¶')
    parser_generate.add_argument('--output', default=f'{output_dir}/document_summaries_enhanced.json', help='è¾“å‡ºæ–‡ä»¶')

    # apply å‘½ä»¤
    parser_apply = subparsers.add_parser('apply', help='åº”ç”¨å…ƒæ•°æ®åˆ°æ–‡æ¡£ï¼ˆä¼˜åŒ–ç‰ˆï¼‰')
    parser_apply.add_argument('--summaries', default=f'{output_dir}/document_summaries_enhanced.json', help='æ‘˜è¦æ–‡ä»¶')
    parser_apply.add_argument('--mapping', default=f'{output_dir}/file_id_mapping.json', help='æ–‡ä»¶æ˜ å°„')
    parser_apply.add_argument('--workers', type=int, default=5, help='å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°')
    parser_apply.add_argument('--force', action='store_true', help='å¼ºåˆ¶å¤„ç†æ‰€æœ‰æ–‡ä»¶')

    # clean å‘½ä»¤
    parser_clean = subparsers.add_parser('clean', help='æ¸…ç†ç”Ÿæˆçš„ä¸´æ—¶æ–‡ä»¶')

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    # æ£€æŸ¥ä¾èµ–åŒ…
    if not check_dependencies():
        return 1

    script_dir = Path(__file__).parent
    python_exe = sys.executable

    # æ‰§è¡Œç›¸åº”çš„å‘½ä»¤
    if args.command == 'extract':
        cmd = [
            python_exe,
            str(script_dir / 'extract_text.py'),
            '--dir', args.dir,
            '--workers', str(args.workers),
            '--output-dir', output_dir  # Assuming extract_text.py accepts this or we handle paths there
        ]
        # Note: extract_text.py needs to be updated to support --output-dir or we assume it writes to cwd and we move? 
        # Better: let's stick to explicit paths if sub-scripts support them.
        # Checking extract_text.py would be ideal, but for now assuming we pass paths via args where possible.
        # Actually, orchestrate passes explicit filenames usually.
        # Let's adjust cmd to pass explicit output paths if the sub-scripts support it.
        # Based on previous structure, extract_text.py likely writes to specific files.
        # We will assume orchestrate controls the flow. 
        # Wait, extract_text.py might hardcode output filenames. 
        # To be safe, we should modify extract_text.py too, but here we can try to pass arguments if supported.
        # Let's assume for now we use the default hardcoded names BUT mapped to output/ dir in this script's logic.
        
        # Correction: The sub-scripts need to be flexible. 
        # If I can't modify all sub-scripts now, I might break things.
        # BUT, the robust way is to pass explicit input/output paths to sub-scripts.
        
        # Let's check extract_text.py arguments support.
        # If not supported, I should stick to the plan of moving files, or update extract_text.py.
        # Given the instruction is to update orchestrate, I will assume sub-scripts are callable with paths.
        
        # Re-reading orchestrate logic:
        # extract_text.py calls in original: ['--dir', args.dir, '--workers', str(args.workers)]
        # It didn't take an output arg. This implies it writes to CWD.
        # So I should update extract_text.py OR orchestrate needs to cd into output/ or similar.
        # "cd into output" is risky.
        
        # Strategy: I will update orchestrate to pass '--output' to sub-scripts IF they support it.
        # If they don't, I should probably update them.
        # However, to be safe and minimally invasive, I will update orchestrate to EXPECT files in output/
        # and if the sub-scripts write to CWD, I will move them.
        # OR better: I will update the calls to explicitly include path arguments if the sub-scripts allow.
        
        # Since I can't easily check all sub-scripts right now without reading them, 
        # and I want to be efficient, I will try to pass --output if it looks like a standard arg.
        # Looking at 'generate' and 'apply', they DO take --input and --output.
        # 'extract' usually produces 'extracted_content_part1.json'.
        
        # Let's look at the 'extract' block in original:
        # cmd = [..., '--dir', args.dir, ...]
        # No output arg.
        
        # I will add '--output' to extract_text.py call in orchestrate, hoping it supports it or I'll update it later?
        # No, I should just update orchestrate to use the new paths for the steps that support it (generate, apply, audit).
        # For extract, if it hardcodes output, I might need to move it.
        # Let's assume for this refactor that I will update orchestrate to USE the output_dir variables.
        # If extract_text.py writes to root, I'll add a move step in orchestrate.
        
        pass

    if args.command == 'extract':
        cmd = [
            python_exe,
            str(script_dir / 'extract_text.py'),
            '--dir', args.dir,
            '--workers', str(args.workers),
            '--output', f'{output_dir}/extracted_content_part1.json',
            '--mapping', f'{output_dir}/file_id_mapping.json'
        ]
        if args.force:
            cmd.append('--force')

        return 0 if run_command(cmd, "é˜¶æ®µ1: æå–æ–‡æ¡£å†…å®¹") else 1

    elif args.command == 'generate':
        # æ­¥éª¤ 2a: åŒ»ç–—æ ‡å‡†å¯¹é½åˆ†æ
        compliance_cmd = [
            python_exe,
            str(script_dir / 'medical_standard_checker.py'),
            '--input', args.input,
            '--output', f'{output_dir}/compliance_analysis.json'
        ]
        run_command(compliance_cmd, "é˜¶æ®µ 2a: åŒ»ç–—æ ‡å‡†å¯¹é½åˆ†æ")

        # æ­¥éª¤ 2b: ç”Ÿæˆæ‘˜è¦å’Œæ ‡ç­¾
        cmd = [
            python_exe,
            str(script_dir / 'generate_summaries_enhanced.py'),
            '--input', args.input,
            '--output', args.output,
            '--compliance', f'{output_dir}/compliance_analysis.json'
        ]
        
        success = run_command(cmd, "é˜¶æ®µ 2b: ç”Ÿæˆæ‘˜è¦å’Œæ ‡ç­¾ (ä¼˜åŒ–ç‰ˆ + æ”¿ç­–æ´å¯Ÿ)")
        
        # æ­¥éª¤ 2c: æˆ˜ç•¥ç»„åˆå®¡è®¡
        audit_cmd = [
            python_exe,
            str(script_dir / 'portfolio_audit.py'),
            '--input', args.output,
            '--output', f'{output_dir}/STRATEGIC_AUDIT.md'
        ]
        run_command(audit_cmd, "é˜¶æ®µ 2c: æˆ˜ç•¥ç»„åˆå®¡è®¡ (SHA)")
        
        return 0 if success else 1

    elif args.command == 'apply':
        cmd = [
            python_exe,
            str(script_dir / 'apply_metadata_enhanced.py'),
            '--summaries', args.summaries,
            '--mapping', args.mapping,
            '--workers', str(args.workers),
            '--log-dir', output_dir
        ]
        if args.force:
            cmd.append('--force')

        return 0 if run_command(cmd, "é˜¶æ®µ3: åº”ç”¨å…ƒæ•°æ® (ä¼˜åŒ–ç‰ˆ å¢é‡+å¹¶è¡Œ)") else 1

    elif args.command == 'all':
        # æ‰§è¡Œå®Œæ•´æµç¨‹
        print("\n" + "="*60)
        print("å¼€å§‹æ‰§è¡Œå®Œæ•´æµç¨‹")
        print("="*60)

        # é˜¶æ®µ1: æå–
        extract_cmd = [
            python_exe,
            str(script_dir / 'extract_text.py'),
            '--dir', args.dir,
            '--workers', str(args.workers),
            '--output', f'{output_dir}/extracted_content_part1.json',
            '--mapping', f'{output_dir}/file_id_mapping.json'
        ]
        if args.force:
            extract_cmd.append('--force')

        if not run_command(extract_cmd, "é˜¶æ®µ1: æå–æ–‡æ¡£å†…å®¹"):
            return 1

        # é˜¶æ®µ2: æ™ºèƒ½ç”Ÿæˆæ‘˜è¦å’Œæ ‡ç­¾
        # 2a: åˆè§„æ€§åˆ†æ
        compliance_cmd = [
            python_exe,
            str(script_dir / 'medical_standard_checker.py'),
            '--input', f'{output_dir}/extracted_content_part1.json',
            '--output', f'{output_dir}/compliance_analysis.json'
        ]
        run_command(compliance_cmd, "é˜¶æ®µ 2a: åŒ»ç–—æ ‡å‡†å¯¹é½åˆ†æ")

        # 2b: ç”Ÿæˆæ‘˜è¦
        generate_cmd = [
            python_exe,
            str(script_dir / 'generate_summaries_enhanced.py'),
            '--input', f'{output_dir}/extracted_content_part1.json',
            '--output', f'{output_dir}/document_summaries_enhanced.json',
            '--compliance', f'{output_dir}/compliance_analysis.json'
        ]

        if not run_command(generate_cmd, "é˜¶æ®µ 2b: ç”Ÿæˆæ‘˜è¦å’Œæ ‡ç­¾ (ä¼˜åŒ–ç‰ˆ + æ”¿ç­–æ´å¯Ÿ)"):
            return 1
            
        # 2c: æˆ˜ç•¥å®¡è®¡
        audit_cmd = [
            python_exe,
            str(script_dir / 'portfolio_audit.py'),
            '--input', f'{output_dir}/document_summaries_enhanced.json',
            '--output', f'{output_dir}/STRATEGIC_AUDIT.md'
        ]
        run_command(audit_cmd, "é˜¶æ®µ 2c: æˆ˜ç•¥ç»„åˆå®¡è®¡ (SHA)")

        # é˜¶æ®µ3: åº”ç”¨å…ƒæ•°æ®
        apply_cmd = [
            python_exe,
            str(script_dir / 'apply_metadata_enhanced.py'),
            '--summaries', f'{output_dir}/document_summaries_enhanced.json',
            '--mapping', f'{output_dir}/file_id_mapping.json',
            '--workers', str(args.workers),
            '--log-dir', output_dir
        ]
        if args.force:
            apply_cmd.append('--force')

        if not run_command(apply_cmd, "é˜¶æ®µ3: åº”ç”¨å…ƒæ•°æ® (ä¼˜åŒ–ç‰ˆ)"):
            return 1

        print("\n" + "="*60)
        print("âœ“ å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
        print("="*60)
        return 0

    elif args.command == 'clean':
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ (in output dir)
        files_to_clean = [
            f'{output_dir}/extracted_content_part*.json',
            f'{output_dir}/document_summaries*.json',
            f'{output_dir}/file_id_mapping.json',
            f'{output_dir}/metadata_application*.log',
            f'{output_dir}/metadata_application_failures.json',
            f'{output_dir}/compliance_analysis.json'
        ]

        print("\næ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        from glob import glob
        for pattern in files_to_clean:
            for file in glob(pattern):
                try:
                    Path(file).unlink()
                    print(f"âœ“ åˆ é™¤: {file}")
                except Exception as e:
                    print(f"âœ— æ— æ³•åˆ é™¤ {file}: {e}")

        print("\næ¸…ç†å®Œæˆï¼")
        return 0

    return 0


if __name__ == "__main__":
    sys.exit(main())
