#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@Input:  Document directory, parallelism settings
@Output: extracted_content_part1.json (Text/ID mapping)
@Pos:    Kernel Layer. Responsible for high-fidelity text extraction across formats.

!!! Maintenance Protocol: If new file formats (e.g. .md, .txt) are needed, update SUPPORTED_EXTENSIONS.
!!! For medical OCR, consider integrating pytesseract in future iterations.

Document Summarizer - æ–‡æœ¬æå–è„šæœ¬
æ”¯æŒ PDFã€DOCXã€PPTXã€XLSX æ–‡æ¡£çš„å¹¶å‘æ–‡æœ¬æå–
"""
import os
import sys
import json
import hashlib
import argparse
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Optional, Tuple

try:
    from pypdf import PdfReader
    from docx import Document
    from pptx import Presentation
    from openpyxl import load_workbook
    from tqdm import tqdm
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
    print("ğŸ’¡ è¯·è¿è¡Œ: pip install -r requirements.txt")
    sys.exit(1)


class DocumentExtractor:
    """æ–‡æ¡£æ–‡æœ¬æå–å™¨"""

    SUPPORTED_EXTENSIONS = {'.pdf', '.docx', '.pptx', '.xlsx', '.xlsm'}

    def __init__(self, force: bool = False):
        self.force = force
        self.stats = {
            'total': 0,
            'extracted': 0,
            'skipped': 0,
            'failed': 0,
            'errors': []
        }

    @staticmethod
    def generate_file_id(file_path: str) -> str:
        """ç”Ÿæˆæ–‡ä»¶å”¯ä¸€IDï¼ˆåŸºäºè·¯å¾„MD5ï¼‰"""
        return hashlib.md5(file_path.encode('utf-8')).hexdigest()[:12]

    @staticmethod
    def has_metadata(file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²æœ‰å…ƒæ•°æ®"""
        if not file_path.exists():
            return False

        ext = file_path.suffix.lower()

        try:
            if ext == '.pdf':
                reader = PdfReader(str(file_path))
                metadata = reader.metadata
                return metadata and (metadata.get('/Subject') or metadata.get('/Keywords'))

            elif ext == '.docx':
                doc = Document(str(file_path))
                props = doc.core_properties
                return bool(props.subject or props.keywords)

            elif ext == '.pptx':
                prs = Presentation(str(file_path))
                props = prs.core_properties
                return bool(props.subject or props.keywords)

            elif ext in {'.xlsx', '.xlsm'}:
                wb = load_workbook(str(file_path), read_only=True)
                props = wb.properties
                wb.close()
                return bool(props.subject or props.keywords)

        except Exception:
            pass

        return False

    def extract_pdf(self, file_path: Path) -> Optional[str]:
        """æå–PDFæ–‡æœ¬"""
        try:
            reader = PdfReader(str(file_path))
            text_parts = []

            # æå–å‰20é¡µæˆ–å…¨éƒ¨é¡µé¢
            max_pages = min(20, len(reader.pages))
            for page in reader.pages[:max_pages]:
                text = page.extract_text()
                if text:
                    text_parts.append(text)

            content = '\n'.join(text_parts)

            # é™åˆ¶é•¿åº¦ï¼ˆæœ€å¤š10000å­—ç¬¦ï¼‰
            if len(content) > 10000:
                content = content[:10000] + '...'

            return content

        except Exception as e:
            raise Exception(f"PDFæå–å¤±è´¥: {e}")

    def extract_docx(self, file_path: Path) -> Optional[str]:
        """æå–Wordæ–‡æ¡£æ–‡æœ¬"""
        try:
            doc = Document(str(file_path))
            text_parts = []

            for para in doc.paragraphs:
                if para.text.strip():
                    text_parts.append(para.text)

            # æå–è¡¨æ ¼å†…å®¹
            for table in doc.tables:
                for row in table.rows:
                    row_text = ' | '.join(cell.text for cell in row.cells)
                    if row_text.strip():
                        text_parts.append(row_text)

            content = '\n'.join(text_parts)

            # é™åˆ¶é•¿åº¦
            if len(content) > 10000:
                content = content[:10000] + '...'

            return content

        except Exception as e:
            raise Exception(f"DOCXæå–å¤±è´¥: {e}")

    def extract_pptx(self, file_path: Path) -> Optional[str]:
        """æå–PowerPointæ–‡æœ¬"""
        try:
            prs = Presentation(str(file_path))
            text_parts = []

            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, 'text') and shape.text.strip():
                        text_parts.append(shape.text)

            content = '\n'.join(text_parts)

            # é™åˆ¶é•¿åº¦
            if len(content) > 10000:
                content = content[:10000] + '...'

            return content

        except Exception as e:
            raise Exception(f"PPTXæå–å¤±è´¥: {e}")

    def extract_xlsx(self, file_path: Path) -> Optional[str]:
        """æå–Excelæ–‡æœ¬"""
        try:
            wb = load_workbook(str(file_path), read_only=True, data_only=True)
            text_parts = []

            # æœ€å¤šå¤„ç†å‰5ä¸ªå·¥ä½œè¡¨
            for sheet_name in list(wb.sheetnames)[:5]:
                sheet = wb[sheet_name]
                text_parts.append(f"[å·¥ä½œè¡¨: {sheet_name}]")

                # æœ€å¤šè¯»å–å‰100è¡Œ
                row_count = 0
                for row in sheet.iter_rows(values_only=True):
                    if row_count >= 100:
                        break

                    row_text = ' | '.join(str(cell) for cell in row if cell is not None)
                    if row_text.strip():
                        text_parts.append(row_text)
                        row_count += 1

            wb.close()
            content = '\n'.join(text_parts)

            # é™åˆ¶é•¿åº¦
            if len(content) > 10000:
                content = content[:10000] + '...'

            return content

        except Exception as e:
            raise Exception(f"XLSXæå–å¤±è´¥: {e}")

    def extract_file(self, file_path: Path) -> Optional[Dict]:
        """æå–å•ä¸ªæ–‡ä»¶çš„æ–‡æœ¬å†…å®¹"""
        ext = file_path.suffix.lower()

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰å…ƒæ•°æ®ï¼ˆéå¼ºåˆ¶æ¨¡å¼ï¼‰
        if not self.force and self.has_metadata(file_path):
            self.stats['skipped'] += 1
            return None

        try:
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©æå–æ–¹æ³•
            if ext == '.pdf':
                content = self.extract_pdf(file_path)
            elif ext == '.docx':
                content = self.extract_docx(file_path)
            elif ext == '.pptx':
                content = self.extract_pptx(file_path)
            elif ext in {'.xlsx', '.xlsm'}:
                content = self.extract_xlsx(file_path)
            else:
                return None

            if not content or not content.strip():
                raise Exception("æå–å†…å®¹ä¸ºç©º")

            file_id = self.generate_file_id(str(file_path))
            self.stats['extracted'] += 1

            return {
                'id': file_id,
                'filename': str(file_path),
                'content': content.strip()
            }

        except Exception as e:
            self.stats['failed'] += 1
            self.stats['errors'].append({
                'file': str(file_path),
                'error': str(e)
            })
            return None

    def find_documents(self, directory: Path) -> List[Path]:
        """é€’å½’æŸ¥æ‰¾æ‰€æœ‰æ”¯æŒçš„æ–‡æ¡£"""
        documents = []

        for ext in self.SUPPORTED_EXTENSIONS:
            documents.extend(directory.rglob(f'*{ext}'))

        return sorted(documents)

    def extract_batch(self, directory: Path, workers: int = 5) -> Tuple[List[Dict], Dict]:
        """æ‰¹é‡æå–æ–‡æ¡£"""
        documents = self.find_documents(directory)
        self.stats['total'] = len(documents)

        if not documents:
            print(f"âŒ åœ¨ç›®å½• {directory} ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„æ–‡æ¡£")
            return [], {}

        print(f"ğŸ“ æ‰¾åˆ° {len(documents)} ä¸ªæ–‡æ¡£æ–‡ä»¶")
        print(f"ğŸ”§ æ”¯æŒçš„æ ¼å¼: {', '.join(self.SUPPORTED_EXTENSIONS)}")

        if not self.force:
            print(f"â­ï¸  å°†è·³è¿‡å·²æœ‰å…ƒæ•°æ®çš„æ–‡ä»¶ï¼ˆä½¿ç”¨ --force å¼ºåˆ¶é‡æ–°æå–ï¼‰")

        extracted_data = []
        file_id_mapping = {}

        # å¹¶å‘æå–
        with ThreadPoolExecutor(max_workers=workers) as executor:
            futures = {executor.submit(self.extract_file, doc): doc for doc in documents}

            with tqdm(total=len(documents), desc="æå–è¿›åº¦", unit="æ–‡ä»¶") as pbar:
                for future in as_completed(futures):
                    result = future.result()
                    if result:
                        extracted_data.append(result)
                        file_id_mapping[result['id']] = result['filename']
                    pbar.update(1)

        return extracted_data, file_id_mapping


def main():
    parser = argparse.ArgumentParser(
        description='æ–‡æ¡£æ–‡æœ¬æå–å·¥å…· - æ”¯æŒ PDF/DOCX/PPTX/XLSX',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('--dir', required=True, help='æ–‡æ¡£ç›®å½•è·¯å¾„')
    parser.add_argument('--workers', type=int, default=5, help='å¹¶è¡Œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 5ï¼‰')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°æå–æ‰€æœ‰æ–‡ä»¶')
    parser.add_argument('--output', default='extracted_content_part1.json', help='è¾“å‡ºæ–‡ä»¶å')
    parser.add_argument('--mapping', default='file_id_mapping.json', help='æ–‡ä»¶æ˜ å°„æ–‡ä»¶å')

    args = parser.parse_args()

    # éªŒè¯ç›®å½•
    directory = Path(args.dir)
    if not directory.exists() or not directory.is_dir():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {directory}")
        return 1

    print("\n" + "="*60)
    print("ğŸ“„ æ–‡æ¡£æ–‡æœ¬æå–å·¥å…·")
    print("="*60)

    # æ‰§è¡Œæå–
    extractor = DocumentExtractor(force=args.force)
    extracted_data, file_id_mapping = extractor.extract_batch(directory, args.workers)

    # ä¿å­˜ç»“æœ
    if extracted_data:
        output_path = Path(args.output)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(extracted_data, f, ensure_ascii=False, indent=2)

        mapping_path = Path(args.mapping)
        with open(mapping_path, 'w', encoding='utf-8') as f:
            json.dump(file_id_mapping, f, ensure_ascii=False, indent=2)

        print(f"\nâœ… æå–å®Œæˆï¼")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æ€»æ–‡ä»¶æ•°: {extractor.stats['total']}")
        print(f"   - æˆåŠŸæå–: {extractor.stats['extracted']}")
        print(f"   - è·³è¿‡æ–‡ä»¶: {extractor.stats['skipped']}")
        print(f"   - å¤±è´¥æ–‡ä»¶: {extractor.stats['failed']}")
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   - {output_path.absolute()}")
        print(f"   - {mapping_path.absolute()}")

        if extractor.stats['errors']:
            print(f"\nâš ï¸  å¤±è´¥è¯¦æƒ…:")
            for err in extractor.stats['errors'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                print(f"   - {Path(err['file']).name}: {err['error']}")
            if len(extractor.stats['errors']) > 5:
                print(f"   ... è¿˜æœ‰ {len(extractor.stats['errors']) - 5} ä¸ªé”™è¯¯")

    else:
        print("\nâš ï¸  æ²¡æœ‰æå–åˆ°ä»»ä½•å†…å®¹")
        return 1

    return 0


if __name__ == '__main__':
    sys.exit(main())
