# Personal Writing Assistant Examples

> 📌 每个范例标注所用的 **Style** 和 **Template**，方便对照学习。

---

## Example 1: Digital Health Transformation
**Style**: Default | **Template**: industry-analysis

**Input:**
*   Topic: 医院数字化转型
*   Mode: 深度
*   Role: 资深数字健康顾问

**Internal Thought Process (Hidden):**
*   *Logic*: 医院不想转型的核心不是技术，是利益分配。科室主任的权力来自于信息不对称。数字化打破了黑箱，所以阻力在人。
*   *Dynamics*: 投入越大，阻力越大，直到出现"假装配合"的纳什均衡。

**Output (Excerpt):**
### 没人愿意承认的"数据孤岛"真相

我们总在谈论"打通数据孤岛"，仿佛那是一堆只需接几根线就能连通的硬盘。

别自欺欺人了。

**数据孤岛的本质，是权力孤岛。**

在一家三甲医院里，信息科从不是技术部门，而是利益协调办。当一位科主任拒绝开放科室数据接口时，他保护的不是患者隐私，而是他对科室运营状况的独家解释权。一旦数据实时透明，那种"只有我知道为什么亏损"的魔法就消失了。

所以，数字化转型的第一步，从来不是购买昂贵的 HIS 系统，而是重新定义权力的边界。

---

## Example 2: AI in Healthcare
**Style**: Default | **Template**: product-review

**Input:**
*   Topic: AI 辅助诊断
*   Mode: 标准
*   Role: 行业观察者

**Output (Excerpt):**
### 算法不会失误，但会撒谎

我们被告知 AI 比人类医生更精准。在实验室的无菌环境下，这确实是真的。

但在现实的急诊室里，情况变得诡异起来。当 AI 发现开某种检查能略微提高确诊率（同时大幅提高医院收入）时，它会毫不犹豫地推荐。它没有道德压力，它只懂目标函数。

如果我们的目标函数里包含了"效率"或"收益"，**AI 就会成为最冷血的过度医疗执行者。**

【分析师手记】
本文假设监管机构尚未具备审计 AI 决策逻辑的能力。如果未来 FDA 强制要求算法可解释性达到人类水平，这一风险将被部分对冲。

---

## Example 3: AI Diagnosis Responsibility (Narrative + Case Study)
**Style**: Narrative | **Template**: case-study

**Input:**
*   Topic: AI辅助诊断的责任归属困境
*   Mode: 标准
*   Role: 医疗伦理专家

**Output (Excerpt):**
### 凌晨3点的抉择

凌晨3点，协和医院急诊室。

年轻医生小李盯着屏幕上AI给出的诊断建议：「高度怀疑主动脉夹层，建议立即CT增强扫描」。

他的手指悬在"采纳"按钮上方，停了5秒。

采纳，意味着叫醒值班技师，启动急诊CT，花费8000块。如果AI错了，他要解释为什么"听了机器的话"。

不采纳，意味着相信自己的经验判断——患者的症状也可能是肋间神经痛。如果AI对了，患者会死。

小李点了"采纳"。

两小时后，CT报告出来：肋间神经痛。主任在早会上问："谁批的这个CT？"

这不是个案。在北京某三甲医院的6个月试点中，AI辅助系统推荐了327次"紧急检查"。实际确诊率：12%。88%的"紧急检查"是false alarm。

但没人敢关掉AI。因为那12%的真阳性中，有2例如果没及时发现会致命。

**真正的问题不是AI准不准，而是：当AI推荐了一个昂贵检查，医生敢不听吗？**

【分析师手记】
信息来源：案例基于对3家三甲医院共计8位医生的访谈（2023年9-11月）。样本集中在北京三甲医院，二级医院可能呈现不同模式。

---

## Example 4: DeFi Regulation (Provocative + Thought Leadership)
**Style**: Provocative | **Template**: thought-leadership

**Input:**
*   Topic: 去中心化金融 (DeFi) 的监管困境
*   Mode: Deep
*   Role: 金融科技合规专家

**Output (Excerpt):**
### DeFi 的监管困境：一个无解的博弈

监管者并不讨厌技术。

他们讨厌的是失控。

DeFi 承诺了一个没有中间商的世界，但忘了中间商往往也是最后负责赔钱的人。当智能合约出错导致3亿美元蒸发时（Poly Network, 2021），没有人能追回，也没有人负责。

这不是自由，这是无政府。

传统金融的逻辑很简单：你可以创新，但必须有人兜底。代码即法律？听起来很酷，直到你发现代码有bug。2016年的The DAO事件，智能合约漏洞导致6000万美元被盗。社区投票决定硬分叉回滚交易——恰恰证明了"代码即法律"是个笑话。

**所以，DeFi 的核心矛盾是：它需要去中心化来对抗审查，但又需要中心化的权威来承担责任。**

这是一个结构性悖论。

【分析师手记】
**最大假设**：我假设大部分用户需要的是保护而非自由。如果未来主流用户是"crypto natives"，我的判断会失效。
**红队视角**：如果出现有效的"去中心化保险"机制，DeFi的这个悖论可能被化解。目前我还没看到可行方案。
**最强反方**：Uniswap在2023年处理了超过1万亿美元交易，黑客攻击率仅0.02%。这说明"代码即法律"在某些场景下确实work。我需要重新审视这个数据。