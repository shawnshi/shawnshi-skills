"""
<!-- Input: Raw text (AI-generated or formal) -->
<!-- Output: Humanized text, Analysis report, Humanizer Score -->
<!-- Pos: scripts/humanize_engine.py. Linguistic refinement engine. -->
"""

import argparse
import sys
import subprocess
import os

def read_file(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return ""

def main():
    parser = argparse.ArgumentParser(description="Humanizer-zh-pro Linguistic Engine")
    parser.add_argument("text_or_file", nargs='?', default="", help="The text to analyze or path to a text file")
    parser.add_argument("--test", action="store_true", help="Run the built-in test case")
    args = parser.parse_args()
    
    # 1. Resolve Input
    input_text = ""
    if args.test:
        input_text = "éšç€æ•°å­—åŒ»ç–—çš„å¤§åŠ›æ¨è¿›ï¼Œæˆ‘å¸çš„ HIS æ ¸å¿ƒç³»ç»Ÿé‡æ„é¡¹ç›®è¿æ¥äº†é‡è¦çš„é‡Œç¨‹ç¢‘ã€‚é€šè¿‡å¯¹åº•å±‚æ¶æ„çš„æ·±åº¦æ•´åˆä¸å¾®æœåŠ¡åŒ–æ”¹é€ ï¼Œæˆ‘ä»¬ä¸ä»…å®ç°äº†ç³»ç»Ÿæ€§èƒ½çš„æ˜¾è‘—ä¼˜åŒ–ï¼Œè¿˜æœ‰æ•ˆé™ä½äº†è¿ç»´æˆæœ¬ã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œè¿™ä¸€é˜¶æ®µæ€§æˆæœå±•ç°äº†æˆ‘ä»¬åœ¨åŒ»ç–—ä¿¡æ¯åŒ–é¢†åŸŸçš„æ·±åšç§¯ç´¯ã€‚"
    elif os.path.isfile(args.text_or_file):
        with open(args.text_or_file, 'r', encoding='utf-8') as f:
            input_text = f.read()
    else:
        input_text = args.text_or_file

    if not input_text.strip():
        print("Error: Empty input. Provide text or use --test.")
        sys.exit(1)

    print(f"[*] Input length: {len(input_text)} chars")
    print(f"[*] Engine initializing...")

    # 2. Build the Persona & Constraints Prompt
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    skill_md = read_file(os.path.join(base_dir, "SKILL.md"))
    guidelines_md = read_file(os.path.join(base_dir, "references", "GUIDELINES.md"))
    checklist_md = read_file(os.path.join(base_dir, "references", "CHECKLIST.md"))

    system_prompt = f"""
ä½ æ˜¯å«å®å¥åº·çš„æˆ˜ç•¥å’¨è¯¢æ€»ç»ç†ï¼Œä¹Ÿæ˜¯é¡¶å°–çš„æ–‡å­—é‡é“¸å¸ˆã€‚ä½ éœ€è¦å°†ä»¥ä¸‹æ–‡æœ¬æŒ‰ç…§ã€ä¸‰é˜¶å±‚æ¶¦è‰²ã€‘çš„æ–¹æ³•è¿›è¡Œå½»åº•â€œå»AIåŒ–â€æ”¹å†™ã€‚

ã€ä¸€ã€æ ¸å¿ƒå¿ƒæ³•ã€‘
{skill_md}

ã€äºŒã€é»‘åå•ä¸ç½®æ¢è¯å…¸ã€‘
{guidelines_md}

ã€ä¸‰ã€ä»»åŠ¡è‡ªæ£€æ¸…å•ã€‘
{checklist_md}

ã€åŠ¨ä½œè¦æ±‚ã€‘
1. é¦–å…ˆï¼Œç®€è¦è¾“å‡ºä¸€æ®µæçŸ­çš„ä¿®æ”¹æ€è·¯ï¼ˆCoTæ¨æ¼”ï¼‰ï¼Œç›´æ¥æŒ‡å‡ºåŸæ–‡æœ¬ä¸­å“ªäº›è¯æ±‡è¸©äº†é»‘åå•ï¼Œå“ªäº›å¥å­èŠ‚å¥ä¸å¯¹ã€‚
2. ç„¶åï¼Œè¾“å‡ºã€æœ€ç»ˆé«˜ç®¡ç®€æŠ¥ç»ˆç¨¿ã€‘ã€‚
3. æœ€åï¼Œæ ¹æ®ã€Šä»»åŠ¡è‡ªæ£€æ¸…å•ã€‹æ‰§è¡Œæ‰“åˆ†æ ¸æŸ¥ï¼ˆä¾‹å¦‚ï¼š5/5åˆ†ï¼Œæ»¡è¶³æ‰€æœ‰æ¡ä»¶ï¼‰ã€‚

ã€åŸå§‹è¾“å…¥æ–‡æœ¬ã€‘
{input_text}
"""

    print("[*] Dispatching to LLM engine for linguistic processing...")
    
    # 3. Call Gemini CLI
    try:
        import tempfile
        # Write prompt to a temporary file to avoid command-line length limits and escaping hell
        with tempfile.NamedTemporaryFile("w", encoding="utf-8", delete=False) as f:
            f.write(system_prompt)
            temp_path = f.name

        cmd = f"gemini -p (Get-Content -Raw -Path '{temp_path}')"
        process = subprocess.Popen(
            ["powershell", "-NoProfile", "-Command", cmd],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            encoding='utf-8',
            errors='replace'
        )
        stdout, stderr = process.communicate()
        
        # Cleanup temp file
        try:
            os.remove(temp_path)
        except Exception:
            pass
        
        if process.returncode != 0:
            print("[!] Gemini CLI execution failed:")
            print(stderr)
        else:
            print("\n" + "="*60)
            print(" ğŸ”ª ã€Humanizer-zh-pro æ–‡æœ¬é‡é“¸å®Œæ¯•ã€‘ ğŸ”ª")
            print("="*60 + "\n")
            print(stdout)
            
    except FileNotFoundError:
        print("[!] Error: 'gemini' CLI tool not found. Please ensure it is installed and in your PATH.")
        sys.exit(1)
    except Exception as e:
        print(f"[!] Unexpected error: {e}")

if __name__ == "__main__":
    main()
